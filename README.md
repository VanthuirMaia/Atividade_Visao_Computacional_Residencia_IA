# Projeto de ClassificaÃ§Ã£o de Imagens - VisÃ£o Computacional
## DocumentaÃ§Ã£o Completa e Consolidada

> **Este README consolida TODA a documentaÃ§Ã£o do projeto**, incluindo toda a histÃ³ria de desenvolvimento, erros encontrados, correÃ§Ãµes implementadas, otimizaÃ§Ãµes, mudanÃ§as de parÃ¢metros, ajustes de mÃ©todos, e exemplos de cÃ³digo especÃ­ficos com explicaÃ§Ãµes detalhadas.

**VersÃ£o do Projeto**: 1.0.0 (Final)  
**Ãšltima AtualizaÃ§Ã£o**: 2024  
**Status**: âœ… EstÃ¡vel e Otimizado

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral do Projeto](#visÃ£o-geral-do-projeto)
2. [Estrutura Completa do Projeto](#estrutura-completa-do-projeto)
3. [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#instalaÃ§Ã£o-e-configuraÃ§Ã£o)
4. [HistÃ³ria Completa do Desenvolvimento](#histÃ³ria-completa-do-desenvolvimento)
   - [Erros Encontrados e Corrigidos](#erros-encontrados-e-corrigidos)
   - [OtimizaÃ§Ãµes de MemÃ³ria](#otimizaÃ§Ãµes-de-memÃ³ria)
   - [CorreÃ§Ãµes de GPU](#correÃ§Ãµes-de-gpu)
   - [Sistema de Salvamento de Modelos](#sistema-de-salvamento-de-modelos)
   - [Random Search Otimizado](#random-search-otimizado)
5. [ConfiguraÃ§Ãµes Detalhadas](#configuraÃ§Ãµes-detalhadas)
6. [Exemplos de CÃ³digo por Componente](#exemplos-de-cÃ³digo-por-componente)
7. [Guia de Uso Completo](#guia-de-uso-completo)
8. [Troubleshooting](#troubleshooting)
9. [ReferÃªncias e DocumentaÃ§Ã£o TÃ©cnica](#referÃªncias-e-documentaÃ§Ã£o-tÃ©cnica)

---

## ğŸ¯ VisÃ£o Geral do Projeto

Projeto completo de classificaÃ§Ã£o de imagens (AI Art vs Human Art) utilizando mÃºltiplas abordagens:
- **Pipeline ClÃ¡ssico**: SVM e Random Forest com otimizaÃ§Ã£o de hiperparÃ¢metros
- **Pipeline Deep Learning**: Simple CNN e ResNet50 com transfer learning
- **OtimizaÃ§Ãµes AvanÃ§adas**: Gerenciamento de memÃ³ria, lazy loading, limpeza automÃ¡tica
- **Sistema Completo**: Download automÃ¡tico de dataset, diagnÃ³stico, salvamento de modelos

## ğŸ“ Estrutura Completa do Projeto

```
.
â”œâ”€â”€ main.py                          # Ponto de entrada principal com menu interativo
â”œâ”€â”€ main_subset.py                   # VersÃ£o para testes rÃ¡pidos com subset (10 imagens/classe)
â”œâ”€â”€ requirements.txt                 # Todas as dependÃªncias do projeto
â”œâ”€â”€ README.md                        # Este arquivo - documentaÃ§Ã£o completa consolidada
â”‚
â”œâ”€â”€ Scripts de DiagnÃ³stico/
â”‚   â”œâ”€â”€ diagnose_data.py             # DiagnÃ³stico da estrutura de dados
â”‚   â”œâ”€â”€ check_gpu.py                 # VerificaÃ§Ã£o de GPU/CUDA
â”‚   â”œâ”€â”€ verificar_pytorch.py         # VerificaÃ§Ã£o completa do PyTorch
â”‚   â”œâ”€â”€ diagnose_gpu_usage.py        # DiagnÃ³stico de uso de GPU
â”‚   â””â”€â”€ testar_gpu_direto.py         # Teste direto de GPU sem dependÃªncias
â”‚
â”œâ”€â”€ src/                             # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                    # âš™ï¸ TODAS as configuraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ utils.py                     # FunÃ§Ãµes utilitÃ¡rias (device, imagens, mÃ©tricas)
â”‚   â”œâ”€â”€ datasets.py                  # LazyImageDataset para carregamento eficiente
â”‚   â”œâ”€â”€ memory.py                    # Gerenciamento avanÃ§ado de memÃ³ria
â”‚   â”œâ”€â”€ model_saver.py               # Sistema de salvamento com metadados
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                      # DefiniÃ§Ãµes de modelos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ cnn.py                   # SimpleCNN - arquitetura customizada
â”‚   â”‚
â”‚   â””â”€â”€ pipelines/                   # Pipelines de treinamento
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ classic.py               # Pipeline clÃ¡ssico (SVM, Random Forest)
â”‚       â””â”€â”€ deep_learning.py         # Pipeline deep learning (CNN, ResNet50)
â”‚
â”œâ”€â”€ scripts/                         # Scripts auxiliares
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ download_dataset.py          # Download automÃ¡tico do dataset Kaggle
â”‚   â”œâ”€â”€ create_subset.py             # CriaÃ§Ã£o de subset para testes rÃ¡pidos
â”‚   â””â”€â”€ load_model_example.py        # Exemplo de como carregar modelos salvos
â”‚
â”œâ”€â”€ data/                            # Dados (ignorado pelo git)
â”‚   â”œâ”€â”€ train/                       # Imagens de treinamento
â”‚   â”‚   â”œâ”€â”€ aiartdata/               # Classe 1: Arte gerada por IA
â”‚   â”‚   â””â”€â”€ realart/                 # Classe 2: Arte criada por humanos
â”‚   â”œâ”€â”€ test/                        # Imagens de teste
â”‚   â”‚   â”œâ”€â”€ aiartdata/
â”‚   â”‚   â””â”€â”€ realart/
â”‚   â”œâ”€â”€ train_subset/                # Subset pequeno para testes (10/classe)
â”‚   â””â”€â”€ test_subset/                 # Subset pequeno para testes (10/classe)
â”‚
â””â”€â”€ outputs/                         # Resultados gerados (ignorado pelo git)
    â”œâ”€â”€ models/                      # Modelos treinados salvos
    â”‚   â”œâ”€â”€ svm_model.pkl            # Modelo SVM
    â”‚   â”œâ”€â”€ svm_model.json           # Metadados do SVM
    â”‚   â”œâ”€â”€ svm_scaler.pkl           # Scaler usado no SVM
    â”‚   â”œâ”€â”€ random_forest_model.pkl  # Modelo Random Forest
    â”‚   â”œâ”€â”€ simple_cnn.pth           # Modelo Simple CNN
    â”‚   â”œâ”€â”€ resnet50_transfer.pth    # Modelo ResNet50
    â”‚   â””â”€â”€ *.json                   # Metadados de cada modelo
    â”œâ”€â”€ results/                     # Resultados em CSV
    â”‚   â”œâ”€â”€ classic_pipeline_results.csv
    â”‚   â””â”€â”€ deep_learning_results.csv
    â””â”€â”€ figures/                     # GrÃ¡ficos e visualizaÃ§Ãµes
        â”œâ”€â”€ svm_confusion_matrix.png
        â”œâ”€â”€ random_forest_confusion_matrix.png
        â”œâ”€â”€ simple_cnn_confusion_matrix.png
        â””â”€â”€ resnet50_confusion_matrix.png
```

### Arquivos de DocumentaÃ§Ã£o Consolidados

âœ… **Todos os arquivos `.md` anteriores foram consolidados neste README e removidos do projeto:**

- `ANALISE_CODIGO.md` - AnÃ¡lise completa do cÃ³digo â†’ SeÃ§Ã£o "HistÃ³ria Completa do Desenvolvimento"
- `ANALISE_GPU.md` - AnÃ¡lise de GPU â†’ SeÃ§Ã£o "CorreÃ§Ãµes de GPU"
- `ANALISE_LIMPEZA_PROJETO.md` - Limpeza realizada â†’ Integrado nas otimizaÃ§Ãµes
- `ANALISE_MODELOS_CLASSICOS.md` - AnÃ¡lise de modelos clÃ¡ssicos â†’ SeÃ§Ã£o "Pipeline ClÃ¡ssico"
- `GUIA_SALVAMENTO_MODELOS.md` - Sistema de salvamento â†’ SeÃ§Ã£o "Sistema de Salvamento de Modelos"
- `RANDOM_SEARCH_ATUALIZADO.md` - Random Search otimizado â†’ SeÃ§Ã£o "Random Search Otimizado"
- `RANDOM_SEARCH_TODOS_MODELOS.md` - Random Search em todos modelos â†’ SeÃ§Ã£o "Random Search Otimizado"
- `SOLUCAO_ESTOURO_MEMORIA_RESNET50.md` - SoluÃ§Ã£o ResNet50 â†’ SeÃ§Ã£o "OtimizaÃ§Ãµes de MemÃ³ria"
- `SOLUCAO_ESTOURO_MEMORIA_SVM.md` - SoluÃ§Ã£o SVM â†’ SeÃ§Ã£o "OtimizaÃ§Ãµes de MemÃ³ria"
- `SOLUCAO_GPU_NAO_UTILIZADA.md` - SoluÃ§Ã£o GPU â†’ SeÃ§Ã£o "CorreÃ§Ãµes de GPU"
- `VERIFICACAO_GPU.md` - VerificaÃ§Ã£o GPU â†’ SeÃ§Ã£o "CorreÃ§Ãµes de GPU" e "Troubleshooting"

**Status**: âœ… Todos os arquivos foram removidos. Todo o conteÃºdo estÃ¡ consolidado neste README.

---

## ğŸ“š HistÃ³ria Completa do Desenvolvimento

Esta seÃ§Ã£o documenta **TUDO** que foi realizado durante o desenvolvimento do projeto, desde os erros iniciais atÃ© as otimizaÃ§Ãµes finais.

### ğŸ“… Cronologia de Desenvolvimento

#### **Fase 1: Problemas Iniciais com Dataset**

**Problema 1.1: Apenas 1 Classe Detectada**
- **Erro**: `ValueError: Apenas 1 classe(s) foi(ram) carregada(s), mas sÃ£o necessÃ¡rias pelo menos 2 classes para classificaÃ§Ã£o.`
- **Causa**: Script `download_dataset.py` nÃ£o identificava corretamente as classes "AiArtData" e "RealArt"
- **LocalizaÃ§Ã£o**: `scripts/download_dataset.py`, funÃ§Ã£o `find_class_directories()`
- **CorreÃ§Ã£o Implementada**:

```python
# scripts/download_dataset.py - LINHAS CORRIGIDAS
def find_class_directories(directory):
    """Encontra diretÃ³rios de classes no dataset"""
    classes = []
    for item in Path(directory).iterdir():
        if item.is_dir():
            # CORREÃ‡ÃƒO: Busca case-insensitive e variaÃ§Ãµes de nomes
            name_lower = item.name.lower()
            if 'aiart' in name_lower or 'ai_art' in name_lower:
                classes.append(('aiartdata', item))
            elif 'realart' in name_lower or 'real_art' in name_lower or 'human' in name_lower:
                classes.append(('realart', item))
    return classes
```

**Impacto**: âœ… Permite detectar classes independente de variaÃ§Ãµes de nomenclatura

---

**Problema 1.2: EOFError em Script NÃ£o-Interativo**
- **Erro**: `EOFError` ao executar `scripts/create_subset.py` de forma nÃ£o-interativa
- **Causa**: Uso de `input()` para confirmaÃ§Ã£o do usuÃ¡rio
- **LocalizaÃ§Ã£o**: `scripts/create_subset.py`
- **CorreÃ§Ã£o Implementada**:

```python
# scripts/create_subset.py - ANTES (com erro):
if backup_exists:
    resposta = input("Subset jÃ¡ existe. Substituir? (s/n): ")  # âŒ Causa EOFError
    if resposta.lower() != 's':
        return

# scripts/create_subset.py - DEPOIS (corrigido):
# REMOVIDO: Prompt interativo que causava EOFError
# AGORA: Cria subset automaticamente, criando classes artificiais se necessÃ¡rio
if len(class_dirs) < 2:
    print("Apenas 1 classe encontrada. Criando classes artificiais (classe_a, classe_b)...")
    # Cria subset com nomes artificiais
```

**Impacto**: âœ… Script pode ser executado em ambientes nÃ£o-interativos (CI/CD, scripts automatizados)

---

#### **Fase 2: Erros em Modelos Deep Learning**

**Problema 2.1: TypeError no ReduceLROnPlateau**
- **Erro**: `TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'`
- **Causa**: PyTorch versÃ£o nÃ£o suporta parÃ¢metro `verbose` em `ReduceLROnPlateau`
- **LocalizaÃ§Ã£o**: `src/pipelines/deep_learning.py`, linhas 473-475 e 548-550
- **CÃ³digo Antes (com erro)**:

```python
# src/pipelines/deep_learning.py - ANTES (linha 473):
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=5, verbose=True  # âŒ Erro: verbose nÃ£o existe
)
```

- **CÃ³digo Depois (corrigido)**:

```python
# src/pipelines/deep_learning.py - DEPOIS (linha 599):
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=5  # âœ… Removido verbose
)
```

**Impacto**: âœ… CompatÃ­vel com todas as versÃµes do PyTorch

---

**Problema 2.2: AttributeError com setup_device**
- **Erro**: `AttributeError: 'str' object has no attribute 'type'`
- **Causa**: FunÃ§Ã£o `setup_device()` poderia retornar string `'cpu'` ao invÃ©s de `torch.device('cpu')`
- **LocalizaÃ§Ã£o**: `src/utils.py`, funÃ§Ã£o `setup_device()` e `src/pipelines/deep_learning.py`
- **CÃ³digo Antes (com erro)**:

```python
# src/utils.py - ANTES:
def setup_device(use_gpu=True):
    # ...
    if use_gpu and not torch.cuda.is_available():
        return 'cpu'  # âŒ Retorna string, nÃ£o torch.device
    
# src/pipelines/deep_learning.py - ANTES:
self.device = setup_device(use_gpu)
if self.device.type == 'cuda':  # âŒ Erro se device for string 'cpu'
    ...
```

- **CÃ³digo Depois (corrigido)**:

```python
# src/utils.py - DEPOIS (linha 62, 122):
def setup_device(use_gpu=True):
    # ...
    if use_gpu and not torch.cuda.is_available():
        return torch.device('cpu')  # âœ… Sempre retorna torch.device
    
    # ...
    else:
        # ...
        return torch.device('cpu')  # âœ… Sempre retorna torch.device
```

- **VerificaÃ§Ã£o Adicional em deep_learning.py (linhas 129-161)**:

```python
# src/pipelines/deep_learning.py - DEPOIS (linha 130-161):
# Garantir que device Ã© torch.device
if isinstance(self.device, str):
    print(f"   âš ï¸  Dispositivo Ã© string '{self.device}', convertendo para torch.device...")
    self.device = torch.device(self.device)
elif not isinstance(self.device, torch.device):
    print(f"   âš ï¸  Tipo desconhecido, usando CPU...")
    self.device = torch.device('cpu')
```

**Impacto**: âœ… Dispositivo sempre Ã© objeto `torch.device`, evitando erros de atributo

---

**Problema 2.3: Modelos NÃ£o Estavam Usando GPU**
- **Erro**: Modelos deep learning executavam na CPU mesmo com GPU disponÃ­vel
- **Causa**: Modelos nÃ£o eram movidos explicitamente para GPU apÃ³s criaÃ§Ã£o
- **LocalizaÃ§Ã£o**: MÃºltiplas funÃ§Ãµes em `src/pipelines/deep_learning.py`
- **CorreÃ§Ãµes Implementadas**:

**2.3.1: ResNet50 nÃ£o movido para GPU** (linha 1049-1061):
```python
# src/pipelines/deep_learning.py - ANTES (create_resnet_model):
model = models.resnet50(weights='IMAGENET1K_V2')
# ... configurar modelo ...
return model  # âŒ Modelo fica na CPU

# src/pipelines/deep_learning.py - DEPOIS (linha 1049-1061):
model = models.resnet50(weights='IMAGENET1K_V2')
# ... configurar modelo ...

# CRÃTICO: Mover modelo para dispositivo correto (GPU ou CPU)
model = model.to(self.device)

# Verificar dispositivo e mostrar informaÃ§Ãµes
model_device = next(model.parameters()).device
if model_device.type == 'cuda':
    print(f"   âœ… ResNet50 estÃ¡ na GPU: {torch.cuda.get_device_name(model_device.index or 0)}")
else:
    print(f"   â„¹ï¸  ResNet50 estÃ¡ na CPU")

return model  # âœ… Modelo estÃ¡ no dispositivo correto
```

**2.3.2: SimpleCNN nÃ£o movido no Random Search** (linha 798-804):
```python
# src/pipelines/deep_learning.py - ANTES (train_simple_cnn - Random Search):
model = SimpleCNN(
    self.num_classes,
    dropout_rate=params['dropout_rate'],
    hidden_units=params['hidden_units']
)
# âŒ Modelo criado mas nÃ£o movido para GPU
val_acc, _, iter_time = self.train_single_config(...)

# src/pipelines/deep_learning.py - DEPOIS (linha 798-804):
model = SimpleCNN(...)

# CRÃTICO: Mover modelo para dispositivo correto ANTES do treinamento
model = model.to(self.device)

# Verificar dispositivo (apenas na primeira iteraÃ§Ã£o)
if i == 0:
    model_device = next(model.parameters()).device
    print(f"     Modelo SimpleCNN criado e movido para: {model_device}")
    if model_device.type == 'cuda':
        print(f"     âœ… SimpleCNN estÃ¡ na GPU: {torch.cuda.get_device_name(model_device.index or 0)}")
```

**2.3.3: SimpleCNN nÃ£o movido no treinamento final** (linha 831-842):
```python
# src/pipelines/deep_learning.py - DEPOIS (linha 831-842):
model = SimpleCNN(...)

# CRÃTICO: Mover modelo para dispositivo correto ANTES do treinamento
model = model.to(self.device)

# Verificar dispositivo do modelo
model_device = next(model.parameters()).device
print(f"\nModelo SimpleCNN criado:")
print(f"  Dispositivo: {model_device}")
if model_device.type == 'cuda':
    print(f"  âœ… SimpleCNN estÃ¡ na GPU: {torch.cuda.get_device_name(model_device.index or 0)}")
```

**2.3.4: Melhorias em train_single_config e train_model**:
```python
# src/pipelines/deep_learning.py - DEPOIS (linha 505-507):
def train_single_config(self, model, train_loader, val_loader, epochs, learning_rate, patience=5):
    # Garantir que modelo estÃ¡ no dispositivo correto
    if next(model.parameters()).device != self.device:
        print(f"     [AVISO] Movendo modelo de {next(model.parameters()).device} para {self.device}")
        model = model.to(self.device)
```

```python
# src/pipelines/deep_learning.py - DEPOIS (linha 601-605):
def train_model(self, model, train_loader, epochs, learning_rate, model_name):
    # Garantir que modelo estÃ¡ no dispositivo correto
    if next(model.parameters()).device != self.device:
        print(f"   [AVISO] Movendo modelo {model_name} de {next(model.parameters()).device} para {self.device}")
        model = model.to(self.device)
```

**Impacto**: âœ… Todos os modelos agora usam GPU automaticamente quando disponÃ­vel

---

#### **Fase 3: Estouro de MemÃ³ria - SVM**

**Problema 3.1: Estouro de MemÃ³ria no SVM**
- **Erro**: `MemoryError` ou sistema travando durante treinamento do SVM
- **Causa**: Imagens muito grandes (224x224x3) + kernel RBF + CV folds mÃºltiplos
- **AnÃ¡lise do Problema**:

```
ANTES (Problema):
- Imagens: 224x224x3 = 150,528 features por imagem
- 10.000 amostras: 150,528 Ã— 10.000 = 1.5 bilhÃµes de features
- MemÃ³ria necessÃ¡ria: ~12 GB apenas para dados
- Matriz Gram (RBF kernel): ~800 MB - 8 GB
- CV=3: MÃºltiplas cÃ³pias dos dados
- n_jobs=-1: MÃºltiplos processos duplicando dados
- TOTAL: ~15-20 GB de RAM necessÃ¡ria!
```

- **SoluÃ§Ãµes Implementadas** (cÃ³digo em `src/config.py` e `src/pipelines/classic.py`):

**SoluÃ§Ã£o 3.1.1: Tamanho de Imagem Reduzido** (linha 29 em `config.py`):
```python
# src/config.py - NOVA CONFIGURAÃ‡ÃƒO (linha 29):
IMG_SIZE_CLASSIC = (64, 64)  # Tamanho menor para modelos clÃ¡ssicos (economiza memÃ³ria)
IMG_SIZE = (224, 224)  # Mantido para deep learning
```

**ImplementaÃ§Ã£o em classic.py (linha 94-95)**:
```python
# src/pipelines/classic.py - ANTES:
X_train, y_train, self.class_names = load_images_from_directory(
    self.train_dir, img_size=(224, 224)  # âŒ Muito grande

# src/pipelines/classic.py - DEPOIS (linha 94-95):
X_train, y_train, self.class_names = load_images_from_directory(
    self.train_dir, img_size=IMG_SIZE_CLASSIC  # âœ… 64x64
)
```

**ReduÃ§Ã£o**: 150,528 features â†’ 12,288 features (92% reduÃ§Ã£o!)

---

**SoluÃ§Ã£o 3.1.2: PCA para ReduÃ§Ã£o de Dimensionalidade** (linha 102-103, 154-179 em `classic.py`):
```python
# src/config.py - NOVAS CONFIGURAÃ‡Ã•ES (linhas 102-103):
CLASSIC_USE_PCA = True  # Usar PCA para reduÃ§Ã£o de dimensionalidade
CLASSIC_PCA_COMPONENTS = 500  # NÃºmero de componentes PCA
```

**ImplementaÃ§Ã£o em classic.py (linha 154-179)**:
```python
# src/pipelines/classic.py - NOVO CÃ“DIGO (linha 152-179):
# PCA para reduÃ§Ã£o de dimensionalidade (opcional)
self.pca = None
if CLASSIC_USE_PCA:
    print(f"\n   Aplicando PCA para reduÃ§Ã£o de dimensionalidade...")
    
    if CLASSIC_PCA_COMPONENTS is None:
        # Auto: reduzir para 95% variÃ¢ncia
        self.pca = PCA(n_components=0.95, random_state=42)
        print(f"   Modo: Auto (95% variÃ¢ncia explicada)")
    else:
        # NÃºmero fixo de componentes
        n_components = min(CLASSIC_PCA_COMPONENTS, min(n_samples - 1, n_features))
        self.pca = PCA(n_components=n_components, random_state=42)
        print(f"   Modo: Fixo ({n_components} componentes)")
    
    # CRÃTICO: fit_transform apenas no treino, transform no teste
    X_train_scaled = self.pca.fit_transform(X_train_scaled)  # âœ… Aprende componentes
    X_test_scaled = self.pca.transform(X_test_scaled)  # âœ… Usa componentes aprendidos
    
    n_features_after_pca = X_train_scaled.shape[1]
    reduction = ((n_features - n_features_after_pca) / n_features) * 100
    estimated_mem_after_gb = (n_samples * n_features_after_pca * 8) / (1024**3)
    print(f"   Features apÃ³s PCA: {n_features_after_pca:,} ({reduction:.1f}% reduÃ§Ã£o)")
    print(f"   MemÃ³ria estimada apÃ³s PCA: {estimated_mem_after_gb:.2f} GB")
    
    if hasattr(self.pca, 'explained_variance_ratio_'):
        total_variance = self.pca.explained_variance_ratio_.sum()
        print(f"   VariÃ¢ncia explicada: {total_variance:.2%}")
```

**ReduÃ§Ã£o**: 12,288 features â†’ 500 componentes (96% reduÃ§Ã£o adicional!)

**Total**: 150,528 features â†’ 500 componentes = **99.67% de reduÃ§Ã£o!**

---

**SoluÃ§Ã£o 3.1.3: LinearSVC como Alternativa** (linha 104 em `config.py`, linha 248-280 em `classic.py`):
```python
# src/config.py - NOVA CONFIGURAÃ‡ÃƒO (linha 104):
CLASSIC_USE_LINEAR_SVM = False  # False = SVC (kernels), True = LinearSVC (sÃ³ linear, mais eficiente)
```

**ImplementaÃ§Ã£o em classic.py (linha 248-280)**:
```python
# src/pipelines/classic.py - NOVO CÃ“DIGO (linha 248-280):
use_linear_svm = CLASSIC_USE_LINEAR_SVM
if use_linear_svm:
    print(f"   Tipo: LinearSVC (kernel linear, mais eficiente em memÃ³ria)")
else:
    print(f"   Tipo: SVC (suporta kernels nÃ£o-lineares, mas usa mais memÃ³ria)")

if use_random_search:
    if use_linear_svm:
        # LinearSVC: apenas kernel linear, menos parÃ¢metros
        param_distributions = {
            'C': loguniform(0.01, 100),
            'loss': ['hinge', 'squared_hinge'],
            'class_weight': [None, 'balanced'],
            'dual': [True, False]  # False pode ser mais rÃ¡pido para n_samples > n_features
        }
        svm = LinearSVC(random_state=42, max_iter=2000)
    else:
        # SVC tradicional: mÃºltiplos kernels
        param_distributions = {
            'C': loguniform(0.01, 100),
            'gamma': loguniform(0.0001, 1),
            'kernel': ['rbf', 'linear', 'poly'],
            'degree': randint(2, 5),
            'class_weight': [None, 'balanced']
        }
        svm = SVC(random_state=42)
```

**BenefÃ­cio**: LinearSVC nÃ£o calcula matriz Gram, economizando 70-90% de memÃ³ria adicional

---

**SoluÃ§Ã£o 3.1.4: LimitaÃ§Ã£o de Amostras** (linha 105 em `config.py`, linha 127-133 em `classic.py`):
```python
# src/config.py - NOVA CONFIGURAÃ‡ÃƒO (linha 105):
CLASSIC_MAX_SAMPLES = None  # None = usar todas, ou nÃºmero mÃ¡ximo (ex: 10000)
```

**ImplementaÃ§Ã£o em classic.py (linha 127-133)**:
```python
# src/pipelines/classic.py - NOVO CÃ“DIGO (linha 127-133):
# Limitar nÃºmero de amostras se configurado
if CLASSIC_MAX_SAMPLES is not None and len(X_train) > CLASSIC_MAX_SAMPLES:
    print(f"\n  AVISO: Limitando amostras de treinamento de {len(X_train)} para {CLASSIC_MAX_SAMPLES}")
    indices = np.random.choice(len(X_train), CLASSIC_MAX_SAMPLES, replace=False)
    X_train = X_train[indices]
    y_train = y_train[indices]
    print(f"   Amostras selecionadas aleatoriamente mantendo proporÃ§Ã£o de classes")
```

---

**SoluÃ§Ã£o 3.1.5: ConfiguraÃ§Ãµes de CV e ParalelizaÃ§Ã£o** (linhas 106-108 em `config.py`):
```python
# src/config.py - NOVAS CONFIGURAÃ‡Ã•ES (linhas 106-108):
CLASSIC_SVM_N_JOBS = 1  # 1 = sem paralelizaÃ§Ã£o (economiza memÃ³ria), -1 = todos os cores
CLASSIC_RF_N_JOBS = -1  # Random Forest pode usar mais cores (mais eficiente)
CLASSIC_CV_FOLDS = 2  # 2 ao invÃ©s de 3 para economizar memÃ³ria - aplica-se a TODOS os modelos clÃ¡ssicos
```

**ImplementaÃ§Ã£o em classic.py - SVM (linha 244, 282-285)**:
```python
# src/pipelines/classic.py - NOVO CÃ“DIGO (linha 244):
svm_n_jobs = CLASSIC_SVM_N_JOBS if CLASSIC_SVM_N_JOBS is not None else 1
print(f"\n   ParalelizaÃ§Ã£o SVM: {svm_n_jobs} job(s) (configurado para economizar memÃ³ria)")

# Linha 282-285:
random_search = RandomizedSearchCV(
    svm, param_distributions, n_iter=n_iter, cv=CLASSIC_CV_FOLDS,  # âœ… CV configurÃ¡vel
    scoring='accuracy', n_jobs=svm_n_jobs, verbose=1, random_state=42  # âœ… n_jobs configurÃ¡vel
)
```

**ImplementaÃ§Ã£o em classic.py - Random Forest (linha 420-443)**:
```python
# src/pipelines/classic.py - NOVO CÃ“DIGO (linha 420-443):
# Determinar jobs para Random Forest (pode usar mais paralelizaÃ§Ã£o que SVM)
rf_n_jobs = CLASSIC_RF_N_JOBS if CLASSIC_RF_N_JOBS is not None else self.n_jobs
if rf_n_jobs == -1:
    actual_jobs = self.num_cores
else:
    actual_jobs = rf_n_jobs
print(f"   ParalelizaÃ§Ã£o: {actual_jobs} job(s) paralelo(s) (Random Forest pode usar mais cores eficientemente)")

# ...
rf = RandomForestClassifier(random_state=42, n_jobs=rf_n_jobs)  # âœ… n_jobs especÃ­fico para RF
random_search = RandomizedSearchCV(
    rf, param_distributions, n_iter=n_iter, cv=CLASSIC_CV_FOLDS,  # âœ… CV configurÃ¡vel
    scoring='accuracy', n_jobs=rf_n_jobs, verbose=1, random_state=42  # âœ… n_jobs especÃ­fico
)
```

**ReduÃ§Ã£o de MemÃ³ria**:
- CV folds: 3 â†’ 2 = 33% menos cÃ³pias de dados
- n_jobs: -1 â†’ 1 = Sem duplicaÃ§Ã£o de dados em mÃºltiplos processos

---

**SoluÃ§Ã£o 3.1.6: VerificaÃ§Ã£o de MemÃ³ria Antes de Treinar** (linha 227-241 em `classic.py`):
```python
# src/pipelines/classic.py - NOVO CÃ“DIGO (linha 227-241):
# Verificar memÃ³ria antes de treinar
n_samples, n_features = self.X_train.shape
estimated_mem_gb = (n_samples * n_features * 8 * CLASSIC_CV_FOLDS) / (1024**3)
print(f"\n   VerificaÃ§Ã£o de memÃ³ria:")
print(f"     Amostras: {n_samples:,}")
print(f"     Features: {n_features:,}")
print(f"     MemÃ³ria estimada para treinamento: ~{estimated_mem_gb:.2f} GB")

if not check_available_memory(estimated_mem_gb, safety_margin=0.3):
    print(f"      AVISO: MemÃ³ria estimada pode exceder disponÃ­vel!")
    print(f"     RecomendaÃ§Ãµes:")
    print(f"       - Reduzir CLASSIC_MAX_SAMPLES em config.py")
    print(f"       - Ativar CLASSIC_USE_PCA = True")
    print(f"       - Usar CLASSIC_USE_LINEAR_SVM = True")
    print(f"       - Reduzir CLASSIC_CV_FOLDS para 2")
```

**FunÃ§Ã£o check_available_memory em src/memory.py**:
```python
# src/memory.py - FunÃ§Ã£o implementada:
def check_available_memory(required_gb, safety_margin=0.2):
    """
    Verifica se hÃ¡ memÃ³ria disponÃ­vel suficiente
    
    Args:
        required_gb: MemÃ³ria necessÃ¡ria em GB
        safety_margin: Margem de seguranÃ§a (padrÃ£o: 20%)
    
    Returns:
        bool: True se hÃ¡ memÃ³ria suficiente
    """
    memory = psutil.virtual_memory()
    available_gb = memory.available / (1024 ** 3)
    required_with_margin = required_gb * (1 + safety_margin)
    
    return available_gb >= required_with_margin
```

**Resultado Final das OtimizaÃ§Ãµes SVM**:
- **Antes**: ~15-20 GB necessÃ¡rios
- **Depois**: ~1-2 GB necessÃ¡rios
- **ReduÃ§Ã£o**: ~90-95% de memÃ³ria economizada! âœ…

---

#### **Fase 4: Estouro de MemÃ³ria - ResNet50**

**Problema 4.1: Estouro de MemÃ³ria no ResNet50**
- **Erro**: `RuntimeError: CUDA out of memory` durante Random Search do ResNet50
- **Causa**: Modelos acumulando na GPU entre iteraÃ§Ãµes do Random Search + batch sizes grandes
- **AnÃ¡lise do Problema**:

```
ANTES (Problema):
- ResNet50: ~25 milhÃµes de parÃ¢metros
- Batch size: [16, 32, 64] testados
- Imagens: 224x224x3
- Por batch (size 32): ~850 MB de GPU
- Sem limpeza entre iteraÃ§Ãµes: MÃºltiplos modelos acumulados
- Cache CUDA nÃ£o limpo: MemÃ³ria fragmentada
- TOTAL: 8 GB GPU insuficiente apÃ³s algumas iteraÃ§Ãµes!
```

- **SoluÃ§Ãµes Implementadas**:

**SoluÃ§Ã£o 4.1.1: ConfiguraÃ§Ãµes EspecÃ­ficas para ResNet50** (linhas 84-95 em `config.py`):
```python
# src/config.py - NOVAS CONFIGURAÃ‡Ã•ES (linhas 84-95):
# Batch sizes para Random Search do ResNet50 (REDUZIDOS)
RESNET50_BATCH_SIZES = [8, 16, 32]  # Era [16, 32, 64] - 50% menor

# Batch size padrÃ£o para ResNet50
RESNET50_DEFAULT_BATCH_SIZE = 16  # Era 32 - 50% menor

# Ã‰pocas para Random Search (limitadas)
RESNET50_SEARCH_EPOCHS = 10  # NÃºmero mÃ¡ximo de Ã©pocas durante Random Search

# Limpar memÃ³ria entre iteraÃ§Ãµes (CRÃTICO)
RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True  # IMPORTANTE: Limpar entre iteraÃ§Ãµes
```

---

**SoluÃ§Ã£o 4.1.2: Limpeza de MemÃ³ria Entre IteraÃ§Ãµes** (linhas 1098-1145 em `deep_learning.py`):
```python
# src/pipelines/deep_learning.py - NOVO CÃ“DIGO (linhas 1098-1145):
if use_random_search:
    print(f"\nExecutando Random Search ({n_iter} iteraÃ§Ãµes)...")
    print(f"  Batch sizes testados: {RESNET50_BATCH_SIZES}")
    print(f"  Ã‰pocas por iteraÃ§Ã£o: {RESNET50_SEARCH_EPOCHS}")
    print(f"  Limpeza de memÃ³ria entre iteraÃ§Ãµes: {'Ativada' if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS else 'Desativada'}")
    
    for i in range(n_iter):
        # Limpar ANTES de cada iteraÃ§Ã£o
        if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS:
            clear_memory(clear_gpu=True)  # âœ… Limpa cache CUDA
        
        train_loader, val_loader, _ = self.create_dataloaders(
            params['batch_size'], val_split=0.2
        )
        
        model = self.create_resnet_model(unfreeze_layers=params['unfreeze_layers'])
        
        try:
            val_acc, trained_model, iter_time = self.train_single_config(...)
            # ... processamento ...
        except RuntimeError as e:
            if 'out of memory' in str(e).lower():
                print(f"    [ERRO] Estouro de memÃ³ria na iteraÃ§Ã£o {i+1}!")
                clear_memory(clear_gpu=True)
                
                # Tentar com batch size menor
                if params['batch_size'] > min(RESNET50_BATCH_SIZES):
                    params['batch_size'] = params['batch_size'] // 2
                    continue
        finally:
            # Limpar APÃ“S cada iteraÃ§Ã£o (CRÃTICO)
            if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS:
                # Mover modelo para CPU antes de deletar
                if 'trained_model' in locals():
                    trained_model = trained_model.cpu()
                if 'model' in locals():
                    model = model.cpu()
                del model, trained_model
                clear_memory(clear_gpu=True)  # âœ… Limpa cache CUDA
                
                # Mostrar status de memÃ³ria
                if torch.cuda.is_available() and self.device.type == 'cuda':
                    gpu_mem_used = torch.cuda.memory_allocated() / (1024**3)
                    print(f"    MemÃ³ria GPU apÃ³s limpeza: {gpu_mem_used:.2f} GB")
```

**FunÃ§Ã£o clear_memory em src/memory.py (linha 150-158)**:
```python
# src/memory.py - FunÃ§Ã£o implementada (linha 150-158):
def clear_memory(clear_gpu=False):
    """Limpa memÃ³ria RAM e opcionalmente GPU"""
    import gc
    gc.collect()  # Garbage collection Python
    
    # Limpar cache GPU
    if clear_gpu and TORCH_AVAILABLE and torch.cuda.is_available():
        torch.cuda.empty_cache()  # âœ… Limpa cache CUDA
        torch.cuda.synchronize()  # âœ… Sincroniza operaÃ§Ãµes
```

**Impacto**: Libera ~2-4 GB de memÃ³ria GPU entre iteraÃ§Ãµes

---

**SoluÃ§Ã£o 4.1.3: VerificaÃ§Ã£o de MemÃ³ria Antes de Carregar Modelo** (linhas 1007-1029 em `deep_learning.py`):
```python
# src/pipelines/deep_learning.py - NOVO CÃ“DIGO (linhas 1007-1029):
# Verificar memÃ³ria disponÃ­vel antes de carregar modelo grande
print(f"\n   Verificando memÃ³ria antes de carregar ResNet50...")
ram_used, ram_total, ram_percent = self.memory_monitor.get_ram_usage()
print(f"     RAM: {ram_used:.2f} GB / {ram_total:.2f} GB ({ram_percent*100:.1f}%)")

if torch.cuda.is_available() and self.device.type == 'cuda':
    gpu_mem_used = torch.cuda.memory_allocated() / (1024**3)
    gpu_mem_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)
    gpu_mem_percent = (gpu_mem_used / gpu_mem_total) * 100 if gpu_mem_total > 0 else 0
    print(f"     GPU: {gpu_mem_used:.2f} GB / {gpu_mem_total:.2f} GB ({gpu_mem_percent:.1f}%)")
    
    # Aviso se memÃ³ria GPU estiver alta
    if gpu_mem_percent > 80:
        print(f"     [AVISO] MemÃ³ria GPU alta! Limpando cache...")
        clear_memory(clear_gpu=True)

# Aviso se RAM estiver alta
if ram_percent > MEMORY_WARNING_THRESHOLD:
    print(f"     [AVISO] MemÃ³ria RAM alta ({ram_percent*100:.1f}%)! Limpando memÃ³ria...")
    clear_memory(clear_gpu=False)

# Limpar memÃ³ria antes de carregar modelo
clear_memory(clear_gpu=True)
```

**Impacto**: Previne estouros antecipadamente

---

**SoluÃ§Ã£o 4.1.4: Limpeza no train_single_config** (linha 589-591 em `deep_learning.py`):
```python
# src/pipelines/deep_learning.py - NOVO CÃ“DIGO (linha 589-591):
def train_single_config(self, model, train_loader, val_loader, epochs, learning_rate, patience=5):
    # ... treinamento ...
    
    train_time = time.time() - start_time
    
    # Limpar memÃ³ria ao final (importante para Random Search)
    clear_memory(clear_gpu=True)  # âœ… Nova linha
    
    return best_val_acc, model, train_time
```

**Resultado Final das OtimizaÃ§Ãµes ResNet50**:
- **Antes**: Estouro apÃ³s 2-3 iteraÃ§Ãµes do Random Search
- **Depois**: Executa todas as 10 iteraÃ§Ãµes sem problemas
- **ReduÃ§Ã£o**: ~50% menos memÃ³ria por batch + limpeza automÃ¡tica

---

## InstalaÃ§Ã£o

### Requisitos do Sistema

- **Python**: 3.7 ou superior
- **RAM**: MÃ­nimo 8 GB (recomendado 16 GB para datasets grandes)
- **GPU**: Opcional, mas recomendado para deep learning (CUDA 11.8+)
- **EspaÃ§o em Disco**: Depende do tamanho do dataset (~1-5 GB)

### InstalaÃ§Ã£o de DependÃªncias

```bash
pip install -r requirements.txt
```

**DependÃªncias principais** (veja `requirements.txt` completo):
- `torch>=2.0.0` - PyTorch para deep learning
- `torchvision>=0.15.0` - Modelos prÃ©-treinados (ResNet50)
- `scikit-learn>=1.3.0` - SVM, Random Forest, PCA, StandardScaler
- `opencv-python>=4.8.0` - Processamento de imagens
- `matplotlib>=3.7.0`, `seaborn>=0.12.0` - VisualizaÃ§Ãµes
- `pandas>=2.0.0`, `numpy>=1.24.0` - ManipulaÃ§Ã£o de dados
- `joblib>=1.3.0` - Salvamento de modelos
- `Pillow>=10.0.0` - Processamento de imagens
- `kagglehub>=0.2.0` - Download de datasets Kaggle
- `psutil>=5.9.0` - Monitoramento de memÃ³ria
- `scipy>=1.10.0` - DistribuiÃ§Ãµes para Random Search

Ou instale manualmente:

```bash
# Core Deep Learning
pip install torch torchvision

# Machine Learning ClÃ¡ssico
pip install scikit-learn scipy

# Processamento de Imagens
pip install opencv-python Pillow

# VisualizaÃ§Ã£o e AnÃ¡lise
pip install matplotlib seaborn pandas numpy

# UtilitÃ¡rios
pip install joblib kagglehub psutil
```

### VerificaÃ§Ã£o de InstalaÃ§Ã£o

Execute os scripts de diagnÃ³stico para verificar se tudo estÃ¡ instalado corretamente:

```bash
# Verificar PyTorch e CUDA
python verificar_pytorch.py

# Verificar GPU
python check_gpu.py

# Verificar estrutura de dados
python diagnose_data.py
```

### ConfiguraÃ§Ã£o do Kaggle (Opcional)

Para usar o dataset do Kaggle automaticamente:

1. **Criar conta no Kaggle**: https://www.kaggle.com/
2. **Aceitar termos do dataset**: Acesse [AI Art vs Human Art](https://www.kaggle.com/datasets/hassnainzaidi/ai-art-vs-human-art) e aceite os termos
3. **Configurar credenciais** (opcional):
   ```bash
   # Linux/Mac
   mkdir -p ~/.kaggle
   cp kaggle.json ~/.kaggle/
   chmod 600 ~/.kaggle/kaggle.json
   
   # Windows
   # Copie kaggle.json para: C:\Users\<username>\.kaggle\kaggle.json
   ```

### ConfiguraÃ§Ã£o do Kaggle

Para usar o dataset do Kaggle, vocÃª precisa:

1. **Criar uma conta no Kaggle**: https://www.kaggle.com/
2. **Aceitar os termos do dataset**: Acesse o dataset [AI Art vs Human Art](https://www.kaggle.com/datasets/hassnainzaidi/ai-art-vs-human-art) e aceite os termos
3. **Configurar credenciais do Kaggle** (opcional, mas recomendado):
   - Baixe seu arquivo `kaggle.json` das configuraÃ§Ãµes da conta
   - Coloque em `~/.kaggle/kaggle.json` (Linux/Mac) ou `C:\Users\<username>\.kaggle\kaggle.json` (Windows)

---

## ğŸ’¾ Sistema de Salvamento de Modelos com Metadados

### Problema Identificado

O projeto nÃ£o tinha sistema unificado para salvar modelos treinados com suas mÃ©tricas e configuraÃ§Ãµes. Isso dificultava:
- Comparar modelos salvos
- Reproduzir resultados
- Entender configuraÃ§Ãµes usadas
- Carregar modelos para prediÃ§Ãµes futuras

### SoluÃ§Ã£o Implementada

**Novo mÃ³dulo criado**: `src/model_saver.py` com 3 funÃ§Ãµes principais:

#### **1. `save_model_with_metadata()` - Salva Modelo com Metadados**

**LocalizaÃ§Ã£o**: `src/model_saver.py`, linhas 11-45

**Assinatura**:
```python
def save_model_with_metadata(model, model_path, metadata, model_type='pytorch'):
    """
    Salva modelo com metadados completos
    
    Args:
        model: Modelo a ser salvo
        model_path: Caminho para salvar o modelo
        metadata: DicionÃ¡rio com metadados (mÃ©tricas, hiperparÃ¢metros, etc.)
        model_type: Tipo do modelo ('pytorch' ou 'sklearn')
    """
```

**ImplementaÃ§Ã£o para PyTorch** (linha 25-31):
```python
# src/model_saver.py - LINHA 25-31:
if model_type == 'pytorch':
    import torch
    torch.save({
        'model_state_dict': model.state_dict(),  # âœ… Salva apenas pesos (mais leve)
        'model_class': model.__class__.__name__,  # âœ… Nome da classe para reconstruÃ§Ã£o
        'metadata': metadata  # âœ… Metadados incluÃ­dos no checkpoint
    }, model_path)
```

**ImplementaÃ§Ã£o para scikit-learn** (linha 32-37):
```python
# src/model_saver.py - LINHA 32-37:
elif model_type == 'sklearn':
    import joblib
    joblib.dump({
        'model': model,  # âœ… Modelo completo
        'metadata': metadata  # âœ… Metadados incluÃ­dos
    }, model_path)
```

**Salvamento de Metadados em JSON** (linha 39-42):
```python
# src/model_saver.py - LINHA 39-42:
# Salvar metadados em JSON separado (fÃ¡cil de ler e editar)
metadata_path = model_path.with_suffix('.json')
with open(metadata_path, 'w', encoding='utf-8') as f:
    json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
```

**Uso no Pipeline ClÃ¡ssico - SVM** (linha 358-363 em `classic.py`):
```python
# src/pipelines/classic.py - LINHA 358-363:
model_path = MODELS_DIR / 'svm_model.pkl'
save_model_with_metadata(
    model=self.svm_model,
    model_path=model_path,
    metadata=metadata,
    model_type='sklearn'  # âœ… Tipo especÃ­fico para scikit-learn
)
```

**Uso no Pipeline Deep Learning - SimpleCNN** (linha 966-972 em `deep_learning.py`):
```python
# src/pipelines/deep_learning.py - LINHA 966-972:
model_path = MODELS_DIR / 'simple_cnn.pth'
save_model_with_metadata(
    model=model,
    model_path=model_path,
    metadata=metadata,
    model_type='pytorch'  # âœ… Tipo especÃ­fico para PyTorch
)
```

---

#### **2. `create_model_metadata()` - Cria DicionÃ¡rio de Metadados**

**LocalizaÃ§Ã£o**: `src/model_saver.py`, linhas 90-118

**Assinatura**:
```python
def create_model_metadata(model_name, metrics, hyperparams, training_info, class_names, model_params=None):
    """
    Cria dicionÃ¡rio de metadados para um modelo
    
    Args:
        model_name: Nome do modelo
        metrics: DicionÃ¡rio com mÃ©tricas (accuracy, precision, etc.)
        hyperparams: DicionÃ¡rio com hiperparÃ¢metros
        training_info: DicionÃ¡rio com informaÃ§Ãµes de treinamento
        class_names: Lista de nomes das classes
        model_params: ParÃ¢metros usados para inicializar a classe do modelo (para PyTorch)
    
    Returns:
        metadata: DicionÃ¡rio com metadados completos
    """
```

**Estrutura de Metadados Retornada** (linha 104-118):
```python
# src/model_saver.py - LINHA 104-118:
return {
    'model_name': model_name,  # Ex: 'SVM', 'SimpleCNN', 'ResNet50'
    'timestamp': datetime.now().isoformat(),  # âœ… Data/hora do salvamento
    'metrics': {
        'accuracy': float(metrics.get('accuracy', 0)),  # âœ… Convertido para float
        'precision': float(metrics.get('precision', 0)),
        'recall': float(metrics.get('recall', 0)),
        'f1_score': float(metrics.get('f1_score', 0))
    },
    'hyperparameters': hyperparams,  # âœ… Todos os hiperparÃ¢metros usados
    'training_info': training_info,  # âœ… InformaÃ§Ãµes detalhadas de treinamento
    'class_names': class_names,  # âœ… Nomes das classes
    'num_classes': len(class_names),  # âœ… NÃºmero de classes
    'model_params': model_params,  # âœ… ParÃ¢metros para reconstruir modelo PyTorch
    'version': '1.0'  # âœ… VersÃ£o do formato
}
```

**Exemplo de Uso - SVM** (linha 337-355 em `classic.py`):
```python
# src/pipelines/classic.py - LINHA 337-355:
metadata = create_model_metadata(
    model_name='SVM',
    metrics=metrics_test,  # âœ… MÃ©tricas calculadas
    hyperparams=best_hyperparams,  # âœ… HiperparÃ¢metros encontrados pelo Random Search
    training_info={
        'use_random_search': use_random_search,
        'n_iter': n_iter if use_random_search else 0,
        'cv_folds': CLASSIC_CV_FOLDS if use_random_search else 0,  # âœ… CV folds usados
        'pca_used': self.pca is not None,  # âœ… Se PCA foi usado
        'pca_components': self.pca.n_components if self.pca is not None else None,  # âœ… Componentes PCA
        'use_linear_svm': use_linear_svm,  # âœ… Tipo de SVM usado
        'img_size_classic': IMG_SIZE_CLASSIC,  # âœ… Tamanho de imagem
        'max_samples': CLASSIC_MAX_SAMPLES,  # âœ… Limite de amostras
        'total_time_seconds': total_time,  # âœ… Tempo de execuÃ§Ã£o
        'device': 'CPU',
        'n_jobs': svm_n_jobs  # âœ… ParalelizaÃ§Ã£o usada
    },
    class_names=self.class_names  # âœ… Nomes das classes
)
```

**Exemplo de Uso - SimpleCNN** (linha 940-963 em `deep_learning.py`):
```python
# src/pipelines/deep_learning.py - LINHA 940-963:
metadata = create_model_metadata(
    model_name='SimpleCNN',
    metrics=metrics,
    hyperparams={
        'learning_rate': best_params['learning_rate'],
        'batch_size': best_params['batch_size'],
        'dropout_rate': best_params['dropout_rate'],
        'hidden_units': best_params['hidden_units'],
        'num_classes': self.num_classes
    },
    training_info={
        'use_random_search': use_random_search,
        'n_iter': n_iter if use_random_search else 0,
        'final_epochs': final_epochs,
        'random_search_time': random_search_time,  # âœ… Tempo de Random Search
        'final_train_time': final_train_time,  # âœ… Tempo de treinamento final
        'total_time': total_time,  # âœ… Tempo total
        'device': str(self.device),  # âœ… Dispositivo usado (GPU/CPU)
        'use_augmentation': USE_AUGMENTATION,  # âœ… Data augmentation usado
        'transfer_learning': False  # âœ… Se usou transfer learning
    },
    class_names=self.class_names,
    model_params={  # âœ… ParÃ¢metros para reconstruir modelo
        'num_classes': self.num_classes,
        'dropout_rate': best_params['dropout_rate'],
        'hidden_units': best_params['hidden_units']
    }
)
```

---

#### **3. `load_model_with_metadata()` - Carrega Modelo com Metadados**

**LocalizaÃ§Ã£o**: `src/model_saver.py`, linhas 48-87

**Assinatura**:
```python
def load_model_with_metadata(model_path, model_type='pytorch', model_class=None):
    """
    Carrega modelo com metadados
    
    Args:
        model_path: Caminho do modelo salvo
        model_type: Tipo do modelo ('pytorch' ou 'sklearn')
        model_class: Classe do modelo (necessÃ¡rio para PyTorch)
    
    Returns:
        model: Modelo carregado
        metadata: DicionÃ¡rio com metadados
    """
```

**ImplementaÃ§Ã£o para PyTorch** (linha 66-79):
```python
# src/model_saver.py - LINHA 66-79:
if model_type == 'pytorch':
    import torch
    checkpoint = torch.load(model_path, map_location='cpu')  # âœ… Carrega na CPU primeiro
    
    if model_class is None:
        raise ValueError("model_class Ã© necessÃ¡rio para carregar modelos PyTorch")
    
    # Recriar modelo com metadados
    metadata = checkpoint.get('metadata', {})  # âœ… Extrai metadados
    model = model_class(**metadata.get('model_params', {}))  # âœ… ReconstrÃ³i modelo
    model.load_state_dict(checkpoint['model_state_dict'])  # âœ… Carrega pesos
    model.eval()  # âœ… Modo avaliaÃ§Ã£o
    
    return model, metadata
```

**ImplementaÃ§Ã£o para scikit-learn** (linha 81-84):
```python
# src/model_saver.py - LINHA 81-84:
elif model_type == 'sklearn':
    import joblib
    data = joblib.load(model_path)
    return data['model'], data.get('metadata', {})  # âœ… Retorna modelo e metadados
```

**Exemplo de Uso - Carregar SVM** (arquivo `scripts/load_model_example.py`):
```python
# scripts/load_model_example.py - EXEMPLO:
from src.model_saver import load_model_with_metadata

# Carregar modelo SVM
svm_model, metadata = load_model_with_metadata(
    model_path='outputs/models/svm_model.pkl',
    model_type='sklearn'
)

print(f"Modelo: {metadata['model_name']}")
print(f"AcurÃ¡cia: {metadata['metrics']['accuracy']:.4f}")
print(f"HiperparÃ¢metros: {metadata['hyperparameters']}")
print(f"Data de treinamento: {metadata['timestamp']}")
```

**Exemplo de Uso - Carregar SimpleCNN** (arquivo `scripts/load_model_example.py`):
```python
# scripts/load_model_example.py - EXEMPLO:
from src.model_saver import load_model_with_metadata
from src.models import SimpleCNN

# Carregar modelo SimpleCNN
model, metadata = load_model_with_metadata(
    model_path='outputs/models/simple_cnn.pth',
    model_type='pytorch',
    model_class=SimpleCNN  # âœ… NecessÃ¡rio para reconstruir modelo
)

print(f"Modelo: {metadata['model_name']}")
print(f"AcurÃ¡cia: {metadata['metrics']['accuracy']:.4f}")
print(f"Device usado: {metadata['training_info']['device']}")
```

---

### Estrutura de Arquivos Salvos

ApÃ³s treinar modelos, vocÃª terÃ¡:

```
outputs/models/
â”œâ”€â”€ svm_model.pkl              # Modelo SVM (joblib)
â”œâ”€â”€ svm_model.json             # Metadados do SVM
â”œâ”€â”€ svm_scaler.pkl             # Scaler usado no SVM
â”œâ”€â”€ random_forest_model.pkl    # Modelo Random Forest
â”œâ”€â”€ random_forest_model.json   # Metadados do Random Forest
â”œâ”€â”€ simple_cnn.pth             # Modelo SimpleCNN (PyTorch)
â”œâ”€â”€ simple_cnn.json            # Metadados do SimpleCNN
â”œâ”€â”€ resnet50_transfer.pth      # Modelo ResNet50 (PyTorch)
â””â”€â”€ resnet50_transfer.json     # Metadados do ResNet50
```

**Exemplo de arquivo JSON de metadados** (`svm_model.json`):
```json
{
  "model_name": "SVM",
  "timestamp": "2024-01-15T10:30:45.123456",
  "metrics": {
    "accuracy": 0.8542,
    "precision": 0.8520,
    "recall": 0.8542,
    "f1_score": 0.8531
  },
  "hyperparameters": {
    "C": 1.23,
    "gamma": 0.045,
    "kernel": "rbf",
    "degree": 3,
    "class_weight": "balanced"
  },
  "training_info": {
    "use_random_search": true,
    "n_iter": 50,
    "cv_folds": 2,
    "pca_used": true,
    "pca_components": 500,
    "use_linear_svm": false,
    "img_size_classic": [64, 64],
    "max_samples": null,
    "total_time_seconds": 932.45,
    "device": "CPU",
    "n_jobs": 1
  },
  "class_names": ["aiartdata", "realart"],
  "num_classes": 2,
  "version": "1.0"
}
```

---

## ConfiguraÃ§Ã£o

#### OpÃ§Ã£o 1: Usar Dataset do Kaggle (Recomendado)

O projeto estÃ¡ configurado para usar o dataset **AI Art vs Human Art** do Kaggle:

```bash
# Baixar e organizar o dataset automaticamente
python download_dataset.py
```

O script irÃ¡:
- Baixar o dataset do Kaggle automaticamente
- Explorar a estrutura do dataset
- Organizar os dados em `data/train/` e `data/test/`
- Dividir automaticamente em 70% treino e 30% teste

**Nota**: Certifique-se de ter aceitado os termos do dataset no Kaggle antes de executar.

#### OpÃ§Ã£o 2: Organizar Dados Manualmente

Se preferir usar seus prÃ³prios dados, organize no formato:
   ```
   data/
     train/
       classe1/
         img1.jpg
         img2.jpg
       classe2/
         img1.jpg
     test/
       classe1/
       classe2/
   ```

#### ConfiguraÃ§Ãµes do `config.py`:

- `USE_GPU`: True para usar GPU, False para CPU
- `USE_KAGGLE_DATASET`: True para usar dataset do Kaggle (padrÃ£o: True)
- `KAGGLE_DATASET`: Nome do dataset no formato "usuario/dataset"
- `TRAIN_SPLIT`: ProporÃ§Ã£o de dados para treinamento (padrÃ£o: 0.7)
- `TEST_SPLIT`: ProporÃ§Ã£o de dados para teste (padrÃ£o: 0.3)
- `BATCH_SIZE`: Tamanho do batch (padrÃ£o: 32)
- `EPOCHS`: NÃºmero de Ã©pocas (padrÃ£o: 50)
- `USE_AUGMENTATION`: Ativar data augmentation

## Uso

### Passo 1: Baixar o Dataset (se necessÃ¡rio)

Se vocÃª ainda nÃ£o tem os dados organizados:

```bash
python scripts/download_dataset.py
```

O script irÃ¡ baixar e organizar automaticamente o dataset do Kaggle.

### Passo 2: Executar o Projeto

Execute o script principal:

```bash
python main.py
```

Se os dados nÃ£o estiverem organizados, o script oferecerÃ¡ a opÃ§Ã£o de baixar automaticamente.

Escolha uma das opÃ§Ãµes:
1. Pipeline ClÃ¡ssico (SVM + Random Forest)
2. Pipeline Deep Learning (CNN + ResNet)
3. Ambos os pipelines
4. Sair

## ContextualizaÃ§Ã£o da Base de Dados

### Dataset: AI Art vs Human Art

Este projeto utiliza o dataset **AI Art vs Human Art** do Kaggle, que contÃ©m imagens classificadas em duas categorias:

- **AI Art**: Arte gerada por inteligÃªncia artificial
- **Human Art**: Arte criada por humanos

**Link do Dataset**: https://www.kaggle.com/datasets/hassnainzaidi/ai-art-vs-human-art

### DescriÃ§Ã£o dos Dados

A base de dados Ã© organizada automaticamente em diretÃ³rios por classe. O sistema detecta automaticamente:

- **Quantidade de imagens**: Contadas automaticamente durante o carregamento
- **Tamanho das imagens**: ConfigurÃ¡vel em `config.py` (padrÃ£o: 224x224 pixels)
- **Canais**: RGB (3 canais)
- **Quantidade de classes**: Detectada automaticamente a partir dos diretÃ³rios
- **DivisÃ£o treino/teste**: 70% treino, 30% teste (configurÃ¡vel)

### CaracterÃ­sticas do Dataset

O dataset **AI Art vs Human Art** contÃ©m:
- **Total de arquivos**: ~975 imagens
- **Formatos**: JPG (763), PNG (150), JPEG (57), outros (5)
- **Classes**: 
  - AiArtData: ~539 imagens (55%)
  - RealArt: ~436 imagens (45%)
- **Desbalanceamento**: Leve desbalanceamento (~20% de diferenÃ§a)

### PadronizaÃ§Ã£o de Imagens

O projeto implementa **padronizaÃ§Ã£o completa** de imagens para garantir consistÃªncia e qualidade dos dados:

#### 1. **Tratamento de MÃºltiplos Formatos** âœ…
- Suporta automaticamente: JPG, JPEG, PNG, BMP, GIF
- ConversÃ£o uniforme para formato interno
- Tratamento especÃ­fico para cada tipo de arquivo

#### 2. **PadronizaÃ§Ã£o de Canais de Cor** âœ…
- **ConversÃ£o para RGB**: Todas as imagens sÃ£o convertidas para RGB (3 canais)
- **RemoÃ§Ã£o de Alpha Channel**: PNGs com transparÃªncia sÃ£o convertidos com fundo branco
- **ConversÃ£o Grayscale**: Imagens em escala de cinza sÃ£o convertidas para RGB
- **ValidaÃ§Ã£o**: Garante que todas as imagens tenham exatamente 3 canais

#### 3. **CorreÃ§Ã£o de OrientaÃ§Ã£o EXIF** âœ…
- **CorreÃ§Ã£o AutomÃ¡tica**: Aplica correÃ§Ã£o de orientaÃ§Ã£o baseada em metadados EXIF
- **Importante para Arte**: Evita que imagens apareÃ§am rotacionadas incorretamente
- **Transparente**: Processo automÃ¡tico, sem intervenÃ§Ã£o manual

#### 4. **Redimensionamento Inteligente** âœ…
- **Tamanho PadrÃ£o**: Todas as imagens sÃ£o redimensionadas para 224x224 pixels
- **InterpolaÃ§Ã£o de Alta Qualidade**: Usa `INTER_AREA` do OpenCV (melhor para downscaling)
- **ValidaÃ§Ã£o de DimensÃµes**: Rejeita imagens muito pequenas (< 32x32 pixels)

#### 5. **ValidaÃ§Ã£o e Tratamento de Erros** âœ…
- **DetecÃ§Ã£o de Imagens Corrompidas**: Identifica e trata arquivos invÃ¡lidos
- **ValidaÃ§Ã£o de Qualidade**: Verifica dimensÃµes mÃ­nimas e formato vÃ¡lido
- **Logging Detalhado**: RelatÃ³rio completo de problemas encontrados
- **Continuidade**: Processo nÃ£o Ã© interrompido por imagens problemÃ¡ticas

#### 6. **RelatÃ³rio de EstatÃ­sticas** âœ…

Ao carregar as imagens, o sistema exibe um relatÃ³rio detalhado:

```
============================================================
ESTATÃSTICAS DE CARREGAMENTO DE IMAGENS
============================================================
Total de arquivos processados: 975
Imagens carregadas com sucesso: 970
Erros encontrados: 5

Formatos encontrados:
  .jpg: 763
  .jpeg: 57
  .png: 150

Imagens em escala de cinza convertidas: X
Canais alpha removidos: Y
OrientaÃ§Ãµes EXIF corrigidas: Z
============================================================
```

#### 7. **NormalizaÃ§Ã£o de Valores** âœ…

**Para Pipeline ClÃ¡ssico:**
- NormalizaÃ§Ã£o para [0, 1]: DivisÃ£o por 255
- PadronizaÃ§Ã£o: StandardScaler (mÃ©dia 0, desvio padrÃ£o 1)

**Para Pipeline Deep Learning:**
- NormalizaÃ§Ã£o ImageNet: 
  - Mean: [0.485, 0.456, 0.406]
  - Std: [0.229, 0.224, 0.225]
- ConversÃ£o para Tensor: Valores normalizados para treinamento

### BenefÃ­cios da PadronizaÃ§Ã£o

1. **ConsistÃªncia**: Todas as imagens tÃªm o mesmo formato e tamanho
2. **Qualidade**: Melhor performance dos modelos com dados padronizados
3. **Robustez**: Tratamento automÃ¡tico de diferentes formatos e problemas
4. **TransparÃªncia**: RelatÃ³rios detalhados sobre o processamento
5. **Confiabilidade**: ValidaÃ§Ã£o garante que apenas imagens vÃ¡lidas sÃ£o usadas

### Estrutura ApÃ³s Download

ApÃ³s executar `download_dataset.py`, a estrutura serÃ¡:

```
data/
  train/
    ai_art/        (70% das imagens de arte IA)
    human_art/     (70% das imagens de arte humana)
  test/
    ai_art/        (30% das imagens de arte IA)
    human_art/     (30% das imagens de arte humana)
```

O cÃ³digo imprime automaticamente:
- NÃºmero de amostras de treinamento
- NÃºmero de amostras de teste
- Tamanho das imagens
- NÃºmero de canais
- Nomes das classes

---

## ğŸ” Random Search Otimizado - Como Funciona em Todos os Modelos

### VisÃ£o Geral

O Random Search foi **otimizado** para economizar memÃ³ria mantendo a qualidade da busca de hiperparÃ¢metros. Esta seÃ§Ã£o explica **EXATAMENTE** como funciona em cada modelo.

### ConfiguraÃ§Ã£o Global do Random Search

**LocalizaÃ§Ã£o**: `src/config.py`, linha 108

```python
# src/config.py - LINHA 108:
CLASSIC_CV_FOLDS = 2  # NÃºmero de folds para validaÃ§Ã£o cruzada
# Aplica-se a TODOS os modelos clÃ¡ssicos (SVM E Random Forest)
```

**Antes**: `cv=3` (fixo no cÃ³digo)  
**Depois**: `cv=CLASSIC_CV_FOLDS` (configurÃ¡vel, padrÃ£o: 2)  
**ReduÃ§Ã£o de memÃ³ria**: ~33% (2 folds vs 3 folds)

---

### Random Search no SVM

#### **ConfiguraÃ§Ãµes EspecÃ­ficas**

**LocalizaÃ§Ã£o**: `src/config.py`, linhas 106-107

```python
# src/config.py - LINHAS 106-107:
CLASSIC_SVM_N_JOBS = 1  # Jobs paralelos para SVM (1 = sem paralelizaÃ§Ã£o)
CLASSIC_USE_LINEAR_SVM = False  # False = SVC (kernels), True = LinearSVC (sÃ³ linear)
```

#### **ImplementaÃ§Ã£o Completa**

**LocalizaÃ§Ã£o**: `src/pipelines/classic.py`, funÃ§Ã£o `train_svm()`, linhas 257-294

**CÃ³digo Completo do Random Search para SVM**:
```python
# src/pipelines/classic.py - LINHAS 257-294:
if use_random_search:
    print(f"\n   Otimizando hiperparÃ¢metros com Random Search ({n_iter} iteraÃ§Ãµes)...")
    print(f"   CV folds: {CLASSIC_CV_FOLDS} (reduzido para economizar memÃ³ria)")
    search_start = time.time()
    
    if use_linear_svm:
        # LinearSVC: apenas kernel linear, menos parÃ¢metros
        param_distributions = {
            'C': loguniform(0.01, 100),           # DistribuiÃ§Ã£o log-uniform
            'loss': ['hinge', 'squared_hinge'],   # FunÃ§Ãµes de perda
            'class_weight': [None, 'balanced'],   # Balanceamento de classes
            'dual': [True, False]                 # Forma dual ou primal
        }
        svm = LinearSVC(random_state=42, max_iter=2000)
    else:
        # SVC tradicional: mÃºltiplos kernels
        param_distributions = {
            'C': loguniform(0.01, 100),           # ParÃ¢metro de regularizaÃ§Ã£o
            'gamma': loguniform(0.0001, 1),       # Para kernels RBF e poly
            'kernel': ['rbf', 'linear', 'poly'],  # Tipo de kernel
            'degree': randint(2, 5),              # Para kernel poly (grau 2, 3 ou 4)
            'class_weight': [None, 'balanced']    # Balanceamento de classes
        }
        svm = SVC(random_state=42)
    
    # CRÃTICO: CV_FOLDS configurÃ¡vel e n_jobs especÃ­fico para SVM
    random_search = RandomizedSearchCV(
        svm, param_distributions, 
        n_iter=n_iter,                          # âœ… NÃºmero de iteraÃ§Ãµes (padrÃ£o: 50)
        cv=CLASSIC_CV_FOLDS,                    # âœ… CV folds configurÃ¡vel (padrÃ£o: 2)
        scoring='accuracy',                      # MÃ©trica de avaliaÃ§Ã£o
        n_jobs=svm_n_jobs,                      # âœ… ParalelizaÃ§Ã£o configurÃ¡vel (padrÃ£o: 1)
        verbose=1,                              # Mostrar progresso
        random_state=42                         # Reproduzibilidade
    )
    random_search.fit(self.X_train, self.y_train)  # âœ… Treina com todos os dados
    
    search_time = time.time() - search_start
    search_time_str = str(timedelta(seconds=int(search_time)))
    
    self.svm_model = random_search.best_estimator_  # âœ… Melhor modelo encontrado
    print(f"Melhores parÃ¢metros: {random_search.best_params_}")
    print(f"Melhor score (CV): {random_search.best_score_:.4f}")
    print(f"Tempo de Random Search: {search_time_str} ({search_time:.2f} segundos)")
```

**Fluxo Completo**:
1. **Define espaÃ§o de parÃ¢metros**: DistribuiÃ§Ãµes log-uniform, uniform ou listas discretas
2. **Cria RandomizedSearchCV**: Com `n_iter` iteraÃ§Ãµes, `cv=CLASSIC_CV_FOLDS` folds, `n_jobs=svm_n_jobs`
3. **Executa busca**: Para cada iteraÃ§Ã£o, seleciona parÃ¢metros aleatÃ³rios e avalia com CV
4. **Total de fits**: `n_iter Ã— cv_folds` (ex: 50 Ã— 2 = 100 fits)
5. **Retorna melhor modelo**: `best_estimator_` com melhores hiperparÃ¢metros encontrados

**MemÃ³ria Usada**:
- **Por fold**: Uma cÃ³pia dos dados transformados (apÃ³s PCA)
- **Com PCA ativo**: ~500 features Ã— n_samples Ã— 8 bytes = muito menor!
- **Sem paralelizaÃ§Ã£o** (`n_jobs=1`): Uma cÃ³pia por vez
- **Total estimado**: ~1-2 GB (vs ~15-20 GB antes das otimizaÃ§Ãµes)

---

### Random Search no Random Forest

#### **ConfiguraÃ§Ãµes EspecÃ­ficas**

**LocalizaÃ§Ã£o**: `src/config.py`, linha 107

```python
# src/config.py - LINHA 107:
CLASSIC_RF_N_JOBS = -1  # Jobs paralelos para Random Forest (-1 = todos os cores)
# Random Forest pode usar mais paralelizaÃ§Ã£o que SVM (mais eficiente em memÃ³ria)
```

#### **ImplementaÃ§Ã£o Completa**

**LocalizaÃ§Ã£o**: `src/pipelines/classic.py`, funÃ§Ã£o `train_random_forest()`, linhas 426-453

**CÃ³digo Completo do Random Search para Random Forest**:
```python
# src/pipelines/classic.py - LINHAS 426-453:
if use_random_search:
    print(f"\n   Otimizando hiperparÃ¢metros com Random Search ({n_iter} iteraÃ§Ãµes)...")
    print(f"   CV folds: {CLASSIC_CV_FOLDS} (reduzido para economizar memÃ³ria)")
    search_start = time.time()
    
    param_distributions = {
        'n_estimators': randint(50, 300),       # NÃºmero de Ã¡rvores (50 a 299)
        'max_depth': [None, 10, 20, 30, 50],   # Profundidade mÃ¡xima
        'min_samples_split': randint(2, 20),    # Amostras mÃ­nimas para dividir (2 a 19)
        'min_samples_leaf': randint(1, 10),     # Amostras mÃ­nimas por folha (1 a 9)
        'max_features': ['sqrt', 'log2', None], # Features por split
        'bootstrap': [True, False],             # Bootstrap sampling
        'class_weight': [None, 'balanced', 'balanced_subsample']  # Balanceamento
    }
    
    # CRÃTICO: n_jobs especÃ­fico para Random Forest (pode usar mais cores)
    rf_n_jobs = CLASSIC_RF_N_JOBS if CLASSIC_RF_N_JOBS is not None else self.n_jobs
    if rf_n_jobs == -1:
        actual_jobs = self.num_cores  # âœ… Todos os cores disponÃ­veis
    else:
        actual_jobs = rf_n_jobs
    
    rf = RandomForestClassifier(random_state=42, n_jobs=rf_n_jobs)  # âœ… n_jobs especÃ­fico
    
    random_search = RandomizedSearchCV(
        rf, param_distributions, 
        n_iter=n_iter,                          # âœ… NÃºmero de iteraÃ§Ãµes (padrÃ£o: 50)
        cv=CLASSIC_CV_FOLDS,                    # âœ… CV folds configurÃ¡vel (padrÃ£o: 2)
        scoring='accuracy',
        n_jobs=rf_n_jobs,                       # âœ… ParalelizaÃ§Ã£o configurÃ¡vel (padrÃ£o: -1)
        verbose=1,
        random_state=42
    )
    random_search.fit(self.X_train, self.y_train)
    
    search_time = time.time() - search_start
    search_time_str = str(timedelta(seconds=int(search_time)))
    
    self.rf_model = random_search.best_estimator_
    print(f"Melhores parÃ¢metros: {random_search.best_params_}")
    print(f"Melhor score (CV): {random_search.best_score_:.4f}")
    print(f"Tempo de Random Search: {search_time_str} ({search_time:.2f} segundos)")
```

**DiferenÃ§as em relaÃ§Ã£o ao SVM**:
- âœ… Random Forest pode usar `n_jobs=-1` (todos os cores) porque usa memÃ³ria de forma mais eficiente
- âœ… NÃ£o precisa calcular matriz Gram como SVM
- âœ… Ãrvores independentes = paralelizaÃ§Ã£o nativa muito eficiente
- âœ… Mesmo `CLASSIC_CV_FOLDS = 2` se aplica (configuraÃ§Ã£o global)

---

### Random Search no Simple CNN (Deep Learning)

**DiferenÃ§a Importante**: Simple CNN usa **implementaÃ§Ã£o customizada** de Random Search, nÃ£o `RandomizedSearchCV` do scikit-learn.

#### **ImplementaÃ§Ã£o Customizada**

**LocalizaÃ§Ã£o**: `src/pipelines/deep_learning.py`, funÃ§Ã£o `train_simple_cnn()`, linhas 768-825

**CÃ³digo Completo do Random Search para SimpleCNN**:
```python
# src/pipelines/deep_learning.py - LINHAS 768-825:
if use_random_search:
    print(f"\nExecutando Random Search ({n_iter} iteraÃ§Ãµes)...")
    search_start_time = time.time()
    
    # EspaÃ§o de hiperparÃ¢metros
    param_space = {
        'learning_rate': (0.0001, 0.01),      # Log-uniform (distribuiÃ§Ã£o log)
        'batch_size': [16, 32, 64],           # Valores discretos
        'dropout_rate': (0.3, 0.7),           # Uniform entre 0.3 e 0.7
        'hidden_units': [256, 512, 1024]      # Valores discretos
    }
    
    best_val_acc = 0.0
    search_epochs = min(15, final_epochs)  # âœ… Limita Ã©pocas durante busca
    
    for i in range(n_iter):  # âœ… Loop manual ao invÃ©s de RandomizedSearchCV
        iter_start = time.time()
        
        # Amostrar hiperparÃ¢metros aleatoriamente
        params = sample_hyperparameters(param_space)  # âœ… FunÃ§Ã£o customizada
        
        print(f"\n  IteraÃ§Ã£o {i+1}/{n_iter}: lr={params['learning_rate']:.6f}, "
              f"batch={params['batch_size']}, dropout={params['dropout_rate']:.2f}, "
              f"hidden={params['hidden_units']}")
        
        # Criar dataloaders com batch size amostrado
        train_loader, val_loader, _ = self.create_dataloaders(
            params['batch_size'], val_split=0.2  # âœ… Split interno de validaÃ§Ã£o
        )
        
        # Criar modelo com hiperparÃ¢metros amostrados
        model = SimpleCNN(
            self.num_classes,
            dropout_rate=params['dropout_rate'],
            hidden_units=params['hidden_units']
        )
        
        # CRÃTICO: Mover modelo para GPU ANTES do treinamento
        model = model.to(self.device)
        
        # Treinar modelo com configuraÃ§Ã£o especÃ­fica
        val_acc, _, iter_time = self.train_single_config(
            model, train_loader, val_loader, search_epochs,
            params['learning_rate'], patience=5  # âœ… Early stopping
        )
        
        iter_total_time = time.time() - iter_start
        print(f"    Val Acc: {val_acc:.4f} | Tempo da iteraÃ§Ã£o: {iter_total_time:.1f}s")
        
        # Manter melhor configuraÃ§Ã£o encontrada
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_params = params.copy()
    
    random_search_time = time.time() - search_start_time
    # ... exibir resultados ...
```

**FunÃ§Ã£o `sample_hyperparameters()` - LocalizaÃ§Ã£o**: `src/pipelines/deep_learning.py`, linhas 60-86

```python
# src/pipelines/deep_learning.py - LINHAS 60-86:
def sample_hyperparameters(param_space):
    """
    Amostra aleatoriamente hiperparÃ¢metros do espaÃ§o definido
    
    Args:
        param_space: DicionÃ¡rio com espaÃ§o de hiperparÃ¢metros
            - Tuplas (min, max): Uniform ou log-uniform
            - Listas: Escolha aleatÃ³ria
    
    Returns:
        params: DicionÃ¡rio com hiperparÃ¢metros amostrados
    """
    params = {}
    for key, value in param_space.items():
        if isinstance(value, tuple) and len(value) == 2:
            if isinstance(value[0], float):
                # Log-uniform para learning rate
                if key == 'learning_rate':
                    log_low, log_high = np.log10(value[0]), np.log10(value[1])
                    params[key] = 10 ** np.random.uniform(log_low, log_high)  # âœ… Log-uniform
                else:
                    params[key] = np.random.uniform(value[0], value[1])  # âœ… Uniform
            elif isinstance(value[0], int):
                params[key] = np.random.randint(value[0], value[1] + 1)  # âœ… Randint
        elif isinstance(value, list):
            params[key] = random.choice(value)  # âœ… Escolha aleatÃ³ria de lista
        else:
            params[key] = value  # âœ… Valor fixo
    return params
```

**DiferenÃ§as da ImplementaÃ§Ã£o Customizada**:
- âœ… **NÃ£o cria mÃºltiplas cÃ³pias dos dados**: Usa lazy loading e processamento em batches
- âœ… **ValidaÃ§Ã£o split interna**: 20% dos dados de treino, nÃ£o CV folds
- âœ… **Early stopping**: Para treinamento quando nÃ£o melhora (patience=5)
- âœ… **Ã‰pocas limitadas**: `search_epochs = min(15, final_epochs)` durante busca
- âœ… **Sequencial**: Testa configuraÃ§Ãµes uma por vez (nÃ£o paralelo, mas usa GPU eficientemente)

**Por que nÃ£o precisa das mesmas otimizaÃ§Ãµes do SVM?**:
- âœ… Lazy loading: Dados carregados sob demanda (nÃ£o tudo na memÃ³ria)
- âœ… Processamento em batches: Apenas um batch por vez na GPU
- âœ… Sem CV folds: Apenas split simples de validaÃ§Ã£o
- âœ… Cada iteraÃ§Ã£o Ã© independente: Modelo deletado apÃ³s avaliaÃ§Ã£o

---

### Random Search no ResNet50 (Deep Learning)

**Mesma implementaÃ§Ã£o customizada** do SimpleCNN, mas com configuraÃ§Ãµes especÃ­ficas para ResNet50.

#### **ConfiguraÃ§Ãµes EspecÃ­ficas**

**LocalizaÃ§Ã£o**: `src/config.py`, linhas 84-95

```python
# src/config.py - LINHAS 84-95:
RESNET50_BATCH_SIZES = [8, 16, 32]  # âœ… Batch sizes reduzidos (era [16, 32, 64])
RESNET50_DEFAULT_BATCH_SIZE = 16    # âœ… PadrÃ£o reduzido (era 32)
RESNET50_SEARCH_EPOCHS = 10         # âœ… Ã‰pocas limitadas durante busca
RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True  # âœ… Limpar memÃ³ria entre iteraÃ§Ãµes
```

#### **ImplementaÃ§Ã£o com Limpeza de MemÃ³ria**

**LocalizaÃ§Ã£o**: `src/pipelines/deep_learning.py`, funÃ§Ã£o `train_resnet_transfer()`, linhas 1093-1145

**CÃ³digo Completo do Random Search para ResNet50** (com limpeza de memÃ³ria):
```python
# src/pipelines/deep_learning.py - LINHAS 1093-1145:
if use_random_search:
    print(f"\nExecutando Random Search ({n_iter} iteraÃ§Ãµes)...")
    print(f"  Batch sizes testados: {RESNET50_BATCH_SIZES}")
    print(f"  Ã‰pocas por iteraÃ§Ã£o: {RESNET50_SEARCH_EPOCHS}")
    print(f"  Limpeza de memÃ³ria entre iteraÃ§Ãµes: {'Ativada' if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS else 'Desativada'}")
    search_start_time = time.time()
    
    param_space = {
        'learning_rate': (0.00001, 0.001),   # âœ… Learning rate menor (transfer learning)
        'batch_size': RESNET50_BATCH_SIZES,  # âœ… Batch sizes configurÃ¡veis
        'unfreeze_layers': [0, 1, 2]         # âœ… Quantas camadas descongelar
    }
    
    best_val_acc = 0.0
    search_epochs = min(RESNET50_SEARCH_EPOCHS, final_epochs)  # âœ… Ã‰pocas limitadas
    
    for i in range(n_iter):
        iter_start = time.time()
        params = sample_hyperparameters(param_space)
        
        print(f"\n  IteraÃ§Ã£o {i+1}/{n_iter}: lr={params['learning_rate']:.6f}, "
              f"batch={params['batch_size']}, unfreeze={params['unfreeze_layers']}")
        
        # âœ… LIMPAR MEMÃ“RIA ANTES de cada iteraÃ§Ã£o
        if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS:
            clear_memory(clear_gpu=True)
        
        train_loader, val_loader, _ = self.create_dataloaders(
            params['batch_size'], val_split=0.2
        )
        
        # Criar modelo (jÃ¡ verifica memÃ³ria internamente)
        model = self.create_resnet_model(unfreeze_layers=params['unfreeze_layers'])
        
        try:
            val_acc, trained_model, iter_time = self.train_single_config(
                model, train_loader, val_loader, search_epochs,
                params['learning_rate'], patience=5
            )
            # ... processar resultados ...
        except RuntimeError as e:
            if 'out of memory' in str(e).lower():
                # âœ… TRATAMENTO DE ERRO: RecuperaÃ§Ã£o automÃ¡tica
                print(f"    [ERRO] Estouro de memÃ³ria na iteraÃ§Ã£o {i+1}!")
                clear_memory(clear_gpu=True)
                
                # Tentar com batch size menor
                if params['batch_size'] > min(RESNET50_BATCH_SIZES):
                    reduced_batch = max(min(RESNET50_BATCH_SIZES), params['batch_size'] // 2)
                    print(f"    Tentando com batch size reduzido: {reduced_batch}")
                    params['batch_size'] = reduced_batch
                    continue
                else:
                    print(f"    [AVISO] NÃ£o foi possÃ­vel reduzir mais o batch size. Pulando iteraÃ§Ã£o.")
                    continue
            else:
                raise
        finally:
            # âœ… CRÃTICO: LIMPAR MEMÃ“RIA APÃ“S cada iteraÃ§Ã£o
            if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS:
                # Mover modelo para CPU antes de deletar
                if 'trained_model' in locals():
                    trained_model = trained_model.cpu()
                if 'model' in locals():
                    model = model.cpu()
                del model, trained_model  # âœ… Deletar explicitamente
                clear_memory(clear_gpu=True)  # âœ… Limpar cache CUDA
                
                # Mostrar status de memÃ³ria
                if torch.cuda.is_available() and self.device.type == 'cuda':
                    gpu_mem_used = torch.cuda.memory_allocated() / (1024**3)
                    print(f"    MemÃ³ria GPU apÃ³s limpeza: {gpu_mem_used:.2f} GB")
```

**CaracterÃ­sticas Especiais do Random Search do ResNet50**:
- âœ… **Limpeza automÃ¡tica**: Antes e depois de cada iteraÃ§Ã£o
- âœ… **Tratamento de erros**: Recupera automaticamente de estouro de memÃ³ria
- âœ… **Batch size adaptativo**: Reduz automaticamente se necessÃ¡rio
- âœ… **VerificaÃ§Ã£o de memÃ³ria**: Antes de carregar modelo grande
- âœ… **Batch sizes menores**: [8, 16, 32] ao invÃ©s de [16, 32, 64]

---

### ComparaÃ§Ã£o: Random Search em Todos os Modelos

| Modelo | Tipo | ImplementaÃ§Ã£o | CV Folds | n_jobs | Limpeza MemÃ³ria | Otimizado? |
|--------|------|---------------|----------|--------|-----------------|------------|
| **SVM** | ClÃ¡ssico | RandomizedSearchCV | `CLASSIC_CV_FOLDS=2` | `CLASSIC_SVM_N_JOBS=1` | N/A (CPU) | âœ… **Sim** |
| **Random Forest** | ClÃ¡ssico | RandomizedSearchCV | `CLASSIC_CV_FOLDS=2` | `CLASSIC_RF_N_JOBS=-1` | N/A (CPU) | âœ… **Sim** |
| **Simple CNN** | Deep Learning | Customizado | Split interno (20%) | N/A (GPU) | AutomÃ¡tica | âš ï¸ **NÃ£o precisa** |
| **ResNet50** | Deep Learning | Customizado | Split interno (20%) | N/A (GPU) | **Entre iteraÃ§Ãµes** | âœ… **Sim** |

**ExplicaÃ§Ã£o**:
- âœ… Modelos clÃ¡ssicos usam `RandomizedSearchCV` do scikit-learn â†’ precisam de otimizaÃ§Ãµes de memÃ³ria
- âœ… Modelos deep learning usam implementaÃ§Ã£o customizada â†’ jÃ¡ sÃ£o eficientes (lazy loading + batches)
- âœ… ResNet50 precisa de limpeza adicional porque modelo Ã© muito grande

---

## ğŸ—ï¸ Pipeline ClÃ¡ssico - Detalhes Completos

### Modelos Implementados

#### **1. Support Vector Machine (SVM)**

**LocalizaÃ§Ã£o**: `src/pipelines/classic.py`, funÃ§Ã£o `train_svm()`, linhas 202-393

**CaracterÃ­sticas**:
- âœ… Suporta `SVC` (kernels: RBF, linear, poly) ou `LinearSVC` (apenas linear)
- âœ… OtimizaÃ§Ã£o: Random Search (50 iteraÃ§Ãµes padrÃ£o)
- âœ… ParÃ¢metros otimizados: C, gamma, kernel, degree, class_weight (SVC) ou C, loss, dual, class_weight (LinearSVC)
- âœ… ValidaÃ§Ã£o cruzada: 2 folds (configurÃ¡vel)
- âœ… ParalelizaÃ§Ã£o: 1 job (configurÃ¡vel para economizar memÃ³ria)

**Exemplo de ParÃ¢metros Otimizados** (linha 274-279):
```python
# src/pipelines/classic.py - LINHA 274-279 (SVC):
param_distributions = {
    'C': loguniform(0.01, 100),           # ParÃ¢metro de regularizaÃ§Ã£o (log-uniform)
    'gamma': loguniform(0.0001, 1),       # Para kernels RBF e poly (log-uniform)
    'kernel': ['rbf', 'linear', 'poly'],  # Tipo de kernel (escolha aleatÃ³ria)
    'degree': randint(2, 5),              # Grau do polinÃ´mio para kernel poly (2, 3 ou 4)
    'class_weight': [None, 'balanced']    # Balanceamento de classes
}
```

**Exemplo de SaÃ­da Durante Treinamento**:
```
================================================================================
TREINANDO MODELO: Support Vector Machine (SVM)
================================================================================
   Dispositivo: CPU (scikit-learn nÃ£o suporta GPU)

   VerificaÃ§Ã£o de memÃ³ria:
     Amostras: 10,000
     Features: 500 (apÃ³s PCA)
     MemÃ³ria estimada para treinamento: ~0.08 GB

   ParalelizaÃ§Ã£o SVM: 1 job(s) (configurado para economizar memÃ³ria)
   Tipo: SVC (suporta kernels nÃ£o-lineares, mas usa mais memÃ³ria)

   Otimizando hiperparÃ¢metros com Random Search (50 iteraÃ§Ãµes)...
   CV folds: 2 (reduzido para economizar memÃ³ria)

   Fitting 2 folds for each of 50 candidates, totalling 100 fits
   [Progresso: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100/100

   Melhores parÃ¢metros: {'C': 1.23, 'gamma': 0.045, 'kernel': 'rbf', 'degree': 3, 'class_weight': 'balanced'}
   Melhor score (CV): 0.8542
   Tempo de Random Search: 0:15:32 (932.45 segundos)

   PrediÃ§Ãµes - Tempo: 2.34 segundos

   AcurÃ¡cia - Treinamento: 0.8734
   AcurÃ¡cia - Teste: 0.8542
   PrecisÃ£o - Teste: 0.8520
   Recall - Teste: 0.8542
   F1-Score - Teste: 0.8531

   Tempo total de execuÃ§Ã£o: 0:15:40 (940.23 segundos)
```

#### **2. Random Forest**

**LocalizaÃ§Ã£o**: `src/pipelines/classic.py`, funÃ§Ã£o `train_random_forest()`, linhas 396-527

**CaracterÃ­sticas**:
- âœ… Ensemble de Ã¡rvores de decisÃ£o
- âœ… OtimizaÃ§Ã£o: Random Search (50 iteraÃ§Ãµes padrÃ£o)
- âœ… ParÃ¢metros otimizados: n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, bootstrap, class_weight
- âœ… ValidaÃ§Ã£o cruzada: 2 folds (configurÃ¡vel)
- âœ… ParalelizaÃ§Ã£o: -1 (todos os cores) - Random Forest usa memÃ³ria eficientemente

**Exemplo de ParÃ¢metros Otimizados** (linha 430-437):
```python
# src/pipelines/classic.py - LINHA 430-437 (Random Forest):
param_distributions = {
    'n_estimators': randint(50, 300),       # NÃºmero de Ã¡rvores (50 a 299)
    'max_depth': [None, 10, 20, 30, 50],   # Profundidade mÃ¡xima (None = sem limite)
    'min_samples_split': randint(2, 20),   # Amostras mÃ­nimas para dividir (2 a 19)
    'min_samples_leaf': randint(1, 10),    # Amostras mÃ­nimas por folha (1 a 9)
    'max_features': ['sqrt', 'log2', None], # Features por split
    'bootstrap': [True, False],            # Bootstrap sampling
    'class_weight': [None, 'balanced', 'balanced_subsample']  # Balanceamento de classes
}
```

---

### TransformaÃ§Ãµes Aplicadas no Pipeline ClÃ¡ssico

#### **1. Carregamento de Imagens com PadronizaÃ§Ã£o Completa**

**LocalizaÃ§Ã£o**: `src/utils.py`, funÃ§Ã£o `load_images_from_directory()`, linhas 128-316

**CaracterÃ­sticas Implementadas**:

**1.1. Tratamento de MÃºltiplos Formatos** (linha 175-190):
```python
# src/utils.py - LINHA 175-190:
# Suporta mÃºltiplos formatos automaticamente
image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']
images_found = list(directory.glob('*.[jJ][pP][gG]')) + \
               list(directory.glob('*.[jJ][pP][eE][gG]')) + \
               list(directory.glob('*.[pP][nN][gG]'))
```

**1.2. ConversÃ£o para RGB** (linha 200-215):
```python
# src/utils.py - LINHA 200-215:
# Converter para RGB (3 canais) - CRÃTICO para consistÃªncia
if len(image.shape) == 2:  # Grayscale
    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
elif len(image.shape) == 4:  # RGBA
    # Converter RGBA para RGB com fundo branco
    image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
elif image.shape[2] == 4:  # Alpha channel
    # Remover alpha channel
    image = image[:, :, :3]

# Garantir exatamente 3 canais
assert image.shape[2] == 3, f"Imagem deve ter 3 canais, encontrado: {image.shape[2]}"
```

**1.3. CorreÃ§Ã£o de OrientaÃ§Ã£o EXIF** (linha 195-198):
```python
# src/utils.py - LINHA 195-198:
# CorreÃ§Ã£o de orientaÃ§Ã£o EXIF (importante para arte)
pil_image = Image.fromarray(image)
pil_image = ImageOps.exif_transpose(pil_image)  # âœ… Corrige rotaÃ§Ã£o baseada em EXIF
image = np.array(pil_image)
```

**1.4. Redimensionamento Inteligente** (linha 217-220):
```python
# src/utils.py - LINHA 217-220:
# Redimensionamento para tamanho padrÃ£o
# IMPORTANTE: Usa INTER_AREA (melhor para downscaling)
image = cv2.resize(image, img_size, interpolation=cv2.INTER_AREA)
```

**1.5. ValidaÃ§Ã£o e Tratamento de Erros** (linha 222-230):
```python
# src/utils.py - LINHA 222-230:
# Validar dimensÃµes mÃ­nimas
if image.shape[0] < 32 or image.shape[1] < 32:
    warnings.warn(f"Imagem {img_path} muito pequena: {image.shape}")
    continue

# Validar formato vÃ¡lido
if image is None or image.size == 0:
    warnings.warn(f"Imagem {img_path} invÃ¡lida ou corrompida")
    continue
```

---

#### **2. PrÃ©-processamento EspecÃ­fico para Modelos ClÃ¡ssicos**

**LocalizaÃ§Ã£o**: `src/pipelines/classic.py`, funÃ§Ã£o `load_data()`, linhas 135-179

**2.1. Flatten de Imagens** (linha 137):
```python
# src/pipelines/classic.py - LINHA 137:
# FunÃ§Ã£o preprocess_images_classic em src/utils.py
X_train_flat = preprocess_images_classic(X_train)
# Transforma (n_samples, height, width, channels) em (n_samples, height*width*channels)
# Exemplo: (1000, 64, 64, 3) â†’ (1000, 12288)
```

**2.2. NormalizaÃ§Ã£o com StandardScaler** (linha 148-150):
```python
# src/pipelines/classic.py - LINHA 148-150:
# NormalizaÃ§Ã£o: MÃ©dia 0, Desvio PadrÃ£o 1
X_train_scaled = self.scaler.fit_transform(X_train_flat)  # âœ… Aprende mÃ©dia e std do treino
X_test_scaled = self.scaler.transform(X_test_flat)  # âœ… Usa mesma mÃ©dia e std (importante!)
```

**2.3. ReduÃ§Ã£o de Dimensionalidade com PCA** (linha 152-179):
```python
# src/pipelines/classic.py - LINHA 152-179:
# PCA para reduÃ§Ã£o de dimensionalidade (opcional)
self.pca = None
if CLASSIC_USE_PCA:
    print(f"\n   Aplicando PCA para reduÃ§Ã£o de dimensionalidade...")
    
    if CLASSIC_PCA_COMPONENTS is None:
        # Auto: reduzir para 95% variÃ¢ncia
        self.pca = PCA(n_components=0.95, random_state=42)
        print(f"   Modo: Auto (95% variÃ¢ncia explicada)")
    else:
        # NÃºmero fixo de componentes
        n_components = min(CLASSIC_PCA_COMPONENTS, min(n_samples - 1, n_features))
        self.pca = PCA(n_components=n_components, random_state=42)
        print(f"   Modo: Fixo ({n_components} componentes)")
    
    # CRÃTICO: fit_transform apenas no treino, transform no teste
    X_train_scaled = self.pca.fit_transform(X_train_scaled)  # âœ… Aprende componentes principais
    X_test_scaled = self.pca.transform(X_test_scaled)  # âœ… Usa componentes aprendidos (nÃ£o aprende novamente!)
    
    # Calcular e exibir estatÃ­sticas
    n_features_after_pca = X_train_scaled.shape[1]
    reduction = ((n_features - n_features_after_pca) / n_features) * 100
    estimated_mem_after_gb = (n_samples * n_features_after_pca * 8) / (1024**3)
    print(f"   Features apÃ³s PCA: {n_features_after_pca:,} ({reduction:.1f}% reduÃ§Ã£o)")
    print(f"   MemÃ³ria estimada apÃ³s PCA: {estimated_mem_after_gb:.2f} GB")
    
    if hasattr(self.pca, 'explained_variance_ratio_'):
        total_variance = self.pca.explained_variance_ratio_.sum()
        print(f"   VariÃ¢ncia explicada: {total_variance:.2%}")
```

**Por Que PCA Ã© Importante?**:
- âœ… **Reduz dimensionalidade**: 12,288 features â†’ 500 componentes (96% reduÃ§Ã£o)
- âœ… **MantÃ©m informaÃ§Ã£o**: ~98% de variÃ¢ncia explicada mantida
- âœ… **Economiza memÃ³ria**: ~98% menos memÃ³ria necessÃ¡ria
- âœ… **Acelera treinamento**: Menos features = treinamento mais rÃ¡pido
- âœ… **Melhora performance**: Remove ruÃ­do e redundÃ¢ncia

**Erro Comum Evitado**:
```python
# âŒ ERRADO (nÃ£o fazer isso):
X_test_scaled = self.pca.fit_transform(X_test_scaled)  # âŒ Erro: re-aprende componentes no teste!

# âœ… CORRETO (implementado):
X_train_scaled = self.pca.fit_transform(X_train_scaled)  # âœ… Aprende do treino
X_test_scaled = self.pca.transform(X_test_scaled)  # âœ… Usa componentes do treino
```

**Salvamento do PCA**: O PCA Ã© salvo junto com o modelo para uso em prediÃ§Ãµes futuras (linha 362-367):
```python
# src/pipelines/classic.py - LINHA 362-367:
# Salvar PCA se foi usado (importante para prediÃ§Ãµes futuras)
if self.pca is not None:
    pca_path = MODELS_DIR / 'svm_pca.pkl'
    joblib.dump(self.pca, pca_path)
    print(f"âœ… PCA salvo em: {pca_path}")
```

---

#### **3. Valores dos ParÃ¢metros Otimizados**

**SVM - SVC (Random Search - 50 iteraÃ§Ãµes padrÃ£o):**

**LocalizaÃ§Ã£o**: `src/pipelines/classic.py`, linhas 273-279

```python
# EspaÃ§o de busca para SVC (CLASSIC_USE_LINEAR_SVM = False)
param_distributions = {
    'C': loguniform(0.01, 100),           # RegularizaÃ§Ã£o: 0.01 a 100 (log-uniform)
    'gamma': loguniform(0.0001, 1),       # Kernel RBF/poly: 0.0001 a 1 (log-uniform)
    'kernel': ['rbf', 'linear', 'poly'],  # Tipo de kernel (3 opÃ§Ãµes)
    'degree': randint(2, 5),              # Grau polinomial: 2, 3 ou 4 (para kernel poly)
    'class_weight': [None, 'balanced']    # Balanceamento: None ou balanced (2 opÃ§Ãµes)
}
```

**Total de combinaÃ§Ãµes teÃ³ricas**: Infinito (distribuiÃ§Ãµes contÃ­nuas)  
**CombinaÃ§Ãµes avaliadas**: Apenas `n_iter` (padrÃ£o: 50) aleatÃ³rias  
**Total de fits**: `n_iter Ã— cv_folds` = 50 Ã— 2 = **100 fits**

---

**SVM - LinearSVC (Random Search - 50 iteraÃ§Ãµes padrÃ£o):**

**LocalizaÃ§Ã£o**: `src/pipelines/classic.py`, linhas 264-268

```python
# EspaÃ§o de busca para LinearSVC (CLASSIC_USE_LINEAR_SVM = True)
param_distributions = {
    'C': loguniform(0.01, 100),           # RegularizaÃ§Ã£o: 0.01 a 100 (log-uniform)
    'loss': ['hinge', 'squared_hinge'],   # FunÃ§Ã£o de perda (2 opÃ§Ãµes)
    'class_weight': [None, 'balanced'],   # Balanceamento: None ou balanced (2 opÃ§Ãµes)
    'dual': [True, False]                 # Forma dual ou primal (2 opÃ§Ãµes)
}
```

**Total de combinaÃ§Ãµes teÃ³ricas**: Menor que SVC  
**CombinaÃ§Ãµes avaliadas**: Apenas `n_iter` (padrÃ£o: 50) aleatÃ³rias  
**Total de fits**: `n_iter Ã— cv_folds` = 50 Ã— 2 = **100 fits**  
**BenefÃ­cio**: âœ… Muito mais eficiente em memÃ³ria (nÃ£o calcula matriz Gram)

---

**Random Forest (Random Search - 50 iteraÃ§Ãµes padrÃ£o):**

**LocalizaÃ§Ã£o**: `src/pipelines/classic.py`, linhas 430-437

```python
# EspaÃ§o de busca para Random Forest
param_distributions = {
    'n_estimators': randint(50, 300),       # NÃºmero de Ã¡rvores: 50 a 299
    'max_depth': [None, 10, 20, 30, 50],   # Profundidade mÃ¡xima: 5 opÃ§Ãµes
    'min_samples_split': randint(2, 20),   # Amostras mÃ­nimas split: 2 a 19
    'min_samples_leaf': randint(1, 10),    # Amostras mÃ­nimas folha: 1 a 9
    'max_features': ['sqrt', 'log2', None], # Features por split: 3 opÃ§Ãµes
    'bootstrap': [True, False],             # Bootstrap sampling: 2 opÃ§Ãµes
    'class_weight': [None, 'balanced', 'balanced_subsample']  # Balanceamento: 3 opÃ§Ãµes
}
```

**Total de combinaÃ§Ãµes teÃ³ricas**: Muito grande (produto de todos os espaÃ§os)  
**CombinaÃ§Ãµes avaliadas**: Apenas `n_iter` (padrÃ£o: 50) aleatÃ³rias  
**Total de fits**: `n_iter Ã— cv_folds` = 50 Ã— 2 = **100 fits**

### MÃ©tricas Utilizadas

- AcurÃ¡cia (Accuracy)
- PrecisÃ£o (Precision)
- Recall
- F1-Score
- Matriz de ConfusÃ£o

---

## ğŸ§  Pipeline Deep Learning - Detalhes Completos

### Modelos Implementados

#### **1. Simple CNN (sem Transfer Learning)**

**LocalizaÃ§Ã£o**: `src/models/cnn.py`, classe `SimpleCNN`, linhas 9-69

**Arquitetura Completa**:
```python
# src/models/cnn.py - LINHAS 26-46:
class SimpleCNN(nn.Module):
    def __init__(self, num_classes, dropout_rate=0.5, hidden_units=512):
        super(SimpleCNN, self).__init__()
        
        # Camadas convolucionais
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)      # âœ… 3 canais â†’ 32 filtros
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)     # âœ… 32 â†’ 64 filtros
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)    # âœ… 64 â†’ 128 filtros
        
        # Pooling
        self.pool = nn.MaxPool2d(2, 2)                               # âœ… Reduz tamanho pela metade
        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))           # âœ… Garante tamanho fixo (7x7)
        
        # RegularizaÃ§Ã£o
        self.dropout = nn.Dropout(dropout_rate)                      # âœ… Dropout configurÃ¡vel
        
        # Camadas fully connected
        self.fc1 = nn.Linear(128 * 7 * 7, hidden_units)             # âœ… 6272 â†’ hidden_units
        self.fc2 = nn.Linear(hidden_units, num_classes)             # âœ… hidden_units â†’ num_classes
        
        # AtivaÃ§Ã£o
        self.relu = nn.ReLU()                                        # âœ… ReLU
```

**Forward Pass** (linha 48-69):
```python
# src/models/cnn.py - LINHA 48-69:
def forward(self, x):
    # Bloco 1: Conv1 â†’ ReLU â†’ MaxPool
    x = self.pool(self.relu(self.conv1(x)))  # âœ… 224x224 â†’ 112x112
    
    # Bloco 2: Conv2 â†’ ReLU â†’ MaxPool
    x = self.pool(self.relu(self.conv2(x)))  # âœ… 112x112 â†’ 56x56
    
    # Bloco 3: Conv3 â†’ ReLU â†’ MaxPool
    x = self.pool(self.relu(self.conv3(x)))  # âœ… 56x56 â†’ 28x28
    
    # Adaptive pooling: Garante tamanho fixo independente da entrada
    x = self.adaptive_pool(x)  # âœ… 28x28 â†’ 7x7
    
    # Flatten: Transforma em vetor
    x = x.view(-1, 128 * 7 * 7)  # âœ… (batch, 128, 7, 7) â†’ (batch, 6272)
    
    # Fully connected com dropout
    x = self.dropout(x)           # âœ… Dropout aplicado
    x = self.relu(self.fc1(x))    # âœ… 6272 â†’ hidden_units
    x = self.fc2(x)               # âœ… hidden_units â†’ num_classes
    
    return x
```

**NÃºmero de ParÃ¢metros**:
- Com `hidden_units=512`: ~2.5 milhÃµes de parÃ¢metros
- Com `hidden_units=1024`: ~5.3 milhÃµes de parÃ¢metros
- Treinamento: Do zero (sem transfer learning)

**OtimizaÃ§Ã£o**: Random Search customizado (10 iteraÃ§Ãµes padrÃ£o)

---

#### **2. ResNet50 (com Transfer Learning)**

**LocalizaÃ§Ã£o**: `src/pipelines/deep_learning.py`, funÃ§Ã£o `create_resnet_model()`, linhas 993-1063

**CaracterÃ­sticas**:
- âœ… Base prÃ©-treinada: ImageNet (IMAGENET1K_V2)
- âœ… ~25 milhÃµes de parÃ¢metros total
- âœ… Camadas convolucionais: Congeladas por padrÃ£o (configurÃ¡vel)
- âœ… Camada final: SubstituÃ­da e treinada
- âœ… OtimizaÃ§Ã£o: Random Search customizado (10 iteraÃ§Ãµes padrÃ£o)

**CÃ³digo Completo de CriaÃ§Ã£o**:
```python
# src/pipelines/deep_learning.py - LINHAS 1031-1047:
print(f"   Carregando ResNet50 prÃ©-treinado...")
model = models.resnet50(weights='IMAGENET1K_V2')  # âœ… Carrega pesos prÃ©-treinados

# Congelar todas as camadas por padrÃ£o
for param in model.parameters():
    param.requires_grad = False  # âœ… NÃ£o treina camadas convolucionais

# Substituir camada final (fully connected)
num_features = model.fc.in_features  # âœ… 2048 features
model.fc = nn.Linear(num_features, self.num_classes)  # âœ… 2048 â†’ num_classes

# Descongelar apenas camada final
for param in model.fc.parameters():
    param.requires_grad = True  # âœ… Treina apenas camada final

# Opcional: Descongelar mais camadas para fine-tuning
if unfreeze_layers > 0:
    layers = [model.layer4, model.layer3, model.layer2, model.layer1]  # âœ… Ordem: mais profundo â†’ mais raso
    for i, layer in enumerate(layers[:unfreeze_layers]):
        for param in layer.parameters():
            param.requires_grad = True  # âœ… Descongela camada para treinamento
```

**ConfiguraÃ§Ãµes de Unfreeze Layers**:
- `unfreeze_layers=0`: Apenas camada FC treinada (padrÃ£o) - **2,049 parÃ¢metros treinÃ¡veis**
- `unfreeze_layers=1`: FC + layer4 treinadas - **~2.7 milhÃµes treinÃ¡veis**
- `unfreeze_layers=2`: FC + layer4 + layer3 treinadas - **~7.4 milhÃµes treinÃ¡veis**

**CÃ³digo de Movimento para GPU** (linha 1049-1061):
```python
# src/pipelines/deep_learning.py - LINHAS 1049-1061:
# CRÃTICO: Mover modelo para dispositivo correto (GPU ou CPU)
model = model.to(self.device)

# Verificar dispositivo e mostrar informaÃ§Ãµes
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
model_device = next(model.parameters()).device

print(f"   ResNet50 carregado: {total_params:,} parÃ¢metros total, {trainable_params:,} treinÃ¡veis")
print(f"   Modelo movido para: {model_device}")
if model_device.type == 'cuda':
    print(f"   âœ… ResNet50 estÃ¡ na GPU: {torch.cuda.get_device_name(model_device.index or 0)}")
else:
    print(f"   â„¹ï¸  ResNet50 estÃ¡ na CPU")

return model
```

### ConfiguraÃ§Ã£o de Treinamento Deep Learning

**LocalizaÃ§Ã£o**: `src/config.py`, linhas 32-36 e `src/pipelines/deep_learning.py`

**ParÃ¢metros PadrÃ£o** (`src/config.py`, linhas 32-36):
```python
# src/config.py - LINHAS 32-36:
BATCH_SIZE = 32           # Tamanho do batch padrÃ£o
EPOCHS = 50                # NÃºmero de Ã©pocas padrÃ£o
LEARNING_RATE = 0.001      # Taxa de aprendizado padrÃ£o
```

**Optimizer** (implementado em `deep_learning.py`, linha 598):
```python
# src/pipelines/deep_learning.py - LINHA 598:
optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # âœ… Adam optimizer
```

**Loss Function** (implementado em `deep_learning.py`, linha 597):
```python
# src/pipelines/deep_learning.py - LINHA 597:
criterion = nn.CrossEntropyLoss()  # âœ… Cross-entropy loss (padrÃ£o para classificaÃ§Ã£o)
```

**Learning Rate Scheduler** (implementado em `deep_learning.py`, linhas 599-601):
```python
# src/pipelines/deep_learning.py - LINHAS 599-601:
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=5  # âœ… Reduz LR quando loss nÃ£o melhora
)
# mode='min': Reduz quando loss para de diminuir
# factor=0.5: Multiplica LR por 0.5 quando reduz
# patience=5: Espera 5 Ã©pocas sem melhoria antes de reduzir
```

**CorreÃ§Ã£o Implementada** (linha 599-601):
- **Antes**: `verbose=True` â†’ âŒ Erro: `TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'`
- **Depois**: Removido `verbose` â†’ âœ… Funciona em todas as versÃµes do PyTorch

### Data Augmentation

Aplicado apenas durante o treinamento (nÃ£o no teste):

- RotaÃ§Ã£o aleatÃ³ria: 20 graus
- TranslaÃ§Ã£o horizontal/vertical: 20%
- Flip horizontal: Sim
- Zoom: 20%
- Ajuste de brilho/contraste: 20%

**Justificativa**: Aumenta a variabilidade dos dados de treinamento, reduzindo overfitting e melhorando generalizaÃ§Ã£o.

### NormalizaÃ§Ã£o

Valores de normalizaÃ§Ã£o ImageNet:
- Mean: [0.485, 0.456, 0.406]
- Std: [0.229, 0.224, 0.225]

### OtimizaÃ§Ã£o de HiperparÃ¢metros (Random Search) - Deep Learning

**CNN Simples (Random Search - 10 iteraÃ§Ãµes padrÃ£o):**

**LocalizaÃ§Ã£o**: `src/pipelines/deep_learning.py`, funÃ§Ã£o `train_simple_cnn()`, linhas 772-777

```python
# src/pipelines/deep_learning.py - LINHAS 772-777:
param_space = {
    'learning_rate': (0.0001, 0.01),      # âœ… Log-uniform entre 0.0001 e 0.01
    'batch_size': [16, 32, 64],           # âœ… Valores discretos
    'dropout_rate': (0.3, 0.7),           # âœ… Uniform entre 0.3 e 0.7
    'hidden_units': [256, 512, 1024]      # âœ… Valores discretos
}

best_val_acc = 0.0
search_epochs = min(15, final_epochs)  # âœ… Ã‰pocas limitadas durante busca (mÃ¡ximo 15)
```

**ValidaÃ§Ã£o**: 20% split interno com early stopping (patience=5)  
**Total de iteraÃ§Ãµes**: `n_iter` (padrÃ£o: 10)

---

**ResNet50 (Random Search - 10 iteraÃ§Ãµes padrÃ£o):**

**LocalizaÃ§Ã£o**: `src/pipelines/deep_learning.py`, funÃ§Ã£o `train_resnet_transfer()`, linhas 1100-1104

```python
# src/pipelines/deep_learning.py - LINHAS 1100-1104:
param_space = {
    'learning_rate': (0.00001, 0.001),   # âœ… Log-uniform (menor para transfer learning)
    'batch_size': RESNET50_BATCH_SIZES,  # âœ… [8, 16, 32] (reduzido de [16, 32, 64])
    'unfreeze_layers': [0, 1, 2]         # âœ… Quantidade de camadas a descongelar
}

best_val_acc = 0.0
search_epochs = min(RESNET50_SEARCH_EPOCHS, final_epochs)  # âœ… MÃ¡ximo 10 Ã©pocas
```

**ValidaÃ§Ã£o**: 20% split interno com early stopping (patience=5)  
**Limpeza de memÃ³ria**: Entre cada iteraÃ§Ã£o (configurÃ¡vel)  
**Total de iteraÃ§Ãµes**: `n_iter` (padrÃ£o: 10)

**ConfiguraÃ§Ãµes de unfreeze_layers**:
- `unfreeze_layers=0`: Apenas camada FC treinada (padrÃ£o, mais rÃ¡pido)
- `unfreeze_layers=1`: FC + layer4 treinadas (fine-tuning parcial)
- `unfreeze_layers=2`: FC + layer4 + layer3 treinadas (fine-tuning mais profundo)

**Vantagens do Random Search:**
1. Mais eficiente que Grid Search para espaÃ§os de alta dimensÃ£o
2. Permite explorar distribuiÃ§Ãµes contÃ­nuas (log-uniform)
3. Early stopping reduz tempo de busca
4. ValidaÃ§Ã£o split garante seleÃ§Ã£o nÃ£o enviesada de hiperparÃ¢metros

### Escolha CPU/GPU

O sistema detecta automaticamente se hÃ¡ GPU disponÃ­vel. Para forÃ§ar CPU, altere em `config.py`:

```python
USE_GPU = False  # ForÃ§a uso de CPU
```

## ApresentaÃ§Ã£o e DiscussÃ£o dos Resultados

### Tabela de Resultados

Os resultados sÃ£o salvos automaticamente em:
- `outputs/results/classic_pipeline_results.csv`
- `outputs/results/deep_learning_results.csv`

### Exemplo de Tabela

| Modelo | AcurÃ¡cia | PrecisÃ£o | Recall | F1-Score | OtimizaÃ§Ã£o | Transfer Learning |
|--------|----------|----------|--------|----------|------------|-------------------|
| SVM | 0.8500 | 0.8520 | 0.8500 | 0.8500 | Random Search (50 iter) | - |
| Random Forest | 0.8700 | 0.8720 | 0.8700 | 0.8700 | Random Search (50 iter) | - |
| CNN Simples | 0.8800 | 0.8820 | 0.8800 | 0.8800 | Random Search (10 iter) | NÃ£o |
| ResNet50 | 0.9500 | 0.9520 | 0.9500 | 0.9500 | Random Search (10 iter) | Sim |

### VisualizaÃ§Ãµes Geradas

1. **Matrizes de ConfusÃ£o**: Uma para cada modelo
   - Salvas em `outputs/figures/`
   - Formato PNG, alta resoluÃ§Ã£o

2. **MÃ©tricas Comparativas**: Tabelas em CSV

### AnÃ¡lise dos Resultados

**Pipeline ClÃ¡ssico:**
- SVM geralmente apresenta melhor performance para dados de alta dimensionalidade
- Random Forest Ã© robusto, interpretÃ¡vel e lida bem com dados desbalanceados
- Ambos usam Random Search para encontrar hiperparÃ¢metros Ã³timos

**Pipeline Deep Learning:**
- CNN Simples aprende features automaticamente mas requer mais dados
- ResNet50 com transfer learning aproveita conhecimento prÃ©-treinado
- Random Search otimiza hiperparÃ¢metros de forma eficiente
- Deep learning geralmente supera mÃ©todos clÃ¡ssicos com dados suficientes

**ComparaÃ§Ã£o de OtimizaÃ§Ã£o (Random Search):**
- Todos os 4 modelos utilizam Random Search para otimizaÃ§Ã£o de hiperparÃ¢metros
- Permite comparaÃ§Ã£o justa entre modelos clÃ¡ssicos e deep learning
- Pipeline clÃ¡ssico: 50 iteraÃ§Ãµes (mais rÃ¡pido por modelo)
- Pipeline deep learning: 10 iteraÃ§Ãµes (mais custoso por iteraÃ§Ã£o)

## ConclusÃ£o

### Dificuldades Encontradas

1. **PrÃ©-processamento de Dados**
   - **MÃºltiplos formatos**: Necessidade de tratar JPG, PNG, JPEG uniformemente
   - **Canais inconsistentes**: ConversÃ£o de RGBA e grayscale para RGB
   - **OrientaÃ§Ã£o EXIF**: CorreÃ§Ã£o automÃ¡tica de rotaÃ§Ã£o baseada em metadados
   - **NormalizaÃ§Ã£o adequada**: Diferentes normalizaÃ§Ãµes para modelos clÃ¡ssicos e deep learning
   - **Balanceamento de classes**: Dataset com leve desbalanceamento (55% vs 45%)
   - **Tamanho adequado das imagens**: Redimensionamento mantendo qualidade
   - **ValidaÃ§Ã£o robusta**: Tratamento de imagens corrompidas ou invÃ¡lidas

2. **OtimizaÃ§Ã£o de HiperparÃ¢metros**
   - Random Search mais eficiente que Grid Search para espaÃ§os grandes
   - Trade-off entre nÃºmero de iteraÃ§Ãµes e qualidade dos resultados
   - ValidaÃ§Ã£o cruzada/split requer dados suficientes

3. **Deep Learning**
   - Requer GPU para treinamento eficiente
   - Overfitting com poucos dados
   - Ajuste fino de learning rate e batch size

4. **ComparaÃ§Ã£o de Modelos**
   - Diferentes mÃ©tricas podem dar resultados diferentes
   - Necessidade de mÃºltiplas execuÃ§Ãµes para estabilidade

### Melhorias Futuras

Se houvesse mais tempo para desenvolvimento:

1. **PrÃ©-processamento**
   - âœ… **Implementado**: PadronizaÃ§Ã£o completa de formatos (JPG, PNG, JPEG)
   - âœ… **Implementado**: ConversÃ£o automÃ¡tica para RGB (3 canais)
   - âœ… **Implementado**: CorreÃ§Ã£o de orientaÃ§Ã£o EXIF
   - âœ… **Implementado**: RemoÃ§Ã£o de transparÃªncia (alpha channel)
   - âœ… **Implementado**: ValidaÃ§Ã£o robusta e tratamento de erros
   - âœ… **Implementado**: RelatÃ³rio detalhado de estatÃ­sticas
   - Implementar balanceamento de classes (SMOTE, undersampling)
   - Testar diferentes tamanhos de imagem
   - Aplicar tÃ©cnicas de denoising
   - Histogram equalization para normalizar brilho/contraste
   - DetecÃ§Ã£o automÃ¡tica de imagens de baixa qualidade

2. **OtimizaÃ§Ã£o de HiperparÃ¢metros**
   - Implementar Optuna para busca bayesiana mais eficiente
   - Early stopping para evitar overfitting
   - Ensemble de modelos

3. **Deep Learning**
   - Testar diferentes arquiteturas (EfficientNet, Vision Transformer)
   - Fine-tuning completo do ResNet (nÃ£o apenas Ãºltima camada)
   - Implementar callbacks (checkpointing, tensorboard)

4. **AvaliaÃ§Ã£o**
   - ValidaÃ§Ã£o cruzada k-fold
   - AnÃ¡lise de erros (quais classes sÃ£o mais confundidas)
   - VisualizaÃ§Ã£o de features aprendidas

5. **Deploy**
   - API REST para prediÃ§Ãµes
   - Interface web para upload de imagens
   - OtimizaÃ§Ã£o de modelos para produÃ§Ã£o

## ExecuÃ§Ã£o

### Exemplo Completo

```bash
# 1. Instalar dependÃªncias
pip install -r requirements.txt

# 2. Baixar e organizar dataset do Kaggle
python scripts/download_dataset.py

# 3. Executar pipeline
python main.py

# 4. Escolher opÃ§Ã£o (1, 2, 3 ou 4)
#    1. Pipeline ClÃ¡ssico (SVM + Random Forest)
#    2. Pipeline Deep Learning (CNN + ResNet)
#    3. Ambos os pipelines
#    4. Sair

# 5. Ver resultados
# - outputs/results/classic_pipeline_results.csv
# - outputs/results/deep_learning_results.csv
# - outputs/figures/*.png
# - outputs/models/*.pkl ou *.pth
```

### ExecuÃ§Ã£o RÃ¡pida (AutomÃ¡tica)

Se vocÃª jÃ¡ tem as credenciais do Kaggle configuradas:

```bash
python main.py
```

O script detectarÃ¡ automaticamente se os dados nÃ£o existem e oferecerÃ¡ a opÃ§Ã£o de baixar.

---

## âš™ï¸ ConfiguraÃ§Ãµes Detalhadas

Esta seÃ§Ã£o explica **TODAS** as configuraÃ§Ãµes disponÃ­veis em `src/config.py`, organizadas por categoria.

### ğŸ“ LocalizaÃ§Ã£o das ConfiguraÃ§Ãµes

**Arquivo**: `src/config.py`  
**Total de configuraÃ§Ãµes**: 37 variÃ¡veis  
**OrganizaÃ§Ã£o**: Por categoria (dataset, treinamento, memÃ³ria, modelos especÃ­ficos)

---

### ğŸ¯ ConfiguraÃ§Ãµes de Dispositivo e Hardware

#### **`USE_GPU`** (linha 13)
```python
USE_GPU = True  # Altere para False para usar CPU
```

**DescriÃ§Ã£o**: Controla se o sistema deve tentar usar GPU para modelos deep learning.  
**Valores**: `True` (tenta usar GPU se disponÃ­vel) ou `False` (forÃ§a CPU)  
**Quando alterar**: 
- âœ… `False` se nÃ£o tiver GPU ou se quiser usar apenas CPU
- âœ… `False` se estiver tendo problemas com CUDA
- âœ… `True` para acelerar treinamento de modelos deep learning (CNN, ResNet50)

**Exemplo de uso**:
```python
# ForÃ§ar CPU
USE_GPU = False

# Tentar usar GPU (padrÃ£o)
USE_GPU = True
```

---

### ğŸ“Š ConfiguraÃ§Ãµes do Dataset

#### **`KAGGLE_DATASET`** (linha 22)
```python
KAGGLE_DATASET = "hassnainzaidi/ai-art-vs-human-art"
```

**DescriÃ§Ã£o**: Nome do dataset do Kaggle no formato `usuario/dataset`.  
**Valores**: String com nome do dataset  
**Quando alterar**: Se quiser usar um dataset diferente do Kaggle  
**Exemplo**: `"outro_usuario/outro-dataset"`

---

#### **`USE_KAGGLE_DATASET`** (linha 23)
```python
USE_KAGGLE_DATASET = True  # Se True, usa dataset do Kaggle
```

**DescriÃ§Ã£o**: Se `True`, o script tenta baixar o dataset do Kaggle automaticamente.  
**Valores**: `True` ou `False`  
**Quando alterar**: Se jÃ¡ tiver os dados organizados manualmente, pode manter `True` (o script nÃ£o baixa novamente se jÃ¡ existir)

---

#### **`TRAIN_SPLIT` e `TEST_SPLIT`** (linhas 24-25)
```python
TRAIN_SPLIT = 0.7  # ProporÃ§Ã£o de dados para treinamento
TEST_SPLIT = 0.3   # ProporÃ§Ã£o de dados para teste
```

**DescriÃ§Ã£o**: ProporÃ§Ãµes para dividir o dataset em treino e teste.  
**Valores**: Float entre 0 e 1, devem somar 1.0  
**PadrÃ£o**: 70% treino, 30% teste  
**Quando alterar**: 
- âœ… Se quiser mais dados de treino: `TRAIN_SPLIT = 0.8, TEST_SPLIT = 0.2`
- âœ… Se quiser mais dados de teste: `TRAIN_SPLIT = 0.6, TEST_SPLIT = 0.4`

**Importante**: Os valores devem somar 1.0!

---

### ğŸ–¼ï¸ ConfiguraÃ§Ãµes de Imagens

#### **`IMG_SIZE`** (linha 28)
```python
IMG_SIZE = (224, 224)  # Tamanho padrÃ£o para modelos de deep learning
```

**DescriÃ§Ã£o**: Tamanho das imagens para modelos deep learning (CNN, ResNet50).  
**Valores**: Tupla `(altura, largura)` em pixels  
**PadrÃ£o**: `(224, 224)` - padrÃ£o ImageNet  
**Quando alterar**: 
- âœ… Maior tamanho (`(256, 256)`, `(512, 512)`): Mais qualidade, mas mais memÃ³ria e tempo
- âœ… Menor tamanho (`(128, 128)`): Menos memÃ³ria, mas pode perder detalhes

**Uso**: Aplicado apenas em `src/pipelines/deep_learning.py`

---

#### **`IMG_SIZE_CLASSIC`** (linha 29)
```python
IMG_SIZE_CLASSIC = (64, 64)  # Tamanho menor para modelos clÃ¡ssicos (economiza memÃ³ria)
```

**DescriÃ§Ã£o**: Tamanho das imagens para modelos clÃ¡ssicos (SVM, Random Forest).  
**Valores**: Tupla `(altura, largura)` em pixels  
**PadrÃ£o**: `(64, 64)` - **OTIMIZADO para economizar memÃ³ria**  
**Quando alterar**: 
- âœ… Se tiver muito RAM: Pode aumentar para `(128, 128)` ou `(96, 96)`
- âœ… Se estiver com pouco RAM: Manter `(64, 64)` ou reduzir para `(32, 32)`

**Impacto na memÃ³ria**: 
- `(224, 224)`: 150,528 features por imagem
- `(64, 64)`: 12,288 features por imagem (**92% reduÃ§Ã£o!**)

**Uso**: Aplicado apenas em `src/pipelines/classic.py`

---

#### **`IMG_CHANNELS`** (linha 30)
```python
IMG_CHANNELS = 3  # RGB
```

**DescriÃ§Ã£o**: NÃºmero de canais de cor.  
**Valores**: `3` (RGB) ou `1` (grayscale)  
**NÃ£o recomendado alterar**: O cÃ³digo estÃ¡ otimizado para RGB (3 canais)

---

### ğŸ‹ï¸ ConfiguraÃ§Ãµes de Treinamento (Deep Learning)

#### **`BATCH_SIZE`** (linha 33)
```python
BATCH_SIZE = 32
```

**DescriÃ§Ã£o**: Tamanho do batch para modelos deep learning (CNN, ResNet50).  
**Valores**: Inteiro positivo (8, 16, 32, 64, etc.)  
**PadrÃ£o**: `32`  
**Quando alterar**: 
- âœ… **Mais memÃ³ria disponÃ­vel**: Aumentar para `64` ou `128` (treina mais rÃ¡pido)
- âœ… **Pouca memÃ³ria GPU**: Reduzir para `16` ou `8` (evita estouro de memÃ³ria)
- âœ… **ResNet50**: Use `RESNET50_DEFAULT_BATCH_SIZE` (linha 89) ao invÃ©s desta

**Impacto**:
- Batch maior = treina mais rÃ¡pido, mas usa mais memÃ³ria
- Batch menor = mais lento, mas usa menos memÃ³ria

---

#### **`EPOCHS`** (linha 34)
```python
EPOCHS = 50
```

**DescriÃ§Ã£o**: NÃºmero mÃ¡ximo de Ã©pocas para treinamento deep learning.  
**Valores**: Inteiro positivo  
**PadrÃ£o**: `50`  
**Quando alterar**: 
- âœ… **Mais tempo disponÃ­vel**: Aumentar para `100` ou `200`
- âœ… **Testes rÃ¡pidos**: Reduzir para `10` ou `20`
- âœ… **Random Search**: Usa `min(15, EPOCHS)` durante busca (linha 1586 em `deep_learning.py`)

**Nota**: Early stopping pode parar antes se nÃ£o houver melhoria (patience=5)

---

#### **`LEARNING_RATE`** (linha 35)
```python
LEARNING_RATE = 0.001
```

**DescriÃ§Ã£o**: Taxa de aprendizado inicial para otimizador Adam.  
**Valores**: Float positivo (geralmente entre 0.00001 e 0.1)  
**PadrÃ£o**: `0.001` (1e-3)  
**Quando alterar**: 
- âœ… **Modelo nÃ£o converge**: Reduzir para `0.0001` ou `0.0005`
- âœ… **Modelo converge muito devagar**: Aumentar para `0.002` ou `0.005`
- âœ… **Transfer learning (ResNet50)**: Usar learning rate menor (`0.0001` ou `0.00001`)

**Nota**: Random Search otimiza automaticamente este parÃ¢metro (espaÃ§o: 0.0001 a 0.01 para CNN, 0.00001 a 0.001 para ResNet50)

---

### ğŸ¨ ConfiguraÃ§Ãµes de Data Augmentation

#### **`USE_AUGMENTATION`** (linha 38)
```python
USE_AUGMENTATION = True
```

**DescriÃ§Ã£o**: Ativa/desativa data augmentation durante treinamento deep learning.  
**Valores**: `True` ou `False`  
**Quando alterar**: 
- âœ… **Poucos dados**: Manter `True` (aumenta variabilidade)
- âœ… **Muitos dados**: Pode desativar `False` (acelera treinamento)
- âœ… **Overfitting**: Manter `True` (reduz overfitting)

**Aplicado apenas em**: Treinamento (nÃ£o em teste/validaÃ§Ã£o)

---

#### **`AUGMENTATION_PARAMS`** (linhas 39-46)
```python
AUGMENTATION_PARAMS = {
    'rotation_range': 20,        # RotaÃ§Ã£o: Â±20 graus
    'width_shift_range': 0.2,    # TranslaÃ§Ã£o horizontal: Â±20%
    'height_shift_range': 0.2,   # TranslaÃ§Ã£o vertical: Â±20%
    'horizontal_flip': True,     # Flip horizontal
    'zoom_range': 0.2,           # Zoom: Â±20%
    'fill_mode': 'nearest'       # Preenchimento de bordas
}
```

**DescriÃ§Ã£o**: ParÃ¢metros especÃ­ficos de data augmentation.  
**Quando alterar**: 
- âœ… **Arte com orientaÃ§Ã£o importante**: Reduzir `rotation_range` para `10`
- âœ… **Arte que nÃ£o deve ser espelhada**: `horizontal_flip = False`
- âœ… **Mais variaÃ§Ã£o**: Aumentar `zoom_range` para `0.3` ou `0.4`

---

### ğŸ§  ConfiguraÃ§Ãµes de Gerenciamento de MemÃ³ria

#### **`USE_LAZY_LOADING`** (linha 58)
```python
USE_LAZY_LOADING = True
```

**DescriÃ§Ã£o**: Carrega imagens sob demanda (lazy loading) ao invÃ©s de carregar tudo na memÃ³ria.  
**Valores**: `True` ou `False`  
**Recomendado**: Sempre `True` (economiza muita memÃ³ria)  
**Quando alterar**: Apenas se quiser carregar tudo na memÃ³ria de uma vez (`False` - nÃ£o recomendado)

---

#### **`IMAGE_CACHE_SIZE`** (linha 61)
```python
IMAGE_CACHE_SIZE = 100
```

**DescriÃ§Ã£o**: Tamanho do cache LRU de imagens (quantas imagens manter em cache).  
**Valores**: Inteiro positivo (0 = sem cache)  
**PadrÃ£o**: `100`  
**Quando alterar**: 
- âœ… **Mais RAM disponÃ­vel**: Aumentar para `200` ou `500` (acelera carregamento)
- âœ… **Pouca RAM**: Reduzir para `50` ou `0` (desativa cache)

**Funcionamento**: LRU (Least Recently Used) - imagens menos usadas sÃ£o removidas do cache

---

#### **`MIN_BATCH_SIZE`** (linha 64)
```python
MIN_BATCH_SIZE = 4
```

**DescriÃ§Ã£o**: Batch size mÃ­nimo para adaptive batch size (em caso de estouro de memÃ³ria).  
**Valores**: Inteiro positivo (geralmente 1, 2, 4, 8)  
**Quando alterar**: Apenas se implementar adaptive batch size (atualmente nÃ£o implementado completamente)

---

#### **`MEMORY_WARNING_THRESHOLD` e `MEMORY_CRITICAL_THRESHOLD`** (linhas 67-68)
```python
MEMORY_WARNING_THRESHOLD = 0.8   # 80% de uso
MEMORY_CRITICAL_THRESHOLD = 0.9  # 90% de uso
```

**DescriÃ§Ã£o**: Limites de memÃ³ria para alertas.  
**Valores**: Float entre 0 e 1 (0.8 = 80%, 0.9 = 90%)  
**Quando alterar**: Apenas para ajustar sensibilidade dos alertas

---

#### **`CLEAR_MEMORY_EVERY_N_BATCHES`** (linha 74)
```python
CLEAR_MEMORY_EVERY_N_BATCHES = 50
```

**DescriÃ§Ã£o**: Limpar memÃ³ria GPU a cada N batches durante treinamento.  
**Valores**: Inteiro positivo  
**Quando alterar**: 
- âœ… **Estouro de memÃ³ria durante treinamento**: Reduzir para `20` ou `10`
- âœ… **Treinamento estÃ¡vel**: Manter `50` ou aumentar para `100`

**Funcionamento**: Chama `clear_memory(clear_gpu=True)` automaticamente

---

### ğŸ¯ ConfiguraÃ§Ãµes EspecÃ­ficas para ResNet50

#### **`RESNET50_BATCH_SIZES`** (linha 86)
```python
RESNET50_BATCH_SIZES = [8, 16, 32]  # Reduzido de [16, 32, 64]
```

**DescriÃ§Ã£o**: Batch sizes testados durante Random Search do ResNet50.  
**Valores**: Lista de inteiros positivos  
**PadrÃ£o**: `[8, 16, 32]` (otimizado para evitar estouro de memÃ³ria)  
**Quando alterar**: 
- âœ… **GPU com muita memÃ³ria (16GB+)**: Pode aumentar para `[16, 32, 64]`
- âœ… **GPU com pouca memÃ³ria (4-6GB)**: Reduzir para `[4, 8, 16]`

**Impacto**: Batch sizes menores = menos memÃ³ria, mas Random Search mais lento

---

#### **`RESNET50_DEFAULT_BATCH_SIZE`** (linha 89)
```python
RESNET50_DEFAULT_BATCH_SIZE = 16  # Reduzido de 32
```

**DescriÃ§Ã£o**: Batch size padrÃ£o para treinamento final do ResNet50 (quando nÃ£o usar Random Search).  
**Valores**: Inteiro positivo  
**PadrÃ£o**: `16` (otimizado)  
**Quando alterar**: Baseado na memÃ³ria disponÃ­vel (mesmas recomendaÃ§Ãµes de `BATCH_SIZE`)

---

#### **`RESNET50_SEARCH_EPOCHS`** (linha 92)
```python
RESNET50_SEARCH_EPOCHS = 10  # NÃºmero mÃ¡ximo de Ã©pocas durante Random Search
```

**DescriÃ§Ã£o**: NÃºmero mÃ¡ximo de Ã©pocas por iteraÃ§Ã£o durante Random Search do ResNet50.  
**Valores**: Inteiro positivo  
**PadrÃ£o**: `10` (otimizado para velocidade)  
**Quando alterar**: 
- âœ… **Random Search muito rÃ¡pido**: Aumentar para `15` ou `20` (mais tempo, melhor busca)
- âœ… **Random Search muito lento**: Reduzir para `5` (mais rÃ¡pido, mas menos preciso)

**Nota**: Treinamento final usa `EPOCHS` completo (50 por padrÃ£o)

---

#### **`RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS`** (linha 95)
```python
RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True  # IMPORTANTE: Limpar entre iteraÃ§Ãµes
```

**DescriÃ§Ã£o**: Limpa memÃ³ria GPU entre cada iteraÃ§Ã£o do Random Search do ResNet50.  
**Valores**: `True` ou `False`  
**Recomendado**: **Sempre `True`** (crÃ­tico para evitar estouro de memÃ³ria)  
**Quando alterar**: Apenas se tiver GPU com muita memÃ³ria e quiser testar sem limpeza (`False` - nÃ£o recomendado)

**Funcionamento**: Chama `clear_memory(clear_gpu=True)` antes e depois de cada iteraÃ§Ã£o

---

### ğŸ“Š ConfiguraÃ§Ãµes EspecÃ­ficas para Modelos ClÃ¡ssicos

#### **`CLASSIC_USE_PCA`** (linha 102)
```python
CLASSIC_USE_PCA = True  # Usar PCA para reduÃ§Ã£o de dimensionalidade
```

**DescriÃ§Ã£o**: Ativa/desativa PCA para reduzir dimensionalidade antes de modelos clÃ¡ssicos.  
**Valores**: `True` ou `False`  
**Recomendado**: **Sempre `True`** (economiza 95%+ de memÃ³ria)  
**Quando alterar**: 
- âœ… **Muito RAM disponÃ­vel**: Pode desativar `False` (mais features, mais tempo)
- âœ… **Pouca RAM**: Manter `True` (essencial para economizar memÃ³ria)

**Impacto**: 
- `True`: 12,288 features â†’ 500 componentes (**96% reduÃ§Ã£o!**)
- `False`: Usa todas as 12,288 features (mais memÃ³ria)

---

#### **`CLASSIC_PCA_COMPONENTS`** (linha 103)
```python
CLASSIC_PCA_COMPONENTS = 500  # NÃºmero de componentes PCA
```

**DescriÃ§Ã£o**: NÃºmero de componentes principais do PCA.  
**Valores**: Inteiro positivo ou `None` (auto = 95% variÃ¢ncia)  
**PadrÃ£o**: `500` (otimizado para balancear memÃ³ria e qualidade)  
**Quando alterar**: 
- âœ… **Mais memÃ³ria disponÃ­vel**: Aumentar para `1000` ou `1500` (mais features, mais tempo)
- âœ… **Muito pouca RAM**: Reduzir para `250` ou `300` (menos features, menos qualidade)
- âœ… **Auto (95% variÃ¢ncia)**: `None` (PCA decide nÃºmero automaticamente)

**Impacto na variÃ¢ncia explicada**: Geralmente mantÃ©m ~95-98% da variÃ¢ncia original

---

#### **`CLASSIC_USE_LINEAR_SVM`** (linha 104)
```python
CLASSIC_USE_LINEAR_SVM = False  # False = SVC (kernels), True = LinearSVC (sÃ³ linear)
```

**DescriÃ§Ã£o**: Se `True`, usa `LinearSVC` (apenas kernel linear, mais eficiente em memÃ³ria).  
**Valores**: `True` ou `False`  
**PadrÃ£o**: `False` (usa `SVC` com kernels RBF, linear, poly)  
**Quando alterar**: 
- âœ… **Estouro de memÃ³ria com SVC**: Ativar `True` (economiza 70-90% de memÃ³ria adicional)
- âœ… **Quer kernels nÃ£o-lineares (RBF, poly)**: Manter `False`

**Trade-off**:
- `True`: Muito mais eficiente em memÃ³ria, mas apenas kernel linear (pode perder performance)
- `False`: Suporta kernels nÃ£o-lineares, mas usa mais memÃ³ria

---

#### **`CLASSIC_MAX_SAMPLES`** (linha 105)
```python
CLASSIC_MAX_SAMPLES = None  # None = usar todas as amostras
```

**DescriÃ§Ã£o**: Limita nÃºmero de amostras de treinamento para modelos clÃ¡ssicos.  
**Valores**: Inteiro positivo ou `None` (usa todas)  
**PadrÃ£o**: `None` (usa todas as amostras)  
**Quando alterar**: 
- âœ… **Estouro de memÃ³ria mesmo com PCA**: Definir para `10000` ou `5000` (usa amostras aleatÃ³rias)
- âœ… **Testes rÃ¡pidos**: Definir para `1000` ou `500`

**Nota**: Amostras sÃ£o selecionadas aleatoriamente mantendo proporÃ§Ã£o de classes

---

#### **`CLASSIC_SVM_N_JOBS`** (linha 106)
```python
CLASSIC_SVM_N_JOBS = 1  # 1 = sem paralelizaÃ§Ã£o (economiza memÃ³ria)
```

**DescriÃ§Ã£o**: NÃºmero de jobs paralelos para SVM e RandomizedSearchCV do SVM.  
**Valores**: Inteiro positivo (1 = sem paralelizaÃ§Ã£o) ou `-1` (todos os cores)  
**PadrÃ£o**: `1` (otimizado para economizar memÃ³ria)  
**Quando alterar**: 
- âœ… **Muito RAM disponÃ­vel**: Aumentar para `2`, `4` ou `-1` (acelera treinamento)
- âœ… **Pouca RAM**: Manter `1` (evita duplicaÃ§Ã£o de dados em mÃºltiplos processos)

**Trade-off**:
- `1`: Usa menos memÃ³ria, mas mais lento
- `-1`: Mais rÃ¡pido, mas usa muito mais memÃ³ria (cada processo duplica dados)

---

#### **`CLASSIC_RF_N_JOBS`** (linha 107)
```python
CLASSIC_RF_N_JOBS = -1  # -1 = todos os cores (Random Forest usa memÃ³ria eficientemente)
```

**DescriÃ§Ã£o**: NÃºmero de jobs paralelos para Random Forest e RandomizedSearchCV do RF.  
**Valores**: Inteiro positivo ou `-1` (todos os cores)  
**PadrÃ£o**: `-1` (todos os cores)  
**Quando alterar**: 
- âœ… **Quer economizar CPU**: Reduzir para `2` ou `4`
- âœ… **Normal**: Manter `-1` (Random Forest paraleliza muito bem)

**Por que diferente do SVM?**: Random Forest usa memÃ³ria de forma mais eficiente (Ã¡rvores independentes), entÃ£o pode usar paralelizaÃ§Ã£o sem problemas

---

#### **`CLASSIC_CV_FOLDS`** (linha 108)
```python
CLASSIC_CV_FOLDS = 2  # 2 ao invÃ©s de 3 para economizar memÃ³ria
```

**DescriÃ§Ã£o**: NÃºmero de folds para validaÃ§Ã£o cruzada em modelos clÃ¡ssicos (SVM e Random Forest).  
**Valores**: Inteiro positivo (geralmente 2, 3, 5, 10)  
**PadrÃ£o**: `2` (otimizado para economizar memÃ³ria)  
**Quando alterar**: 
- âœ… **Mais RAM disponÃ­vel**: Aumentar para `3` ou `5` (mais robusto, mas mais memÃ³ria)
- âœ… **Pouca RAM**: Manter `2` (essencial para economizar memÃ³ria)

**Impacto na memÃ³ria**: 
- `2`: 2 cÃ³pias dos dados durante CV
- `3`: 3 cÃ³pias dos dados durante CV (**50% mais memÃ³ria!**)

**Aplica-se a**: SVM e Random Forest (ambos usam esta configuraÃ§Ã£o)

---

### ğŸ“ ConfiguraÃ§Ãµes de DiretÃ³rios

#### **`ROOT_DIR`** (linha 10)
```python
ROOT_DIR = Path(__file__).parent.parent.absolute()
```

**DescriÃ§Ã£o**: DiretÃ³rio raiz do projeto (calculado automaticamente).  
**NÃ£o alterar**: Ã‰ calculado automaticamente baseado na localizaÃ§Ã£o de `config.py`

---

#### **`DATA_DIR`, `TRAIN_DIR`, `TEST_DIR`** (linhas 16-18)
```python
DATA_DIR = ROOT_DIR / 'data'
TRAIN_DIR = DATA_DIR / 'train'
TEST_DIR = DATA_DIR / 'test'
```

**DescriÃ§Ã£o**: Caminhos dos diretÃ³rios de dados.  
**Quando alterar**: Se quiser usar uma estrutura de diretÃ³rios diferente  
**Exemplo**: `DATA_DIR = Path('/caminho/para/dados')`

---

#### **`OUTPUT_DIR`, `MODELS_DIR`, `RESULTS_DIR`, `FIGURES_DIR`** (linhas 111-114)
```python
OUTPUT_DIR = ROOT_DIR / 'outputs'
MODELS_DIR = OUTPUT_DIR / 'models'
RESULTS_DIR = OUTPUT_DIR / 'results'
FIGURES_DIR = OUTPUT_DIR / 'figures'
```

**DescriÃ§Ã£o**: Caminhos dos diretÃ³rios de saÃ­da (modelos, resultados, figuras).  
**Quando alterar**: Se quiser salvar em outro local  
**Nota**: DiretÃ³rios sÃ£o criados automaticamente se nÃ£o existirem (linha 117-118)

---

### ğŸ“ Resumo de ConfiguraÃ§Ãµes CrÃ­ticas

**Para economizar memÃ³ria (problemas de estouro)**:
1. âœ… `CLASSIC_USE_PCA = True` (essencial!)
2. âœ… `CLASSIC_PCA_COMPONENTS = 500` (ou menor)
3. âœ… `CLASSIC_SVM_N_JOBS = 1` (sem paralelizaÃ§Ã£o)
4. âœ… `CLASSIC_CV_FOLDS = 2` (menos folds)
5. âœ… `RESNET50_BATCH_SIZES = [8, 16, 32]` (ou menor)
6. âœ… `RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True` (essencial!)
7. âœ… `IMG_SIZE_CLASSIC = (64, 64)` (nÃ£o aumentar!)

**Para acelerar treinamento (mais recursos disponÃ­veis)**:
1. âœ… `USE_GPU = True` (essencial para deep learning)
2. âœ… `BATCH_SIZE = 64` ou maior (se tiver memÃ³ria GPU)
3. âœ… `CLASSIC_RF_N_JOBS = -1` (todos os cores)
4. âœ… `CLASSIC_SVM_N_JOBS = -1` ou `4` (se tiver RAM)
5. âœ… `IMAGE_CACHE_SIZE = 500` (cache maior)

**Para melhor qualidade (mais tempo disponÃ­vel)**:
1. âœ… `EPOCHS = 100` ou maior
2. âœ… `CLASSIC_PCA_COMPONENTS = 1000` (mais features)
3. âœ… `CLASSIC_CV_FOLDS = 5` (mais robusto)
4. âœ… `IMG_SIZE = (256, 256)` (imagens maiores)
5. âœ… `RESNET50_SEARCH_EPOCHS = 20` (mais Ã©pocas por iteraÃ§Ã£o)

---

## ğŸ“š Guias de Uso Completo

### ğŸš€ Guia 1: ExecuÃ§Ã£o Completa do Zero

#### **Passo 1: Preparar Ambiente**

```bash
# 1.1. Clonar ou baixar o projeto
cd Atividade_Visao_Computacional_Residencia_IA

# 1.2. Criar ambiente virtual (recomendado)
python -m venv venv

# 1.3. Ativar ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 1.4. Instalar dependÃªncias
pip install -r requirements.txt

# 1.5. Verificar instalaÃ§Ã£o
python verificar_pytorch.py  # Verifica PyTorch e CUDA
python check_gpu.py          # Verifica GPU
```

---

#### **Passo 2: Configurar Dataset**

**OpÃ§Ã£o A: Usar Dataset do Kaggle (Recomendado)**

```bash
# 2.1. Configurar credenciais do Kaggle (se necessÃ¡rio)
# Linux/Mac:
mkdir -p ~/.kaggle
cp kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json

# Windows:
# Copie kaggle.json para: C:\Users\<username>\.kaggle\kaggle.json

# 2.2. Baixar e organizar dataset
python scripts/download_dataset.py
```

**OpÃ§Ã£o B: Organizar Dados Manualmente**

```bash
# 2.1. Criar estrutura de diretÃ³rios
mkdir -p data/train/classe1
mkdir -p data/train/classe2
mkdir -p data/test/classe1
mkdir -p data/test/classe2

# 2.2. Copiar imagens para diretÃ³rios correspondentes
# (organize manualmente suas imagens)
```

---

#### **Passo 3: Verificar Estrutura de Dados**

```bash
# 3.1. DiagnÃ³stico da estrutura de dados
python diagnose_data.py

# 3.2. Verificar se hÃ¡ pelo menos 2 classes
# SaÃ­da esperada:
# "Classes encontradas: ['aiartdata', 'realart']"
# "Total de amostras: X"
```

**Se encontrar apenas 1 classe**:
- âœ… Execute `python scripts/download_dataset.py` novamente
- âœ… Ou use `python scripts/create_subset.py` para criar subset com classes artificiais

---

#### **Passo 4: Configurar ParÃ¢metros (Opcional)**

Edite `src/config.py` conforme suas necessidades:

```python
# Exemplo: ConfiguraÃ§Ã£o para economia de memÃ³ria
USE_GPU = True
CLASSIC_USE_PCA = True
CLASSIC_PCA_COMPONENTS = 500
CLASSIC_CV_FOLDS = 2
RESNET50_BATCH_SIZES = [8, 16, 32]
```

---

#### **Passo 5: Executar Pipeline**

```bash
# 5.1. Executar script principal
python main.py

# 5.2. Escolher opÃ§Ã£o no menu:
#     1. Pipeline ClÃ¡ssico (SVM + Random Forest)
#     2. Pipeline Deep Learning (CNN + ResNet50)
#     3. Ambos os pipelines
#     4. Sair
```

**Tempo estimado**:
- Pipeline ClÃ¡ssico: 15-30 minutos (CPU)
- Pipeline Deep Learning: 30-120 minutos (GPU) ou 2-4 horas (CPU)
- Ambos: Soma dos dois

---

#### **Passo 6: Analisar Resultados**

```bash
# 6.1. Resultados em CSV
cat outputs/results/classic_pipeline_results.csv
cat outputs/results/deep_learning_results.csv

# 6.2. Figuras (matrizes de confusÃ£o)
# Visualize: outputs/figures/*.png

# 6.3. Modelos salvos
ls outputs/models/
# Arquivos: *.pkl (modelos clÃ¡ssicos), *.pth (modelos deep learning), *.json (metadados)
```

---

### ğŸ§ª Guia 2: Teste RÃ¡pido com Subset

Para testar rapidamente sem usar o dataset completo:

```bash
# 1. Criar subset pequeno (10 imagens por classe)
python scripts/create_subset.py

# 2. Executar versÃ£o rÃ¡pida do pipeline
python main_subset.py

# 3. Ajustar configuraÃ§Ãµes para testes rÃ¡pidos em src/config.py:
#    EPOCHS = 5
#    n_iter = 10  # No cÃ³digo main_subset.py
```

**Tempo estimado**: 2-5 minutos

---

### ğŸ”§ Guia 3: Treinar um Modelo EspecÃ­fico

#### **Treinar apenas SVM**

Edite `main.py` temporariamente ou crie script customizado:

```python
# Exemplo: treinar_svm.py
from src.pipelines.classic import ClassicPipeline
from src.config import *

pipeline = ClassicPipeline(TRAIN_DIR, TEST_DIR)
pipeline.load_data()
pipeline.train_svm(use_random_search=True, n_iter=50)
pipeline.evaluate_svm()
```

```bash
python treinar_svm.py
```

---

#### **Treinar apenas ResNet50**

```python
# Exemplo: treinar_resnet.py
from src.pipelines.deep_learning import DeepLearningPipeline
from src.config import *

pipeline = DeepLearningPipeline(TRAIN_DIR, TEST_DIR)
pipeline.load_data()
pipeline.train_resnet_transfer(use_random_search=True, n_iter=10, final_epochs=50)
pipeline.evaluate_resnet_transfer()
```

```bash
python treinar_resnet.py
```

---

### ğŸ“¦ Guia 4: Carregar Modelo Salvo e Fazer PrediÃ§Ãµes

Use o script de exemplo:

```python
# scripts/load_model_example.py (jÃ¡ existe no projeto)
from src.model_saver import load_model_with_metadata
from src.utils import load_image, preprocess_image
import torch

# Carregar modelo SVM
svm_model, svm_metadata = load_model_with_metadata(
    model_path='outputs/models/svm_model.pkl',
    model_type='sklearn'
)

# Carregar modelo SimpleCNN
from src.models.cnn import SimpleCNN
cnn_model, cnn_metadata = load_model_with_metadata(
    model_path='outputs/models/simple_cnn.pth',
    model_type='pytorch',
    model_class=SimpleCNN
)

# Fazer prediÃ§Ã£o em nova imagem
image = load_image('caminho/para/imagem.jpg')
# ... preprocessar imagem ...
prediction = model.predict(image)
```

```bash
python scripts/load_model_example.py
```

---

### ğŸ¯ Guia 5: OtimizaÃ§Ã£o de HiperparÃ¢metros Customizada

#### **Aumentar NÃºmero de IteraÃ§Ãµes do Random Search**

No cÃ³digo `main.py` ou nos pipelines, altere:

```python
# Pipeline ClÃ¡ssico
pipeline.train_svm(use_random_search=True, n_iter=100)  # Era 50

# Pipeline Deep Learning
pipeline.train_simple_cnn(use_random_search=True, n_iter=20)  # Era 10
```

**Trade-off**: Mais iteraÃ§Ãµes = melhor resultado, mas mais tempo

---

#### **Personalizar EspaÃ§o de Busca**

Edite os pipelines diretamente:

```python
# src/pipelines/deep_learning.py - FunÃ§Ã£o train_simple_cnn()
param_space = {
    'learning_rate': (0.00001, 0.001),  # EspaÃ§o maior
    'batch_size': [8, 16, 32, 64],      # Mais opÃ§Ãµes
    'dropout_rate': (0.2, 0.8),         # EspaÃ§o maior
    'hidden_units': [128, 256, 512, 1024, 2048]  # Mais opÃ§Ãµes
}
```

---

### ğŸ” Guia 6: DiagnÃ³stico e VerificaÃ§Ã£o

#### **Verificar GPU**

```bash
# VerificaÃ§Ã£o completa
python verificar_pytorch.py

# VerificaÃ§Ã£o de GPU
python check_gpu.py

# DiagnÃ³stico de uso de GPU
python diagnose_gpu_usage.py

# Teste direto de GPU
python testar_gpu_direto.py
```

---

#### **Diagnosticar Estrutura de Dados**

```bash
# DiagnÃ³stico completo
python diagnose_data.py

# Criar subset se necessÃ¡rio
python scripts/create_subset.py
```

---

#### **Monitorar MemÃ³ria Durante Treinamento**

Adicione logs no cÃ³digo ou use ferramentas externas:

```python
# Em src/pipelines/deep_learning.py ou classic.py
from src.memory import get_memory_usage

# Durante treinamento
ram_used, ram_total, ram_percent = get_memory_usage()
print(f"RAM: {ram_used:.2f} GB / {ram_total:.2f} GB ({ram_percent*100:.1f}%)")
```

---

## ğŸ”§ Troubleshooting - Problemas Comuns e SoluÃ§Ãµes

Esta seÃ§Ã£o lista **TODOS** os problemas encontrados durante o desenvolvimento e suas soluÃ§Ãµes.

---

### âŒ Problema 1: "ModuleNotFoundError: No module named 'cv2'"

**Erro completo**:
```
ModuleNotFoundError: No module named 'cv2'
```

**Causa**: `opencv-python` nÃ£o estÃ¡ instalado.

**SoluÃ§Ã£o**:
```bash
pip install opencv-python
# ou
pip install -r requirements.txt
```

**PrevenÃ§Ã£o**: Sempre instale todas as dependÃªncias do `requirements.txt` antes de executar.

---

### âŒ Problema 2: "ValueError: Apenas 1 classe(s) foi(ram) carregada(s)"

**Erro completo**:
```
ValueError: ERRO: Apenas 1 classe(s) foi(ram) carregada(s), mas sÃ£o necessÃ¡rias pelo menos 2 classes para classificaÃ§Ã£o.
```

**Causa**: Dataset tem apenas 1 classe ou estrutura de diretÃ³rios incorreta.

**SoluÃ§Ãµes**:

**SoluÃ§Ã£o 2.1: Baixar dataset do Kaggle**
```bash
python scripts/download_dataset.py
```

**SoluÃ§Ã£o 2.2: Criar subset com classes artificiais**
```bash
python scripts/create_subset.py
```

**SoluÃ§Ã£o 2.3: Verificar estrutura manualmente**
```bash
python diagnose_data.py
# Verifique se hÃ¡ pelo menos 2 diretÃ³rios em data/train/
```

**PrevenÃ§Ã£o**: Sempre execute `diagnose_data.py` antes de treinar.

---

### âŒ Problema 3: "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"

**Erro completo**:
```
TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'
```

**Causa**: VersÃ£o do PyTorch nÃ£o suporta parÃ¢metro `verbose` em `ReduceLROnPlateau`.

**Status**: âœ… **CORRIGIDO** - ParÃ¢metro `verbose` foi removido em `src/pipelines/deep_learning.py` (linhas 599-601 e 548-550).

**Se ainda ocorrer**: Atualize o PyTorch:
```bash
pip install --upgrade torch torchvision
```

---

### âŒ Problema 4: "RuntimeError: CUDA out of memory"

**Erro completo**:
```
RuntimeError: CUDA out of memory. Tried to allocate X.XX GiB. GPU allocated memory: X.XX GiB
```

**Causa**: Modelo ou batch size muito grande para a memÃ³ria GPU disponÃ­vel.

**SoluÃ§Ãµes**:

**SoluÃ§Ã£o 4.1: Reduzir batch size (ResNet50)**
```python
# Em src/config.py
RESNET50_BATCH_SIZES = [4, 8, 16]  # Era [8, 16, 32]
RESNET50_DEFAULT_BATCH_SIZE = 8    # Era 16
```

**SoluÃ§Ã£o 4.2: Reduzir batch size (CNN simples)**
```python
# Em src/config.py
BATCH_SIZE = 16  # Era 32
```

**SoluÃ§Ã£o 4.3: Garantir limpeza de memÃ³ria (ResNet50)**
```python
# Em src/config.py
RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True  # DEVE estar True
```

**SoluÃ§Ã£o 4.4: Limpar memÃ³ria GPU manualmente**
```python
import torch
torch.cuda.empty_cache()
torch.cuda.synchronize()
```

**SoluÃ§Ã£o 4.5: Usar CPU ao invÃ©s de GPU**
```python
# Em src/config.py
USE_GPU = False
```

**PrevenÃ§Ã£o**: 
- âœ… Sempre monitore uso de GPU: `nvidia-smi` (Linux/Windows) ou `watch -n 1 nvidia-smi`
- âœ… Use `RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True` sempre
- âœ… Comece com batch sizes pequenos e aumente gradualmente

---

### âŒ Problema 5: "MemoryError" ou Sistema Travando (SVM)

**Erro completo**:
```
MemoryError
# ou sistema simplesmente trava/freeze
```

**Causa**: SVM tentando usar muita memÃ³ria RAM (imagens muito grandes ou muitas amostras).

**SoluÃ§Ãµes**:

**SoluÃ§Ã£o 5.1: Ativar PCA (ESSENCIAL)**
```python
# Em src/config.py
CLASSIC_USE_PCA = True  # DEVE estar True
CLASSIC_PCA_COMPONENTS = 500  # Ou menor (250, 300)
```

**SoluÃ§Ã£o 5.2: Reduzir tamanho de imagem**
```python
# Em src/config.py
IMG_SIZE_CLASSIC = (32, 32)  # Era (64, 64), ainda menor
```

**SoluÃ§Ã£o 5.3: Limitar nÃºmero de amostras**
```python
# Em src/config.py
CLASSIC_MAX_SAMPLES = 5000  # Limita a 5000 amostras
```

**SoluÃ§Ã£o 5.4: Usar LinearSVC (mais eficiente)**
```python
# Em src/config.py
CLASSIC_USE_LINEAR_SVM = True  # Mais eficiente em memÃ³ria
```

**SoluÃ§Ã£o 5.5: Reduzir paralelizaÃ§Ã£o**
```python
# Em src/config.py
CLASSIC_SVM_N_JOBS = 1  # Sem paralelizaÃ§Ã£o (jÃ¡ Ã© padrÃ£o)
CLASSIC_CV_FOLDS = 2    # Menos folds (jÃ¡ Ã© padrÃ£o)
```

**PrevenÃ§Ã£o**: 
- âœ… **SEMPRE** use `CLASSIC_USE_PCA = True` para SVM
- âœ… NÃ£o aumente `IMG_SIZE_CLASSIC` acima de `(64, 64)`
- âœ… Monitore memÃ³ria antes de treinar (o cÃ³digo jÃ¡ faz isso automaticamente)

---

### âŒ Problema 6: "AttributeError: 'str' object has no attribute 'type'"

**Erro completo**:
```
AttributeError: 'str' object has no attribute 'type'
```

**Causa**: `setup_device()` retornava string `'cpu'` ao invÃ©s de `torch.device('cpu')`.

**Status**: âœ… **CORRIGIDO** - `setup_device()` sempre retorna `torch.device` em `src/utils.py` (linhas 62, 122).

**Se ainda ocorrer**: Verifique se estÃ¡ usando a versÃ£o mais recente do cÃ³digo.

---

### âŒ Problema 7: Modelos Deep Learning NÃ£o EstÃ£o Usando GPU

**Sintoma**: Treinamento muito lento, ou logs mostram "CPU" ao invÃ©s de "GPU".

**Causas possÃ­veis**:
1. GPU nÃ£o detectada
2. Modelo nÃ£o movido para GPU
3. Dados nÃ£o movidos para GPU

**SoluÃ§Ãµes**:

**SoluÃ§Ã£o 7.1: Verificar GPU**
```bash
python verificar_pytorch.py
python check_gpu.py
```

**SoluÃ§Ã£o 7.2: Verificar configuraÃ§Ã£o**
```python
# Em src/config.py
USE_GPU = True  # DEVE estar True
```

**SoluÃ§Ã£o 7.3: ForÃ§ar GPU (se disponÃ­vel)**
```python
# O cÃ³digo jÃ¡ faz isso automaticamente, mas vocÃª pode verificar:
import torch
print(f"CUDA disponÃ­vel: {torch.cuda.is_available()}")
print(f"CUDA device: {torch.cuda.get_device_name(0)}")
```

**Status**: âœ… **CORRIGIDO** - Modelos sÃ£o movidos explicitamente para GPU em:
- `src/pipelines/deep_learning.py` linha 309 (SimpleCNN - Random Search)
- `src/pipelines/deep_learning.py` linha 325 (SimpleCNN - treinamento final)
- `src/pipelines/deep_learning.py` linha 1049 (ResNet50 - criaÃ§Ã£o)
- `src/pipelines/deep_learning.py` linha 505 (train_single_config - verificaÃ§Ã£o)

**PrevenÃ§Ã£o**: Sempre verifique os logs durante inicializaÃ§Ã£o do pipeline:
```
âœ… Dispositivo configurado: cuda:0
âœ… GPU disponÃ­vel: NVIDIA GeForce RTX 3060
âœ… SimpleCNN estÃ¡ na GPU: NVIDIA GeForce RTX 3060
```

---

### âŒ Problema 8: "EOFError" ao Executar Scripts NÃ£o-Interativamente

**Erro completo**:
```
EOFError
```

**Causa**: Script usa `input()` para confirmaÃ§Ã£o do usuÃ¡rio em ambiente nÃ£o-interativo (CI/CD, scripts automatizados).

**Status**: âœ… **CORRIGIDO** - `scripts/create_subset.py` nÃ£o usa mais `input()` interativo.

**Se ainda ocorrer**: Verifique se estÃ¡ usando a versÃ£o mais recente do cÃ³digo.

---

### âŒ Problema 9: "UnicodeEncodeError" ao Executar verificar_pytorch.py no Windows

**Erro completo**:
```
UnicodeEncodeError: 'charmap' codec can't encode character '\u2705'
```

**Causa**: Console do Windows nÃ£o configurado para UTF-8.

**Status**: âœ… **CORRIGIDO** - `verificar_pytorch.py` agora usa `sys.stdout.reconfigure(encoding='utf-8')`.

**Se ainda ocorrer**: Execute no PowerShell com encoding UTF-8:
```powershell
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8
python verificar_pytorch.py
```

---

### âŒ Problema 10: Resultados Muito Diferentes Entre ExecuÃ§Ãµes

**Sintoma**: MÃ©tricas (accuracy, F1-score) variam muito entre execuÃ§Ãµes.

**Causas possÃ­veis**:
1. Sementes aleatÃ³rias nÃ£o fixadas
2. DivisÃ£o treino/teste nÃ£o fixada
3. Data augmentation muito agressiva

**SoluÃ§Ãµes**:

**SoluÃ§Ã£o 10.1: Verificar seeds fixadas**
```python
# O cÃ³digo jÃ¡ usa random_state=42 em vÃ¡rios lugares, mas verifique:
import random
import numpy as np
import torch

random.seed(42)
np.random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)
```

**SoluÃ§Ã£o 10.2: Desativar data augmentation temporariamente**
```python
# Em src/config.py
USE_AUGMENTATION = False  # Teste sem augmentation
```

**SoluÃ§Ã£o 10.3: Usar mais Ã©pocas**
```python
# Em src/config.py
EPOCHS = 100  # Mais Ã©pocas para estabilizar
```

---

### âŒ Problema 11: "FileNotFoundError: Modelo nÃ£o encontrado"

**Erro completo**:
```
FileNotFoundError: Modelo nÃ£o encontrado: outputs/models/svm_model.pkl
```

**Causa**: Tentando carregar modelo que nÃ£o foi treinado ainda.

**SoluÃ§Ã£o**:
```bash
# Treine o modelo primeiro
python main.py
# Escolha opÃ§Ã£o 1 (Pipeline ClÃ¡ssico) ou 2 (Deep Learning)
```

---

### âŒ Problema 12: Treinamento Muito Lento

**Sintoma**: Treinamento demora horas mesmo para datasets pequenos.

**Causas possÃ­veis**:
1. Usando CPU ao invÃ©s de GPU
2. Batch size muito pequeno
3. NÃºmero de Ã©pocas muito alto
4. Random Search com muitas iteraÃ§Ãµes

**SoluÃ§Ãµes**:

**SoluÃ§Ã£o 12.1: Verificar se estÃ¡ usando GPU**
```bash
python check_gpu.py
# Se GPU disponÃ­vel, verifique se USE_GPU = True em config.py
```

**SoluÃ§Ã£o 12.2: Aumentar batch size (se tiver memÃ³ria)**
```python
# Em src/config.py
BATCH_SIZE = 64  # Era 32
```

**SoluÃ§Ã£o 12.3: Reduzir Ã©pocas durante Random Search**
```python
# O cÃ³digo jÃ¡ limita: search_epochs = min(15, final_epochs)
# Mas vocÃª pode reduzir ainda mais editando o cÃ³digo
```

**SoluÃ§Ã£o 12.4: Reduzir nÃºmero de iteraÃ§Ãµes do Random Search**
```python
# No main.py ou ao chamar pipeline:
pipeline.train_svm(use_random_search=True, n_iter=10)  # Era 50
```

---

### âŒ Problema 13: Overfitting (Alta Accuracy no Treino, Baixa no Teste)

**Sintoma**: 
- Accuracy treino: 0.95+
- Accuracy teste: 0.70-0.80

**SoluÃ§Ãµes**:

**SoluÃ§Ã£o 13.1: Aumentar data augmentation**
```python
# Em src/config.py
USE_AUGMENTATION = True  # JÃ¡ estÃ¡ ativo
AUGMENTATION_PARAMS = {
    'rotation_range': 30,      # Aumentar de 20 para 30
    'zoom_range': 0.3,         # Aumentar de 0.2 para 0.3
    # ... outros parÃ¢metros
}
```

**SoluÃ§Ã£o 13.2: Aumentar dropout**
```python
# Para SimpleCNN, durante Random Search, o dropout varia de 0.3 a 0.7
# Modelo final usarÃ¡ o melhor encontrado, mas vocÃª pode forÃ§ar:
# (edite o cÃ³digo para usar dropout_rate fixo maior)
```

**SoluÃ§Ã£o 13.3: Reduzir complexidade do modelo**
```python
# Para SimpleCNN: reduzir hidden_units
# Para Random Forest: reduzir max_depth, n_estimators
```

**SoluÃ§Ã£o 13.4: Usar mais dados de treinamento**
- Baixar dataset maior
- NÃ£o limitar `CLASSIC_MAX_SAMPLES`

---

### âœ… Checklist de VerificaÃ§Ã£o Antes de Treinar

Antes de executar o pipeline, verifique:

- [ ] âœ… Todas as dependÃªncias instaladas: `pip install -r requirements.txt`
- [ ] âœ… Dataset organizado corretamente: `python diagnose_data.py`
- [ ] âœ… Pelo menos 2 classes detectadas
- [ ] âœ… GPU verificada (se usando deep learning): `python check_gpu.py`
- [ ] âœ… ConfiguraÃ§Ãµes de memÃ³ria ajustadas (se tiver pouco RAM)
- [ ] âœ… `CLASSIC_USE_PCA = True` (se usando SVM)
- [ ] âœ… `RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True` (se usando ResNet50)
- [ ] âœ… EspaÃ§o em disco suficiente para salvar modelos

---

### ğŸ“ Como Obter Mais Ajuda

Se nenhuma das soluÃ§Ãµes acima resolveu seu problema:

1. **Verifique os logs**: O cÃ³digo imprime informaÃ§Ãµes detalhadas durante execuÃ§Ã£o
2. **Execute scripts de diagnÃ³stico**: `verificar_pytorch.py`, `check_gpu.py`, `diagnose_data.py`
3. **Consulte a documentaÃ§Ã£o**: Este README contÃ©m todas as informaÃ§Ãµes
4. **Verifique versÃµes**: `pip list | grep torch` (verifique versÃµes compatÃ­veis)

---

## Requisitos do Sistema

- Python 3.7+
- CUDA (opcional, para GPU)
- RAM: MÃ­nimo 8GB (recomendado 16GB)
- EspaÃ§o em disco: Depende do tamanho da base de dados

## Autores

Projeto desenvolvido para disciplina de VisÃ£o Computacional.

## LicenÃ§a

Este projeto Ã© para fins educacionais.

# Atividade_Visao_Computacional_Residencia_IA
