# Projeto de Classifica√ß√£o de Imagens - Vis√£o Computacional
## Documenta√ß√£o Completa e Consolidada

> **Este README consolida TODA a documenta√ß√£o do projeto**, incluindo toda a hist√≥ria de desenvolvimento, erros encontrados, corre√ß√µes implementadas, otimiza√ß√µes, mudan√ßas de par√¢metros, ajustes de m√©todos, e exemplos de c√≥digo espec√≠ficos com explica√ß√µes detalhadas.

**Vers√£o do Projeto**: 1.0.0 (Final) **√öltima Atualiza√ß√£o**: 2024 **Status**: Est√°vel e Otimizado

---

## √çndice

1. [Vis√£o Geral do Projeto](#vis√£o-geral-do-projeto)
2. [Estrutura Completa do Projeto](#estrutura-completa-do-projeto)
3. [Instala√ß√£o e Configura√ß√£o](#instala√ß√£o-e-configura√ß√£o)
4. [Hist√≥ria Completa do Desenvolvimento](#hist√≥ria-completa-do-desenvolvimento) - [Erros Encontrados e Corrigidos](#erros-encontrados-e-corrigidos) - [Otimiza√ß√µes de Mem√≥ria](#otimiza√ß√µes-de-mem√≥ria) - [Corre√ß√µes de GPU](#corre√ß√µes-de-gpu) - [Sistema de Salvamento de Modelos](#sistema-de-salvamento-de-modelos) - [Random Search Otimizado](#random-search-otimizado)
5. [Configura√ß√µes Detalhadas](#configura√ß√µes-detalhadas)
6. [Exemplos de C√≥digo por Componente](#exemplos-de-c√≥digo-por-componente)
7. [Guia de Uso Completo](#guia-de-uso-completo)
8. [Troubleshooting](#troubleshooting)
9. [Refer√™ncias e Documenta√ß√£o T√©cnica](#refer√™ncias-e-documenta√ß√£o-t√©cnica)

---

## Vis√£o Geral do Projeto

Projeto completo de classifica√ß√£o de imagens (AI Art vs Human Art) utilizando m√∫ltiplas abordagens:
- **Pipeline Cl√°ssico**: SVM e Random Forest com otimiza√ß√£o de hiperpar√¢metros
- **Pipeline Deep Learning**: Simple CNN e ResNet50 com transfer learning
- **Otimiza√ß√µes Avan√ßadas**: Gerenciamento de mem√≥ria, lazy loading, limpeza autom√°tica
- **Sistema Completo**: Download autom√°tico de dataset, diagn√≥stico, salvamento de modelos

## Estrutura Completa do Projeto

```
.
‚îú‚îÄ‚îÄ main.py # Ponto de entrada principal com menu interativo
‚îú‚îÄ‚îÄ main_subset.py # Vers√£o para testes r√°pidos com subset (10 imagens/classe)
‚îú‚îÄ‚îÄ requirements.txt # Todas as depend√™ncias do projeto
‚îú‚îÄ‚îÄ README.md # Este arquivo - documenta√ß√£o completa consolidada
‚îÇ
‚îú‚îÄ‚îÄ Scripts de Diagn√≥stico/
‚îÇ ‚îú‚îÄ‚îÄ diagnose_data.py # Diagn√≥stico da estrutura de dados
‚îÇ ‚îú‚îÄ‚îÄ check_gpu.py # Verifica√ß√£o de GPU/CUDA
‚îÇ ‚îú‚îÄ‚îÄ verificar_pytorch.py # Verifica√ß√£o completa do PyTorch
‚îÇ ‚îú‚îÄ‚îÄ diagnose_gpu_usage.py # Diagn√≥stico de uso de GPU
‚îÇ ‚îî‚îÄ‚îÄ testar_gpu_direto.py # Teste direto de GPU sem depend√™ncias
‚îÇ
‚îú‚îÄ‚îÄ src/ # C√≥digo fonte principal
‚îÇ ‚îú‚îÄ‚îÄ __init__.py
‚îÇ ‚îú‚îÄ‚îÄ config.py # TODAS as configura√ß√µes centralizadas
‚îÇ ‚îú‚îÄ‚îÄ utils.py # Fun√ß√µes utilit√°rias (device, imagens, m√©tricas)
‚îÇ ‚îú‚îÄ‚îÄ datasets.py # LazyImageDataset para carregamento eficiente
‚îÇ ‚îú‚îÄ‚îÄ memory.py # Gerenciamento avan√ßado de mem√≥ria
‚îÇ ‚îú‚îÄ‚îÄ model_saver.py # Sistema de salvamento com metadados
‚îÇ ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ models/ # Defini√ß√µes de modelos
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ __init__.py
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ cnn.py # SimpleCNN - arquitetura customizada
‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ pipelines/ # Pipelines de treinamento
‚îÇ ‚îú‚îÄ‚îÄ __init__.py
‚îÇ ‚îú‚îÄ‚îÄ classic.py # Pipeline cl√°ssico (SVM, Random Forest)
‚îÇ ‚îî‚îÄ‚îÄ deep_learning.py # Pipeline deep learning (CNN, ResNet50)
‚îÇ
‚îú‚îÄ‚îÄ scripts/ # Scripts auxiliares
‚îÇ ‚îú‚îÄ‚îÄ __init__.py
‚îÇ ‚îú‚îÄ‚îÄ download_dataset.py # Download autom√°tico do dataset Kaggle
‚îÇ ‚îú‚îÄ‚îÄ create_subset.py # Cria√ß√£o de subset para testes r√°pidos
‚îÇ ‚îî‚îÄ‚îÄ load_model_example.py # Exemplo de como carregar modelos salvos
‚îÇ
‚îú‚îÄ‚îÄ data/ # Dados (ignorado pelo git)
‚îÇ ‚îú‚îÄ‚îÄ train/ # Imagens de treinamento
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ aiartdata/ # Classe 1: Arte gerada por IA
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ realart/ # Classe 2: Arte criada por humanos
‚îÇ ‚îú‚îÄ‚îÄ test/ # Imagens de teste
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ aiartdata/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ realart/
‚îÇ ‚îú‚îÄ‚îÄ train_subset/ # Subset pequeno para testes (10/classe)
‚îÇ ‚îî‚îÄ‚îÄ test_subset/ # Subset pequeno para testes (10/classe)
‚îÇ
‚îî‚îÄ‚îÄ outputs/ # Resultados gerados (ignorado pelo git) ‚îú‚îÄ‚îÄ models/ # Modelos treinados salvos ‚îÇ ‚îú‚îÄ‚îÄ svm_model.pkl # Modelo SVM ‚îÇ ‚îú‚îÄ‚îÄ svm_model.json # Metadados do SVM ‚îÇ ‚îú‚îÄ‚îÄ svm_scaler.pkl # Scaler usado no SVM ‚îÇ ‚îú‚îÄ‚îÄ random_forest_model.pkl  # Modelo Random Forest ‚îÇ ‚îú‚îÄ‚îÄ simple_cnn.pth # Modelo Simple CNN ‚îÇ ‚îú‚îÄ‚îÄ resnet50_transfer.pth # Modelo ResNet50 ‚îÇ ‚îî‚îÄ‚îÄ *.json # Metadados de cada modelo ‚îú‚îÄ‚îÄ results/ # Resultados em CSV ‚îÇ ‚îú‚îÄ‚îÄ classic_pipeline_results.csv ‚îÇ ‚îî‚îÄ‚îÄ deep_learning_results.csv ‚îî‚îÄ‚îÄ figures/ # Gr√°ficos e visualiza√ß√µes ‚îú‚îÄ‚îÄ svm_confusion_matrix.png ‚îú‚îÄ‚îÄ random_forest_confusion_matrix.png ‚îú‚îÄ‚îÄ simple_cnn_confusion_matrix.png ‚îî‚îÄ‚îÄ resnet50_confusion_matrix.png
```

### Arquivos de Documenta√ß√£o Consolidados

**Todos os arquivos `.md` anteriores foram consolidados neste README e removidos do projeto:**

- `ANALISE_CODIGO.md` - An√°lise completa do c√≥digo ‚Üí Se√ß√£o "Hist√≥ria Completa do Desenvolvimento"
- `ANALISE_GPU.md` - An√°lise de GPU ‚Üí Se√ß√£o "Corre√ß√µes de GPU"
- `ANALISE_LIMPEZA_PROJETO.md` - Limpeza realizada ‚Üí Integrado nas otimiza√ß√µes
- `ANALISE_MODELOS_CLASSICOS.md` - An√°lise de modelos cl√°ssicos ‚Üí Se√ß√£o "Pipeline Cl√°ssico"
- `GUIA_SALVAMENTO_MODELOS.md` - Sistema de salvamento ‚Üí Se√ß√£o "Sistema de Salvamento de Modelos"
- `RANDOM_SEARCH_ATUALIZADO.md` - Random Search otimizado ‚Üí Se√ß√£o "Random Search Otimizado"
- `RANDOM_SEARCH_TODOS_MODELOS.md` - Random Search em todos modelos ‚Üí Se√ß√£o "Random Search Otimizado"
- `SOLUCAO_ESTOURO_MEMORIA_RESNET50.md` - Solu√ß√£o ResNet50 ‚Üí Se√ß√£o "Otimiza√ß√µes de Mem√≥ria"
- `SOLUCAO_ESTOURO_MEMORIA_SVM.md` - Solu√ß√£o SVM ‚Üí Se√ß√£o "Otimiza√ß√µes de Mem√≥ria"
- `SOLUCAO_GPU_NAO_UTILIZADA.md` - Solu√ß√£o GPU ‚Üí Se√ß√£o "Corre√ß√µes de GPU"
- `VERIFICACAO_GPU.md` - Verifica√ß√£o GPU ‚Üí Se√ß√£o "Corre√ß√µes de GPU" e "Troubleshooting"

**Status**: Todos os arquivos foram removidos. Todo o conte√∫do est√° consolidado neste README.

---

# Hist√≥ria Completa do Desenvolvimento

Esta se√ß√£o documenta **TUDO** que foi realizado durante o desenvolvimento do projeto, desde os erros iniciais at√© as otimiza√ß√µes finais.

### üìÖ Cronologia de Desenvolvimento

#### **Fase 1: Problemas Iniciais com Dataset**

**Problema 1.1: Apenas 1 Classe Detectada**
- **Erro**: `ValueError: Apenas 1 classe(s) foi(ram) carregada(s), mas s√£o necess√°rias pelo menos 2 classes para classifica√ß√£o.`
- **Causa**: Script `download_dataset.py` n√£o identificava corretamente as classes "AiArtData" e "RealArt"
- **Localiza√ß√£o**: `scripts/download_dataset.py`, fun√ß√£o `find_class_directories()`
- **Corre√ß√£o Implementada**:

```python
# scripts/download_dataset.py - LINHAS CORRIGIDAS
def find_class_directories(directory): """Encontra diret√≥rios de classes no dataset""" classes = [] for item in Path(directory).iterdir(): if item.is_dir(): # CORRE√á√ÉO: Busca case-insensitive e varia√ß√µes de nomes name_lower = item.name.lower() if 'aiart' in name_lower or 'ai_art' in name_lower: classes.append(('aiartdata', item)) elif 'realart' in name_lower or 'real_art' in name_lower or 'human' in name_lower: classes.append(('realart', item)) return classes
```

**Impacto**:  Permite detectar classes independente de varia√ß√µes de nomenclatura

--- **Problema 1.2: EOFError em Script N√£o-Interativo**
- **Erro**: `EOFError` ao executar `scripts/create_subset.py` de forma n√£o-interativa
- **Causa**: Uso de `input()` para confirma√ß√£o do usu√°rio
- **Localiza√ß√£o**: `scripts/create_subset.py`
- **Corre√ß√£o Implementada**:

```python
# scripts/create_subset.py - ANTES (com erro):
if backup_exists: resposta = input("Subset j√° existe. Substituir? (s/n): ")  #  Causa EOFError if resposta.lower() != 's': return

# scripts/create_subset.py - DEPOIS (corrigido):
# REMOVIDO: Prompt interativo que causava EOFError
# AGORA: Cria subset automaticamente, criando classes artificiais se necess√°rio
if len(class_dirs) < 2: print("Apenas 1 classe encontrada. Criando classes artificiais (classe_a, classe_b)...") # Cria subset com nomes artificiais
```

**Impacto**:  Script pode ser executado em ambientes n√£o-interativos (CI/CD, scripts automatizados)

---

# **Fase 2: Erros em Modelos Deep Learning**

**Problema 2.1: TypeError no ReduceLROnPlateau**
- **Erro**: `TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'`
- **Causa**: PyTorch vers√£o n√£o suporta par√¢metro `verbose` em `ReduceLROnPlateau`
- **Localiza√ß√£o**: `src/pipelines/deep_learning.py`, linhas 473-475 e 548-550
- **C√≥digo Antes (com erro)**:

```python
# src/pipelines/deep_learning.py - ANTES (linha 473):
scheduler = optim.lr_scheduler.ReduceLROnPlateau( optimizer, mode='min', factor=0.5, patience=5, verbose=True  #  Erro: verbose n√£o existe
)
```

- **C√≥digo Depois (corrigido)**:

```python
# src/pipelines/deep_learning.py - DEPOIS (linha 599):
scheduler = optim.lr_scheduler.ReduceLROnPlateau( optimizer, mode='min', factor=0.5, patience=5  #  Removido verbose
)
```

**Impacto**:  Compat√≠vel com todas as vers√µes do PyTorch

--- **Problema 2.2: AttributeError com setup_device**
- **Erro**: `AttributeError: 'str' object has no attribute 'type'`
- **Causa**: Fun√ß√£o `setup_device()` poderia retornar string `'cpu'` ao inv√©s de `torch.device('cpu')`
- **Localiza√ß√£o**: `src/utils.py`, fun√ß√£o `setup_device()` e `src/pipelines/deep_learning.py`
- **C√≥digo Antes (com erro)**:

```python
# src/utils.py - ANTES:
def setup_device(use_gpu=True): # ... if use_gpu and not torch.cuda.is_available(): return 'cpu'  #  Retorna string, n√£o torch.device # src/pipelines/deep_learning.py - ANTES:
self.device = setup_device(use_gpu)
if self.device.type == 'cuda':  #  Erro se device for string 'cpu' ...
```

- **C√≥digo Depois (corrigido)**:

```python
# src/utils.py - DEPOIS (linha 62, 122):
def setup_device(use_gpu=True): # ... if use_gpu and not torch.cuda.is_available(): return torch.device('cpu')  #  Sempre retorna torch.device # ... else: # ... return torch.device('cpu')  #  Sempre retorna torch.device
```

- **Verifica√ß√£o Adicional em deep_learning.py (linhas 129-161)**:

```python
# src/pipelines/deep_learning.py - DEPOIS (linha 130-161):
# Garantir que device √© torch.device
if isinstance(self.device, str): print(f" Dispositivo √© string '{self.device}', convertendo para torch.device...") self.device = torch.device(self.device)
elif not isinstance(self.device, torch.device): print(f" Tipo desconhecido, usando CPU...") self.device = torch.device('cpu')
```

**Impacto**:  Dispositivo sempre √© objeto `torch.device`, evitando erros de atributo

--- **Problema 2.3: Modelos N√£o Estavam Usando GPU**
- **Erro**: Modelos deep learning executavam na CPU mesmo com GPU dispon√≠vel
- **Causa**: Modelos n√£o eram movidos explicitamente para GPU ap√≥s cria√ß√£o
- **Localiza√ß√£o**: M√∫ltiplas fun√ß√µes em `src/pipelines/deep_learning.py`
- **Corre√ß√µes Implementadas**:

**2.3.1: ResNet50 n√£o movido para GPU** (linha 1049-1061):
```python
# src/pipelines/deep_learning.py - ANTES (create_resnet_model):
model = models.resnet50(weights='IMAGENET1K_V2')
# ... configurar modelo ...
return model  #  Modelo fica na CPU

# src/pipelines/deep_learning.py - DEPOIS (linha 1049-1061):
model = models.resnet50(weights='IMAGENET1K_V2')
# ... configurar modelo ...

# CR√çTICO: Mover modelo para dispositivo correto (GPU ou CPU)
model = model.to(self.device)

# Verificar dispositivo e mostrar informa√ß√µes
model_device = next(model.parameters()).device
if model_device.type == 'cuda': print(f" ResNet50 est√° na GPU: {torch.cuda.get_device_name(model_device.index or 0)}")
else: print(f" ResNet50 est√° na CPU")

return model  #  Modelo est√° no dispositivo correto
```

**2.3.2: SimpleCNN n√£o movido no Random Search** (linha 798-804):
```python
# src/pipelines/deep_learning.py - ANTES (train_simple_cnn - Random Search):
model = SimpleCNN( self.num_classes, dropout_rate=params['dropout_rate'], hidden_units=params['hidden_units']
)
# Modelo criado mas n√£o movido para GPU
val_acc, _, iter_time = self.train_single_config(...)

# src/pipelines/deep_learning.py - DEPOIS (linha 798-804):
model = SimpleCNN(...)

# CR√çTICO: Mover modelo para dispositivo correto ANTES do treinamento
model = model.to(self.device)

# Verificar dispositivo (apenas na primeira itera√ß√£o)
if i == 0: model_device = next(model.parameters()).device print(f" Modelo SimpleCNN criado e movido para: {model_device}") if model_device.type == 'cuda': print(f" SimpleCNN est√° na GPU: {torch.cuda.get_device_name(model_device.index or 0)}")
```

**2.3.3: SimpleCNN n√£o movido no treinamento final** (linha 831-842):
```python
# src/pipelines/deep_learning.py - DEPOIS (linha 831-842):
model = SimpleCNN(...)

# CR√çTICO: Mover modelo para dispositivo correto ANTES do treinamento
model = model.to(self.device)

# Verificar dispositivo do modelo
model_device = next(model.parameters()).device
print(f"\nModelo SimpleCNN criado:")
print(f"  Dispositivo: {model_device}")
if model_device.type == 'cuda': print(f" SimpleCNN est√° na GPU: {torch.cuda.get_device_name(model_device.index or 0)}")
```

**2.3.4: Melhorias em train_single_config e train_model**:
```python
# src/pipelines/deep_learning.py - DEPOIS (linha 505-507):
def train_single_config(self, model, train_loader, val_loader, epochs, learning_rate, patience=5): # Garantir que modelo est√° no dispositivo correto if next(model.parameters()).device != self.device: print(f" [AVISO] Movendo modelo de {next(model.parameters()).device} para {self.device}") model = model.to(self.device)
```

```python
# src/pipelines/deep_learning.py - DEPOIS (linha 601-605):
def train_model(self, model, train_loader, epochs, learning_rate, model_name): # Garantir que modelo est√° no dispositivo correto if next(model.parameters()).device != self.device: print(f" [AVISO] Movendo modelo {model_name} de {next(model.parameters()).device} para {self.device}") model = model.to(self.device)
```

**Impacto**:  Todos os modelos agora usam GPU automaticamente quando dispon√≠vel

---

# **Fase 3: Estouro de Mem√≥ria - SVM**

**Problema 3.1: Estouro de Mem√≥ria no SVM**
- **Erro**: `MemoryError` ou sistema travando durante treinamento do SVM
- **Causa**: Imagens muito grandes (224x224x3) + kernel RBF + CV folds m√∫ltiplos
- **An√°lise do Problema**:

```
ANTES (Problema):
- Imagens: 224x224x3 = 150,528 features por imagem
- 10.000 amostras: 150,528 √ó 10.000 = 1.5 bilh√µes de features
- Mem√≥ria necess√°ria: ~12 GB apenas para dados
- Matriz Gram (RBF kernel): ~800 MB - 8 GB
- CV=3: M√∫ltiplas c√≥pias dos dados
- n_jobs=-1: M√∫ltiplos processos duplicando dados
- TOTAL: ~15-20 GB de RAM necess√°ria!
```

- **Solu√ß√µes Implementadas** (c√≥digo em `src/config.py` e `src/pipelines/classic.py`):

**Solu√ß√£o 3.1.1: Tamanho de Imagem Reduzido** (linha 29 em `config.py`):
```python
# src/config.py - NOVA CONFIGURA√á√ÉO (linha 29):
IMG_SIZE_CLASSIC = (64, 64)  # Tamanho menor para modelos cl√°ssicos (economiza mem√≥ria)
IMG_SIZE = (224, 224)  # Mantido para deep learning
```

**Implementa√ß√£o em classic.py (linha 94-95)**:
```python
# src/pipelines/classic.py - ANTES:
X_train, y_train, self.class_names = load_images_from_directory( self.train_dir, img_size=(224, 224)  #  Muito grande

# src/pipelines/classic.py - DEPOIS (linha 94-95):
X_train, y_train, self.class_names = load_images_from_directory( self.train_dir, img_size=IMG_SIZE_CLASSIC  #  64x64
)
```

**Redu√ß√£o**: 150,528 features ‚Üí 12,288 features (92% redu√ß√£o!)

--- **Solu√ß√£o 3.1.2: PCA para Redu√ß√£o de Dimensionalidade** (linha 102-103, 154-179 em `classic.py`):
```python
# src/config.py - NOVAS CONFIGURA√á√ïES (linhas 102-103):
CLASSIC_USE_PCA = True  # Usar PCA para redu√ß√£o de dimensionalidade
CLASSIC_PCA_COMPONENTS = 500  # N√∫mero de componentes PCA
```

**Implementa√ß√£o em classic.py (linha 154-179)**:
```python
# src/pipelines/classic.py - NOVO C√ìDIGO (linha 152-179):
# PCA para redu√ß√£o de dimensionalidade (opcional)
self.pca = None
if CLASSIC_USE_PCA: print(f"\n Aplicando PCA para redu√ß√£o de dimensionalidade...") if CLASSIC_PCA_COMPONENTS is None: # Auto: reduzir para 95% vari√¢ncia self.pca = PCA(n_components=0.95, random_state=42) print(f" Modo: Auto (95% vari√¢ncia explicada)") else: # N√∫mero fixo de componentes n_components = min(CLASSIC_PCA_COMPONENTS, min(n_samples - 1, n_features)) self.pca = PCA(n_components=n_components, random_state=42) print(f" Modo: Fixo ({n_components} componentes)") # CR√çTICO: fit_transform apenas no treino, transform no teste X_train_scaled = self.pca.fit_transform(X_train_scaled)  #  Aprende componentes X_test_scaled = self.pca.transform(X_test_scaled)  #  Usa componentes aprendidos n_features_after_pca = X_train_scaled.shape[1] reduction = ((n_features - n_features_after_pca) / n_features) * 100 estimated_mem_after_gb = (n_samples * n_features_after_pca * 8) / (1024**3) print(f" Features ap√≥s PCA: {n_features_after_pca:,} ({reduction:.1f}% redu√ß√£o)") print(f" Mem√≥ria estimada ap√≥s PCA: {estimated_mem_after_gb:.2f} GB") if hasattr(self.pca, 'explained_variance_ratio_'): total_variance = self.pca.explained_variance_ratio_.sum() print(f" Vari√¢ncia explicada: {total_variance:.2%}")
```

**Redu√ß√£o**: 12,288 features ‚Üí 500 componentes (96% redu√ß√£o adicional!)

**Total**: 150,528 features ‚Üí 500 componentes = **99.67% de redu√ß√£o!**

--- **Solu√ß√£o 3.1.3: LinearSVC como Alternativa** (linha 104 em `config.py`, linha 248-280 em `classic.py`):
```python
# src/config.py - NOVA CONFIGURA√á√ÉO (linha 104):
CLASSIC_USE_LINEAR_SVM = False  # False = SVC (kernels), True = LinearSVC (s√≥ linear, mais eficiente)
```

**Implementa√ß√£o em classic.py (linha 248-280)**:
```python
# src/pipelines/classic.py - NOVO C√ìDIGO (linha 248-280):
use_linear_svm = CLASSIC_USE_LINEAR_SVM
if use_linear_svm: print(f" Tipo: LinearSVC (kernel linear, mais eficiente em mem√≥ria)")
else: print(f" Tipo: SVC (suporta kernels n√£o-lineares, mas usa mais mem√≥ria)")

if use_random_search: if use_linear_svm: # LinearSVC: apenas kernel linear, menos par√¢metros param_distributions = { 'C': loguniform(0.01, 100), 'loss': ['hinge', 'squared_hinge'], 'class_weight': [None, 'balanced'], 'dual': [True, False]  # False pode ser mais r√°pido para n_samples > n_features } svm = LinearSVC(random_state=42, max_iter=2000) else: # SVC tradicional: m√∫ltiplos kernels param_distributions = { 'C': loguniform(0.01, 100), 'gamma': loguniform(0.0001, 1), 'kernel': ['rbf', 'linear', 'poly'], 'degree': randint(2, 5), 'class_weight': [None, 'balanced'] } svm = SVC(random_state=42)
```

**Benef√≠cio**: LinearSVC n√£o calcula matriz Gram, economizando 70-90% de mem√≥ria adicional

--- **Solu√ß√£o 3.1.4: Limita√ß√£o de Amostras** (linha 105 em `config.py`, linha 127-133 em `classic.py`):
```python
# src/config.py - NOVA CONFIGURA√á√ÉO (linha 105):
CLASSIC_MAX_SAMPLES = None  # None = usar todas, ou n√∫mero m√°ximo (ex: 10000)
```

**Implementa√ß√£o em classic.py (linha 127-133)**:
```python
# src/pipelines/classic.py - NOVO C√ìDIGO (linha 127-133):
# Limitar n√∫mero de amostras se configurado
if CLASSIC_MAX_SAMPLES is not None and len(X_train) > CLASSIC_MAX_SAMPLES: print(f"\n  AVISO: Limitando amostras de treinamento de {len(X_train)} para {CLASSIC_MAX_SAMPLES}") indices = np.random.choice(len(X_train), CLASSIC_MAX_SAMPLES, replace=False) X_train = X_train[indices] y_train = y_train[indices] print(f" Amostras selecionadas aleatoriamente mantendo propor√ß√£o de classes")
```

--- **Solu√ß√£o 3.1.5: Configura√ß√µes de CV e Paraleliza√ß√£o** (linhas 106-108 em `config.py`):
```python
# src/config.py - NOVAS CONFIGURA√á√ïES (linhas 106-108):
CLASSIC_SVM_N_JOBS = 1  # 1 = sem paraleliza√ß√£o (economiza mem√≥ria), -1 = todos os cores
CLASSIC_RF_N_JOBS = -1  # Random Forest pode usar mais cores (mais eficiente)
CLASSIC_CV_FOLDS = 2  # 2 ao inv√©s de 3 para economizar mem√≥ria - aplica-se a TODOS os modelos cl√°ssicos
```

**Implementa√ß√£o em classic.py - SVM (linha 244, 282-285)**:
```python
# src/pipelines/classic.py - NOVO C√ìDIGO (linha 244):
svm_n_jobs = CLASSIC_SVM_N_JOBS if CLASSIC_SVM_N_JOBS is not None else 1
print(f"\n Paraleliza√ß√£o SVM: {svm_n_jobs} job(s) (configurado para economizar mem√≥ria)")

# Linha 282-285:
random_search = RandomizedSearchCV( svm, param_distributions, n_iter=n_iter, cv=CLASSIC_CV_FOLDS,  #  CV configur√°vel scoring='accuracy', n_jobs=svm_n_jobs, verbose=1, random_state=42  #  n_jobs configur√°vel
)
```

**Implementa√ß√£o em classic.py - Random Forest (linha 420-443)**:
```python
# src/pipelines/classic.py - NOVO C√ìDIGO (linha 420-443):
# Determinar jobs para Random Forest (pode usar mais paraleliza√ß√£o que SVM)
rf_n_jobs = CLASSIC_RF_N_JOBS if CLASSIC_RF_N_JOBS is not None else self.n_jobs
if rf_n_jobs == -1: actual_jobs = self.num_cores
else: actual_jobs = rf_n_jobs
print(f" Paraleliza√ß√£o: {actual_jobs} job(s) paralelo(s) (Random Forest pode usar mais cores eficientemente)")

# ...
rf = RandomForestClassifier(random_state=42, n_jobs=rf_n_jobs)  #  n_jobs espec√≠fico para RF
random_search = RandomizedSearchCV( rf, param_distributions, n_iter=n_iter, cv=CLASSIC_CV_FOLDS,  #  CV configur√°vel scoring='accuracy', n_jobs=rf_n_jobs, verbose=1, random_state=42  #  n_jobs espec√≠fico
)
```

**Redu√ß√£o de Mem√≥ria**:
- CV folds: 3 ‚Üí 2 = 33% menos c√≥pias de dados
- n_jobs: -1 ‚Üí 1 = Sem duplica√ß√£o de dados em m√∫ltiplos processos

--- **Solu√ß√£o 3.1.6: Verifica√ß√£o de Mem√≥ria Antes de Treinar** (linha 227-241 em `classic.py`):
```python
# src/pipelines/classic.py - NOVO C√ìDIGO (linha 227-241):
# Verificar mem√≥ria antes de treinar
n_samples, n_features = self.X_train.shape
estimated_mem_gb = (n_samples * n_features * 8 * CLASSIC_CV_FOLDS) / (1024**3)
print(f"\n Verifica√ß√£o de mem√≥ria:")
print(f" Amostras: {n_samples:,}")
print(f" Features: {n_features:,}")
print(f" Mem√≥ria estimada para treinamento: ~{estimated_mem_gb:.2f} GB")

if not check_available_memory(estimated_mem_gb, safety_margin=0.3): print(f" AVISO: Mem√≥ria estimada pode exceder dispon√≠vel!") print(f" Recomenda√ß√µes:") print(f" - Reduzir CLASSIC_MAX_SAMPLES em config.py") print(f" - Ativar CLASSIC_USE_PCA = True") print(f" - Usar CLASSIC_USE_LINEAR_SVM = True") print(f" - Reduzir CLASSIC_CV_FOLDS para 2")
```

**Fun√ß√£o check_available_memory em src/memory.py**:
```python
# src/memory.py - Fun√ß√£o implementada:
def check_available_memory(required_gb, safety_margin=0.2): """ Verifica se h√° mem√≥ria dispon√≠vel suficiente Args: required_gb: Mem√≥ria necess√°ria em GB safety_margin: Margem de seguran√ßa (padr√£o: 20%) Returns: bool: True se h√° mem√≥ria suficiente """ memory = psutil.virtual_memory() available_gb = memory.available / (1024 ** 3) required_with_margin = required_gb * (1 + safety_margin) return available_gb >= required_with_margin
```

**Resultado Final das Otimiza√ß√µes SVM**:
- **Antes**: ~15-20 GB necess√°rios
- **Depois**: ~1-2 GB necess√°rios
- **Redu√ß√£o**: ~90-95% de mem√≥ria economizada! --- #### **Fase 4: Estouro de Mem√≥ria - ResNet50**

**Problema 4.1: Estouro de Mem√≥ria no ResNet50**
- **Erro**: `RuntimeError: CUDA out of memory` durante Random Search do ResNet50
- **Causa**: Modelos acumulando na GPU entre itera√ß√µes do Random Search + batch sizes grandes
- **An√°lise do Problema**:

```
ANTES (Problema):
- ResNet50: ~25 milh√µes de par√¢metros
- Batch size: [16, 32, 64] testados
- Imagens: 224x224x3
- Por batch (size 32): ~850 MB de GPU
- Sem limpeza entre itera√ß√µes: M√∫ltiplos modelos acumulados
- Cache CUDA n√£o limpo: Mem√≥ria fragmentada
- TOTAL: 8 GB GPU insuficiente ap√≥s algumas itera√ß√µes!
```

- **Solu√ß√µes Implementadas**:

**Solu√ß√£o 4.1.1: Configura√ß√µes Espec√≠ficas para ResNet50** (linhas 84-95 em `config.py`):
```python
# src/config.py - NOVAS CONFIGURA√á√ïES (linhas 84-95):
# Batch sizes para Random Search do ResNet50 (REDUZIDOS)
RESNET50_BATCH_SIZES = [8, 16, 32]  # Era [16, 32, 64] - 50% menor

# Batch size padr√£o para ResNet50
RESNET50_DEFAULT_BATCH_SIZE = 16  # Era 32 - 50% menor

# √âpocas para Random Search (limitadas)
RESNET50_SEARCH_EPOCHS = 10  # N√∫mero m√°ximo de √©pocas durante Random Search

# Limpar mem√≥ria entre itera√ß√µes (CR√çTICO)
RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True  # IMPORTANTE: Limpar entre itera√ß√µes
```

--- **Solu√ß√£o 4.1.2: Limpeza de Mem√≥ria Entre Itera√ß√µes** (linhas 1098-1145 em `deep_learning.py`):
```python
# src/pipelines/deep_learning.py - NOVO C√ìDIGO (linhas 1098-1145):
if use_random_search: print(f"\nExecutando Random Search ({n_iter} itera√ß√µes)...") print(f"  Batch sizes testados: {RESNET50_BATCH_SIZES}") print(f"  √âpocas por itera√ß√£o: {RESNET50_SEARCH_EPOCHS}") print(f"  Limpeza de mem√≥ria entre itera√ß√µes: {'Ativada' if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS else 'Desativada'}") for i in range(n_iter): # Limpar ANTES de cada itera√ß√£o if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS: clear_memory(clear_gpu=True)  #  Limpa cache CUDA train_loader, val_loader, _ = self.create_dataloaders( params['batch_size'], val_split=0.2 ) model = self.create_resnet_model(unfreeze_layers=params['unfreeze_layers']) try: val_acc, trained_model, iter_time = self.train_single_config(...) # ... processamento ... except RuntimeError as e: if 'out of memory' in str(e).lower(): print(f" [ERRO] Estouro de mem√≥ria na itera√ß√£o {i+1}!") clear_memory(clear_gpu=True) # Tentar com batch size menor if params['batch_size'] > min(RESNET50_BATCH_SIZES): params['batch_size'] = params['batch_size'] // 2 continue finally: # Limpar AP√ìS cada itera√ß√£o (CR√çTICO) if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS: # Mover modelo para CPU antes de deletar if 'trained_model' in locals(): trained_model = trained_model.cpu() if 'model' in locals(): model = model.cpu() del model, trained_model clear_memory(clear_gpu=True)  #  Limpa cache CUDA # Mostrar status de mem√≥ria if torch.cuda.is_available() and self.device.type == 'cuda': gpu_mem_used = torch.cuda.memory_allocated() / (1024**3) print(f" Mem√≥ria GPU ap√≥s limpeza: {gpu_mem_used:.2f} GB")
```

**Fun√ß√£o clear_memory em src/memory.py (linha 150-158)**:
```python
# src/memory.py - Fun√ß√£o implementada (linha 150-158):
def clear_memory(clear_gpu=False): """Limpa mem√≥ria RAM e opcionalmente GPU""" import gc gc.collect()  # Garbage collection Python # Limpar cache GPU if clear_gpu and TORCH_AVAILABLE and torch.cuda.is_available(): torch.cuda.empty_cache()  #  Limpa cache CUDA torch.cuda.synchronize()  #  Sincroniza opera√ß√µes
```

**Impacto**: Libera ~2-4 GB de mem√≥ria GPU entre itera√ß√µes

--- **Solu√ß√£o 4.1.3: Verifica√ß√£o de Mem√≥ria Antes de Carregar Modelo** (linhas 1007-1029 em `deep_learning.py`):
```python
# src/pipelines/deep_learning.py - NOVO C√ìDIGO (linhas 1007-1029):
# Verificar mem√≥ria dispon√≠vel antes de carregar modelo grande
print(f"\n Verificando mem√≥ria antes de carregar ResNet50...")
ram_used, ram_total, ram_percent = self.memory_monitor.get_ram_usage()
print(f" RAM: {ram_used:.2f} GB / {ram_total:.2f} GB ({ram_percent*100:.1f}%)")

if torch.cuda.is_available() and self.device.type == 'cuda': gpu_mem_used = torch.cuda.memory_allocated() / (1024**3) gpu_mem_total = torch.cuda.get_device_properties(0).total_memory / (1024**3) gpu_mem_percent = (gpu_mem_used / gpu_mem_total) * 100 if gpu_mem_total > 0 else 0 print(f" GPU: {gpu_mem_used:.2f} GB / {gpu_mem_total:.2f} GB ({gpu_mem_percent:.1f}%)") # Aviso se mem√≥ria GPU estiver alta if gpu_mem_percent > 80: print(f" [AVISO] Mem√≥ria GPU alta! Limpando cache...") clear_memory(clear_gpu=True)

# Aviso se RAM estiver alta
if ram_percent > MEMORY_WARNING_THRESHOLD: print(f" [AVISO] Mem√≥ria RAM alta ({ram_percent*100:.1f}%)! Limpando mem√≥ria...") clear_memory(clear_gpu=False)

# Limpar mem√≥ria antes de carregar modelo
clear_memory(clear_gpu=True)
```

**Impacto**: Previne estouros antecipadamente

--- **Solu√ß√£o 4.1.4: Limpeza no train_single_config** (linha 589-591 em `deep_learning.py`):
```python
# src/pipelines/deep_learning.py - NOVO C√ìDIGO (linha 589-591):
def train_single_config(self, model, train_loader, val_loader, epochs, learning_rate, patience=5): # ... treinamento ... train_time = time.time() - start_time # Limpar mem√≥ria ao final (importante para Random Search) clear_memory(clear_gpu=True)  #  Nova linha return best_val_acc, model, train_time
```

**Resultado Final das Otimiza√ß√µes ResNet50**:
- **Antes**: Estouro ap√≥s 2-3 itera√ß√µes do Random Search
- **Depois**: Executa todas as 10 itera√ß√µes sem problemas
- **Redu√ß√£o**: ~50% menos mem√≥ria por batch + limpeza autom√°tica

---

# Instala√ß√£o

### Requisitos do Sistema

- **Python**: 3.7 ou superior
- **RAM**: M√≠nimo 8 GB (recomendado 16 GB para datasets grandes)
- **GPU**: Opcional, mas recomendado para deep learning (CUDA 11.8+)
- **Espa√ßo em Disco**: Depende do tamanho do dataset (~1-5 GB)

### Instala√ß√£o de Depend√™ncias

```bash
pip install -r requirements.txt
```

**Depend√™ncias principais** (veja `requirements.txt` completo):
- `torch>=2.0.0` - PyTorch para deep learning
- `torchvision>=0.15.0` - Modelos pr√©-treinados (ResNet50)
- `scikit-learn>=1.3.0` - SVM, Random Forest, PCA, StandardScaler
- `opencv-python>=4.8.0` - Processamento de imagens
- `matplotlib>=3.7.0`, `seaborn>=0.12.0` - Visualiza√ß√µes
- `pandas>=2.0.0`, `numpy>=1.24.0` - Manipula√ß√£o de dados
- `joblib>=1.3.0` - Salvamento de modelos
- `Pillow>=10.0.0` - Processamento de imagens
- `kagglehub>=0.2.0` - Download de datasets Kaggle
- `psutil>=5.9.0` - Monitoramento de mem√≥ria
- `scipy>=1.10.0` - Distribui√ß√µes para Random Search

Ou instale manualmente:

```bash
# Core Deep Learning
pip install torch torchvision

# Machine Learning Cl√°ssico
pip install scikit-learn scipy

# Processamento de Imagens
pip install opencv-python Pillow

# Visualiza√ß√£o e An√°lise
pip install matplotlib seaborn pandas numpy

# Utilit√°rios
pip install joblib kagglehub psutil
```

### Verifica√ß√£o de Instala√ß√£o

Execute os scripts de diagn√≥stico para verificar se tudo est√° instalado corretamente:

```bash
# Verificar PyTorch e CUDA
python verificar_pytorch.py

# Verificar GPU
python check_gpu.py

# Verificar estrutura de dados
python diagnose_data.py
```

### Configura√ß√£o do Kaggle (Opcional)

Para usar o dataset do Kaggle automaticamente:

1. **Criar conta no Kaggle**: https://www.kaggle.com/
2. **Aceitar termos do dataset**: Acesse [AI Art vs Human Art](https://www.kaggle.com/datasets/hassnainzaidi/ai-art-vs-human-art) e aceite os termos
3. **Configurar credenciais** (opcional): ```bash # Linux/Mac mkdir -p ~/.kaggle cp kaggle.json ~/.kaggle/ chmod 600 ~/.kaggle/kaggle.json # Windows # Copie kaggle.json para: C:\Users\<username>\.kaggle\kaggle.json ```

### Configura√ß√£o do Kaggle

Para usar o dataset do Kaggle, voc√™ precisa:

1. **Criar uma conta no Kaggle**: https://www.kaggle.com/
2. **Aceitar os termos do dataset**: Acesse o dataset [AI Art vs Human Art](https://www.kaggle.com/datasets/hassnainzaidi/ai-art-vs-human-art) e aceite os termos
3. **Configurar credenciais do Kaggle** (opcional, mas recomendado): - Baixe seu arquivo `kaggle.json` das configura√ß√µes da conta - Coloque em `~/.kaggle/kaggle.json` (Linux/Mac) ou `C:\Users\<username>\.kaggle\kaggle.json` (Windows)

---

## Sistema de Salvamento de Modelos com Metadados

### Problema Identificado

O projeto n√£o tinha sistema unificado para salvar modelos treinados com suas m√©tricas e configura√ß√µes. Isso dificultava:
- Comparar modelos salvos
- Reproduzir resultados
- Entender configura√ß√µes usadas
- Carregar modelos para predi√ß√µes futuras

### Solu√ß√£o Implementada

**Novo m√≥dulo criado**: `src/model_saver.py` com 3 fun√ß√µes principais:

#### **1. `save_model_with_metadata()` - Salva Modelo com Metadados**

**Localiza√ß√£o**: `src/model_saver.py`, linhas 11-45

**Assinatura**:
```python
def save_model_with_metadata(model, model_path, metadata, model_type='pytorch'): """ Salva modelo com metadados completos Args: model: Modelo a ser salvo model_path: Caminho para salvar o modelo metadata: Dicion√°rio com metadados (m√©tricas, hiperpar√¢metros, etc.) model_type: Tipo do modelo ('pytorch' ou 'sklearn') """
```

**Implementa√ß√£o para PyTorch** (linha 25-31):
```python
# src/model_saver.py - LINHA 25-31:
if model_type == 'pytorch': import torch torch.save({ 'model_state_dict': model.state_dict(),  #  Salva apenas pesos (mais leve) 'model_class': model.__class__.__name__,  #  Nome da classe para reconstru√ß√£o 'metadata': metadata  #  Metadados inclu√≠dos no checkpoint }, model_path)
```

**Implementa√ß√£o para scikit-learn** (linha 32-37):
```python
# src/model_saver.py - LINHA 32-37:
elif model_type == 'sklearn': import joblib joblib.dump({ 'model': model,  #  Modelo completo 'metadata': metadata  #  Metadados inclu√≠dos }, model_path)
```

**Salvamento de Metadados em JSON** (linha 39-42):
```python
# src/model_saver.py - LINHA 39-42:
# Salvar metadados em JSON separado (f√°cil de ler e editar)
metadata_path = model_path.with_suffix('.json')
with open(metadata_path, 'w', encoding='utf-8') as f: json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
```

**Uso no Pipeline Cl√°ssico - SVM** (linha 358-363 em `classic.py`):
```python
# src/pipelines/classic.py - LINHA 358-363:
model_path = MODELS_DIR / 'svm_model.pkl'
save_model_with_metadata( model=self.svm_model, model_path=model_path, metadata=metadata, model_type='sklearn'  #  Tipo espec√≠fico para scikit-learn
)
```

**Uso no Pipeline Deep Learning - SimpleCNN** (linha 966-972 em `deep_learning.py`):
```python
# src/pipelines/deep_learning.py - LINHA 966-972:
model_path = MODELS_DIR / 'simple_cnn.pth'
save_model_with_metadata( model=model, model_path=model_path, metadata=metadata, model_type='pytorch'  #  Tipo espec√≠fico para PyTorch
)
```

---

# **2. `create_model_metadata()` - Cria Dicion√°rio de Metadados**

**Localiza√ß√£o**: `src/model_saver.py`, linhas 90-118

**Assinatura**:
```python
def create_model_metadata(model_name, metrics, hyperparams, training_info, class_names, model_params=None): """ Cria dicion√°rio de metadados para um modelo Args: model_name: Nome do modelo metrics: Dicion√°rio com m√©tricas (accuracy, precision, etc.) hyperparams: Dicion√°rio com hiperpar√¢metros training_info: Dicion√°rio com informa√ß√µes de treinamento class_names: Lista de nomes das classes model_params: Par√¢metros usados para inicializar a classe do modelo (para PyTorch) Returns: metadata: Dicion√°rio com metadados completos """
```

**Estrutura de Metadados Retornada** (linha 104-118):
```python
# src/model_saver.py - LINHA 104-118:
return { 'model_name': model_name,  # Ex: 'SVM', 'SimpleCNN', 'ResNet50' 'timestamp': datetime.now().isoformat(),  #  Data/hora do salvamento 'metrics': { 'accuracy': float(metrics.get('accuracy', 0)),  #  Convertido para float 'precision': float(metrics.get('precision', 0)), 'recall': float(metrics.get('recall', 0)), 'f1_score': float(metrics.get('f1_score', 0)) }, 'hyperparameters': hyperparams,  #  Todos os hiperpar√¢metros usados 'training_info': training_info,  #  Informa√ß√µes detalhadas de treinamento 'class_names': class_names,  #  Nomes das classes 'num_classes': len(class_names),  #  N√∫mero de classes 'model_params': model_params,  #  Par√¢metros para reconstruir modelo PyTorch 'version': '1.0'  #  Vers√£o do formato
}
```

**Exemplo de Uso - SVM** (linha 337-355 em `classic.py`):
```python
# src/pipelines/classic.py - LINHA 337-355:
metadata = create_model_metadata( model_name='SVM', metrics=metrics_test,  #  M√©tricas calculadas hyperparams=best_hyperparams,  #  Hiperpar√¢metros encontrados pelo Random Search training_info={ 'use_random_search': use_random_search, 'n_iter': n_iter if use_random_search else 0, 'cv_folds': CLASSIC_CV_FOLDS if use_random_search else 0,  #  CV folds usados 'pca_used': self.pca is not None,  #  Se PCA foi usado 'pca_components': self.pca.n_components if self.pca is not None else None,  #  Componentes PCA 'use_linear_svm': use_linear_svm,  #  Tipo de SVM usado 'img_size_classic': IMG_SIZE_CLASSIC,  #  Tamanho de imagem 'max_samples': CLASSIC_MAX_SAMPLES,  #  Limite de amostras 'total_time_seconds': total_time,  #  Tempo de execu√ß√£o 'device': 'CPU', 'n_jobs': svm_n_jobs  #  Paraleliza√ß√£o usada }, class_names=self.class_names  #  Nomes das classes
)
```

**Exemplo de Uso - SimpleCNN** (linha 940-963 em `deep_learning.py`):
```python
# src/pipelines/deep_learning.py - LINHA 940-963:
metadata = create_model_metadata( model_name='SimpleCNN', metrics=metrics, hyperparams={ 'learning_rate': best_params['learning_rate'], 'batch_size': best_params['batch_size'], 'dropout_rate': best_params['dropout_rate'], 'hidden_units': best_params['hidden_units'], 'num_classes': self.num_classes }, training_info={ 'use_random_search': use_random_search, 'n_iter': n_iter if use_random_search else 0, 'final_epochs': final_epochs, 'random_search_time': random_search_time,  #  Tempo de Random Search 'final_train_time': final_train_time,  #  Tempo de treinamento final 'total_time': total_time,  #  Tempo total 'device': str(self.device),  #  Dispositivo usado (GPU/CPU) 'use_augmentation': USE_AUGMENTATION,  #  Data augmentation usado 'transfer_learning': False  #  Se usou transfer learning }, class_names=self.class_names, model_params={  #  Par√¢metros para reconstruir modelo 'num_classes': self.num_classes, 'dropout_rate': best_params['dropout_rate'], 'hidden_units': best_params['hidden_units'] }
)
```

---

# **3. `load_model_with_metadata()` - Carrega Modelo com Metadados**

**Localiza√ß√£o**: `src/model_saver.py`, linhas 48-87

**Assinatura**:
```python
def load_model_with_metadata(model_path, model_type='pytorch', model_class=None): """ Carrega modelo com metadados Args: model_path: Caminho do modelo salvo model_type: Tipo do modelo ('pytorch' ou 'sklearn') model_class: Classe do modelo (necess√°rio para PyTorch) Returns: model: Modelo carregado metadata: Dicion√°rio com metadados """
```

**Implementa√ß√£o para PyTorch** (linha 66-79):
```python
# src/model_saver.py - LINHA 66-79:
if model_type == 'pytorch': import torch checkpoint = torch.load(model_path, map_location='cpu')  #  Carrega na CPU primeiro if model_class is None: raise ValueError("model_class √© necess√°rio para carregar modelos PyTorch") # Recriar modelo com metadados metadata = checkpoint.get('metadata', {})  #  Extrai metadados model = model_class(**metadata.get('model_params', {}))  #  Reconstr√≥i modelo model.load_state_dict(checkpoint['model_state_dict'])  #  Carrega pesos model.eval()  #  Modo avalia√ß√£o return model, metadata
```

**Implementa√ß√£o para scikit-learn** (linha 81-84):
```python
# src/model_saver.py - LINHA 81-84:
elif model_type == 'sklearn': import joblib data = joblib.load(model_path) return data['model'], data.get('metadata', {})  #  Retorna modelo e metadados
```

**Exemplo de Uso - Carregar SVM** (arquivo `scripts/load_model_example.py`):
```python
# scripts/load_model_example.py - EXEMPLO:
from src.model_saver import load_model_with_metadata

# Carregar modelo SVM
svm_model, metadata = load_model_with_metadata( model_path='outputs/models/svm_model.pkl', model_type='sklearn'
)

print(f"Modelo: {metadata['model_name']}")
print(f"Acur√°cia: {metadata['metrics']['accuracy']:.4f}")
print(f"Hiperpar√¢metros: {metadata['hyperparameters']}")
print(f"Data de treinamento: {metadata['timestamp']}")
```

**Exemplo de Uso - Carregar SimpleCNN** (arquivo `scripts/load_model_example.py`):
```python
# scripts/load_model_example.py - EXEMPLO:
from src.model_saver import load_model_with_metadata
from src.models import SimpleCNN

# Carregar modelo SimpleCNN
model, metadata = load_model_with_metadata( model_path='outputs/models/simple_cnn.pth', model_type='pytorch', model_class=SimpleCNN  #  Necess√°rio para reconstruir modelo
)

print(f"Modelo: {metadata['model_name']}")
print(f"Acur√°cia: {metadata['metrics']['accuracy']:.4f}")
print(f"Device usado: {metadata['training_info']['device']}")
```

---

# Estrutura de Arquivos Salvos

Ap√≥s treinar modelos, voc√™ ter√°:

```
outputs/models/
‚îú‚îÄ‚îÄ svm_model.pkl # Modelo SVM (joblib)
‚îú‚îÄ‚îÄ svm_model.json # Metadados do SVM
‚îú‚îÄ‚îÄ svm_scaler.pkl # Scaler usado no SVM
‚îú‚îÄ‚îÄ random_forest_model.pkl # Modelo Random Forest
‚îú‚îÄ‚îÄ random_forest_model.json # Metadados do Random Forest
‚îú‚îÄ‚îÄ simple_cnn.pth # Modelo SimpleCNN (PyTorch)
‚îú‚îÄ‚îÄ simple_cnn.json # Metadados do SimpleCNN
‚îú‚îÄ‚îÄ resnet50_transfer.pth # Modelo ResNet50 (PyTorch)
‚îî‚îÄ‚îÄ resnet50_transfer.json # Metadados do ResNet50
```

**Exemplo de arquivo JSON de metadados** (`svm_model.json`):
```json
{ "model_name": "SVM", "timestamp": "2024-01-15T10:30:45.123456", "metrics": { "accuracy": 0.8542, "precision": 0.8520, "recall": 0.8542, "f1_score": 0.8531 }, "hyperparameters": { "C": 1.23, "gamma": 0.045, "kernel": "rbf", "degree": 3, "class_weight": "balanced" }, "training_info": { "use_random_search": true, "n_iter": 50, "cv_folds": 2, "pca_used": true, "pca_components": 500, "use_linear_svm": false, "img_size_classic": [64, 64], "max_samples": null, "total_time_seconds": 932.45, "device": "CPU", "n_jobs": 1 }, "class_names": ["aiartdata", "realart"], "num_classes": 2, "version": "1.0"
}
```

---

# Configura√ß√£o

#### Op√ß√£o 1: Usar Dataset do Kaggle (Recomendado)

O projeto est√° configurado para usar o dataset **AI Art vs Human Art** do Kaggle:

```bash
# Baixar e organizar o dataset automaticamente
python download_dataset.py
```

O script ir√°:
- Baixar o dataset do Kaggle automaticamente
- Explorar a estrutura do dataset
- Organizar os dados em `data/train/` e `data/test/`
- Dividir automaticamente em 70% treino e 30% teste

**Nota**: Certifique-se de ter aceitado os termos do dataset no Kaggle antes de executar.

#### Op√ß√£o 2: Organizar Dados Manualmente

Se preferir usar seus pr√≥prios dados, organize no formato: ``` data/ train/ classe1/ img1.jpg img2.jpg classe2/ img1.jpg test/ classe1/ classe2/ ```

#### Configura√ß√µes do `config.py`:

- `USE_GPU`: True para usar GPU, False para CPU
- `USE_KAGGLE_DATASET`: True para usar dataset do Kaggle (padr√£o: True)
- `KAGGLE_DATASET`: Nome do dataset no formato "usuario/dataset"
- `TRAIN_SPLIT`: Propor√ß√£o de dados para treinamento (padr√£o: 0.7)
- `TEST_SPLIT`: Propor√ß√£o de dados para teste (padr√£o: 0.3)
- `BATCH_SIZE`: Tamanho do batch (padr√£o: 32)
- `EPOCHS`: N√∫mero de √©pocas (padr√£o: 50)
- `USE_AUGMENTATION`: Ativar data augmentation

## Uso

### Passo 1: Baixar o Dataset (se necess√°rio)

Se voc√™ ainda n√£o tem os dados organizados:

```bash
python scripts/download_dataset.py
```

O script ir√° baixar e organizar automaticamente o dataset do Kaggle.

### Passo 2: Executar o Projeto

Execute o script principal:

```bash
python main.py
```

Se os dados n√£o estiverem organizados, o script oferecer√° a op√ß√£o de baixar automaticamente.

Escolha uma das op√ß√µes:
1. Pipeline Cl√°ssico (SVM + Random Forest)
2. Pipeline Deep Learning (CNN + ResNet)
3. Ambos os pipelines
4. Sair

## Contextualiza√ß√£o da Base de Dados

### Dataset: AI Art vs Human Art

Este projeto utiliza o dataset **AI Art vs Human Art** do Kaggle, que cont√©m imagens classificadas em duas categorias:

- **AI Art**: Arte gerada por intelig√™ncia artificial
- **Human Art**: Arte criada por humanos

**Link do Dataset**: https://www.kaggle.com/datasets/hassnainzaidi/ai-art-vs-human-art

### Descri√ß√£o dos Dados

A base de dados √© organizada automaticamente em diret√≥rios por classe. O sistema detecta automaticamente:

- **Quantidade de imagens**: Contadas automaticamente durante o carregamento
- **Tamanho das imagens**: Configur√°vel em `config.py` (padr√£o: 224x224 pixels)
- **Canais**: RGB (3 canais)
- **Quantidade de classes**: Detectada automaticamente a partir dos diret√≥rios
- **Divis√£o treino/teste**: 70% treino, 30% teste (configur√°vel)

### Caracter√≠sticas do Dataset

O dataset **AI Art vs Human Art** cont√©m:
- **Total de arquivos**: ~975 imagens
- **Formatos**: JPG (763), PNG (150), JPEG (57), outros (5)
- **Classes**: - AiArtData: ~539 imagens (55%) - RealArt: ~436 imagens (45%)
- **Desbalanceamento**: Leve desbalanceamento (~20% de diferen√ßa)

### Padroniza√ß√£o de Imagens

O projeto implementa **padroniza√ß√£o completa** de imagens para garantir consist√™ncia e qualidade dos dados:

#### 1. **Tratamento de M√∫ltiplos Formatos** 
- Suporta automaticamente: JPG, JPEG, PNG, BMP, GIF
- Convers√£o uniforme para formato interno
- Tratamento espec√≠fico para cada tipo de arquivo

#### 2. **Padroniza√ß√£o de Canais de Cor** 
- **Convers√£o para RGB**: Todas as imagens s√£o convertidas para RGB (3 canais)
- **Remo√ß√£o de Alpha Channel**: PNGs com transpar√™ncia s√£o convertidos com fundo branco
- **Convers√£o Grayscale**: Imagens em escala de cinza s√£o convertidas para RGB
- **Valida√ß√£o**: Garante que todas as imagens tenham exatamente 3 canais

#### 3. **Corre√ß√£o de Orienta√ß√£o EXIF** 
- **Corre√ß√£o Autom√°tica**: Aplica corre√ß√£o de orienta√ß√£o baseada em metadados EXIF
- **Importante para Arte**: Evita que imagens apare√ßam rotacionadas incorretamente
- **Transparente**: Processo autom√°tico, sem interven√ß√£o manual

#### 4. **Redimensionamento Inteligente** 
- **Tamanho Padr√£o**: Todas as imagens s√£o redimensionadas para 224x224 pixels
- **Interpola√ß√£o de Alta Qualidade**: Usa `INTER_AREA` do OpenCV (melhor para downscaling)
- **Valida√ß√£o de Dimens√µes**: Rejeita imagens muito pequenas (< 32x32 pixels)

#### 5. **Valida√ß√£o e Tratamento de Erros** 
- **Detec√ß√£o de Imagens Corrompidas**: Identifica e trata arquivos inv√°lidos
- **Valida√ß√£o de Qualidade**: Verifica dimens√µes m√≠nimas e formato v√°lido
- **Logging Detalhado**: Relat√≥rio completo de problemas encontrados
- **Continuidade**: Processo n√£o √© interrompido por imagens problem√°ticas

#### 6. **Relat√≥rio de Estat√≠sticas** Ao carregar as imagens, o sistema exibe um relat√≥rio detalhado:

```
============================================================
ESTAT√çSTICAS DE CARREGAMENTO DE IMAGENS
============================================================
Total de arquivos processados: 975
Imagens carregadas com sucesso: 970
Erros encontrados: 5

Formatos encontrados: .jpg: 763 .jpeg: 57 .png: 150

Imagens em escala de cinza convertidas: X
Canais alpha removidos: Y
Orienta√ß√µes EXIF corrigidas: Z
============================================================
```

#### 7. **Normaliza√ß√£o de Valores** **Para Pipeline Cl√°ssico:**
- Normaliza√ß√£o para [0, 1]: Divis√£o por 255
- Padroniza√ß√£o: StandardScaler (m√©dia 0, desvio padr√£o 1)

**Para Pipeline Deep Learning:**
- Normaliza√ß√£o ImageNet: - Mean: [0.485, 0.456, 0.406] - Std: [0.229, 0.224, 0.225]
- Convers√£o para Tensor: Valores normalizados para treinamento

### Benef√≠cios da Padroniza√ß√£o

1. **Consist√™ncia**: Todas as imagens t√™m o mesmo formato e tamanho
2. **Qualidade**: Melhor performance dos modelos com dados padronizados
3. **Robustez**: Tratamento autom√°tico de diferentes formatos e problemas
4. **Transpar√™ncia**: Relat√≥rios detalhados sobre o processamento
5. **Confiabilidade**: Valida√ß√£o garante que apenas imagens v√°lidas s√£o usadas

### Estrutura Ap√≥s Download

Ap√≥s executar `download_dataset.py`, a estrutura ser√°:

```
data/ train/ ai_art/ (70% das imagens de arte IA) human_art/ (70% das imagens de arte humana) test/ ai_art/ (30% das imagens de arte IA) human_art/ (30% das imagens de arte humana)
```

O c√≥digo imprime automaticamente:
- N√∫mero de amostras de treinamento
- N√∫mero de amostras de teste
- Tamanho das imagens
- N√∫mero de canais
- Nomes das classes

---

## Random Search Otimizado - Como Funciona em Todos os Modelos

### Vis√£o Geral

O Random Search foi **otimizado** para economizar mem√≥ria mantendo a qualidade da busca de hiperpar√¢metros. Esta se√ß√£o explica **EXATAMENTE** como funciona em cada modelo.

### Configura√ß√£o Global do Random Search

**Localiza√ß√£o**: `src/config.py`, linha 108

```python
# src/config.py - LINHA 108:
CLASSIC_CV_FOLDS = 2  # N√∫mero de folds para valida√ß√£o cruzada
# Aplica-se a TODOS os modelos cl√°ssicos (SVM E Random Forest)
```

**Antes**: `cv=3` (fixo no c√≥digo) **Depois**: `cv=CLASSIC_CV_FOLDS` (configur√°vel, padr√£o: 2) **Redu√ß√£o de mem√≥ria**: ~33% (2 folds vs 3 folds)

---

# Random Search no SVM

#### **Configura√ß√µes Espec√≠ficas**

**Localiza√ß√£o**: `src/config.py`, linhas 106-107

```python
# src/config.py - LINHAS 106-107:
CLASSIC_SVM_N_JOBS = 1  # Jobs paralelos para SVM (1 = sem paraleliza√ß√£o)
CLASSIC_USE_LINEAR_SVM = False  # False = SVC (kernels), True = LinearSVC (s√≥ linear)
```

#### **Implementa√ß√£o Completa**

**Localiza√ß√£o**: `src/pipelines/classic.py`, fun√ß√£o `train_svm()`, linhas 257-294

**C√≥digo Completo do Random Search para SVM**:
```python
# src/pipelines/classic.py - LINHAS 257-294:
if use_random_search: print(f"\n Otimizando hiperpar√¢metros com Random Search ({n_iter} itera√ß√µes)...") print(f" CV folds: {CLASSIC_CV_FOLDS} (reduzido para economizar mem√≥ria)") search_start = time.time() if use_linear_svm: # LinearSVC: apenas kernel linear, menos par√¢metros param_distributions = { 'C': loguniform(0.01, 100), # Distribui√ß√£o log-uniform 'loss': ['hinge', 'squared_hinge'], # Fun√ß√µes de perda 'class_weight': [None, 'balanced'], # Balanceamento de classes 'dual': [True, False] # Forma dual ou primal } svm = LinearSVC(random_state=42, max_iter=2000) else: # SVC tradicional: m√∫ltiplos kernels param_distributions = { 'C': loguniform(0.01, 100), # Par√¢metro de regulariza√ß√£o 'gamma': loguniform(0.0001, 1), # Para kernels RBF e poly 'kernel': ['rbf', 'linear', 'poly'],  # Tipo de kernel 'degree': randint(2, 5), # Para kernel poly (grau 2, 3 ou 4) 'class_weight': [None, 'balanced'] # Balanceamento de classes } svm = SVC(random_state=42) # CR√çTICO: CV_FOLDS configur√°vel e n_jobs espec√≠fico para SVM random_search = RandomizedSearchCV( svm, param_distributions, n_iter=n_iter, #  N√∫mero de itera√ß√µes (padr√£o: 50) cv=CLASSIC_CV_FOLDS, #  CV folds configur√°vel (padr√£o: 2) scoring='accuracy', # M√©trica de avalia√ß√£o n_jobs=svm_n_jobs, #  Paraleliza√ß√£o configur√°vel (padr√£o: 1) verbose=1, # Mostrar progresso random_state=42 # Reproduzibilidade ) random_search.fit(self.X_train, self.y_train)  #  Treina com todos os dados search_time = time.time() - search_start search_time_str = str(timedelta(seconds=int(search_time))) self.svm_model = random_search.best_estimator_  #  Melhor modelo encontrado print(f"Melhores par√¢metros: {random_search.best_params_}") print(f"Melhor score (CV): {random_search.best_score_:.4f}") print(f"Tempo de Random Search: {search_time_str} ({search_time:.2f} segundos)")
```

**Fluxo Completo**:
1. **Define espa√ßo de par√¢metros**: Distribui√ß√µes log-uniform, uniform ou listas discretas
2. **Cria RandomizedSearchCV**: Com `n_iter` itera√ß√µes, `cv=CLASSIC_CV_FOLDS` folds, `n_jobs=svm_n_jobs`
3. **Executa busca**: Para cada itera√ß√£o, seleciona par√¢metros aleat√≥rios e avalia com CV
4. **Total de fits**: `n_iter √ó cv_folds` (ex: 50 √ó 2 = 100 fits)
5. **Retorna melhor modelo**: `best_estimator_` com melhores hiperpar√¢metros encontrados

**Mem√≥ria Usada**:
- **Por fold**: Uma c√≥pia dos dados transformados (ap√≥s PCA)
- **Com PCA ativo**: ~500 features √ó n_samples √ó 8 bytes = muito menor!
- **Sem paraleliza√ß√£o** (`n_jobs=1`): Uma c√≥pia por vez
- **Total estimado**: ~1-2 GB (vs ~15-20 GB antes das otimiza√ß√µes)

---

# Random Search no Random Forest

#### **Configura√ß√µes Espec√≠ficas**

**Localiza√ß√£o**: `src/config.py`, linha 107

```python
# src/config.py - LINHA 107:
CLASSIC_RF_N_JOBS = -1  # Jobs paralelos para Random Forest (-1 = todos os cores)
# Random Forest pode usar mais paraleliza√ß√£o que SVM (mais eficiente em mem√≥ria)
```

#### **Implementa√ß√£o Completa**

**Localiza√ß√£o**: `src/pipelines/classic.py`, fun√ß√£o `train_random_forest()`, linhas 426-453

**C√≥digo Completo do Random Search para Random Forest**:
```python
# src/pipelines/classic.py - LINHAS 426-453:
if use_random_search: print(f"\n Otimizando hiperpar√¢metros com Random Search ({n_iter} itera√ß√µes)...") print(f" CV folds: {CLASSIC_CV_FOLDS} (reduzido para economizar mem√≥ria)") search_start = time.time() param_distributions = { 'n_estimators': randint(50, 300), # N√∫mero de √°rvores (50 a 299) 'max_depth': [None, 10, 20, 30, 50], # Profundidade m√°xima 'min_samples_split': randint(2, 20), # Amostras m√≠nimas para dividir (2 a 19) 'min_samples_leaf': randint(1, 10), # Amostras m√≠nimas por folha (1 a 9) 'max_features': ['sqrt', 'log2', None], # Features por split 'bootstrap': [True, False], # Bootstrap sampling 'class_weight': [None, 'balanced', 'balanced_subsample']  # Balanceamento } # CR√çTICO: n_jobs espec√≠fico para Random Forest (pode usar mais cores) rf_n_jobs = CLASSIC_RF_N_JOBS if CLASSIC_RF_N_JOBS is not None else self.n_jobs if rf_n_jobs == -1: actual_jobs = self.num_cores  #  Todos os cores dispon√≠veis else: actual_jobs = rf_n_jobs rf = RandomForestClassifier(random_state=42, n_jobs=rf_n_jobs)  #  n_jobs espec√≠fico random_search = RandomizedSearchCV( rf, param_distributions, n_iter=n_iter, #  N√∫mero de itera√ß√µes (padr√£o: 50) cv=CLASSIC_CV_FOLDS, #  CV folds configur√°vel (padr√£o: 2) scoring='accuracy', n_jobs=rf_n_jobs, #  Paraleliza√ß√£o configur√°vel (padr√£o: -1) verbose=1, random_state=42 ) random_search.fit(self.X_train, self.y_train) search_time = time.time() - search_start search_time_str = str(timedelta(seconds=int(search_time))) self.rf_model = random_search.best_estimator_ print(f"Melhores par√¢metros: {random_search.best_params_}") print(f"Melhor score (CV): {random_search.best_score_:.4f}") print(f"Tempo de Random Search: {search_time_str} ({search_time:.2f} segundos)")
```

**Diferen√ßas em rela√ß√£o ao SVM**:
- Random Forest pode usar `n_jobs=-1` (todos os cores) porque usa mem√≥ria de forma mais eficiente
- N√£o precisa calcular matriz Gram como SVM
- √Årvores independentes = paraleliza√ß√£o nativa muito eficiente
- Mesmo `CLASSIC_CV_FOLDS = 2` se aplica (configura√ß√£o global)

---

# Random Search no Simple CNN (Deep Learning)

**Diferen√ßa Importante**: Simple CNN usa **implementa√ß√£o customizada** de Random Search, n√£o `RandomizedSearchCV` do scikit-learn.

#### **Implementa√ß√£o Customizada**

**Localiza√ß√£o**: `src/pipelines/deep_learning.py`, fun√ß√£o `train_simple_cnn()`, linhas 768-825

**C√≥digo Completo do Random Search para SimpleCNN**:
```python
# src/pipelines/deep_learning.py - LINHAS 768-825:
if use_random_search: print(f"\nExecutando Random Search ({n_iter} itera√ß√µes)...") search_start_time = time.time() # Espa√ßo de hiperpar√¢metros param_space = { 'learning_rate': (0.0001, 0.01), # Log-uniform (distribui√ß√£o log) 'batch_size': [16, 32, 64], # Valores discretos 'dropout_rate': (0.3, 0.7), # Uniform entre 0.3 e 0.7 'hidden_units': [256, 512, 1024] # Valores discretos } best_val_acc = 0.0 search_epochs = min(15, final_epochs)  #  Limita √©pocas durante busca for i in range(n_iter):  #  Loop manual ao inv√©s de RandomizedSearchCV iter_start = time.time() # Amostrar hiperpar√¢metros aleatoriamente params = sample_hyperparameters(param_space)  #  Fun√ß√£o customizada print(f"\n  Itera√ß√£o {i+1}/{n_iter}: lr={params['learning_rate']:.6f}, " f"batch={params['batch_size']}, dropout={params['dropout_rate']:.2f}, " f"hidden={params['hidden_units']}") # Criar dataloaders com batch size amostrado train_loader, val_loader, _ = self.create_dataloaders( params['batch_size'], val_split=0.2  #  Split interno de valida√ß√£o ) # Criar modelo com hiperpar√¢metros amostrados model = SimpleCNN( self.num_classes, dropout_rate=params['dropout_rate'], hidden_units=params['hidden_units'] ) # CR√çTICO: Mover modelo para GPU ANTES do treinamento model = model.to(self.device) # Treinar modelo com configura√ß√£o espec√≠fica val_acc, _, iter_time = self.train_single_config( model, train_loader, val_loader, search_epochs, params['learning_rate'], patience=5  #  Early stopping ) iter_total_time = time.time() - iter_start print(f" Val Acc: {val_acc:.4f} | Tempo da itera√ß√£o: {iter_total_time:.1f}s") # Manter melhor configura√ß√£o encontrada if val_acc > best_val_acc: best_val_acc = val_acc best_params = params.copy() random_search_time = time.time() - search_start_time # ... exibir resultados ...
```

**Fun√ß√£o `sample_hyperparameters()` - Localiza√ß√£o**: `src/pipelines/deep_learning.py`, linhas 60-86

```python
# src/pipelines/deep_learning.py - LINHAS 60-86:
def sample_hyperparameters(param_space): """ Amostra aleatoriamente hiperpar√¢metros do espa√ßo definido Args: param_space: Dicion√°rio com espa√ßo de hiperpar√¢metros - Tuplas (min, max): Uniform ou log-uniform - Listas: Escolha aleat√≥ria Returns: params: Dicion√°rio com hiperpar√¢metros amostrados """ params = {} for key, value in param_space.items(): if isinstance(value, tuple) and len(value) == 2: if isinstance(value[0], float): # Log-uniform para learning rate if key == 'learning_rate': log_low, log_high = np.log10(value[0]), np.log10(value[1]) params[key] = 10 ** np.random.uniform(log_low, log_high)  #  Log-uniform else: params[key] = np.random.uniform(value[0], value[1])  #  Uniform elif isinstance(value[0], int): params[key] = np.random.randint(value[0], value[1] + 1)  #  Randint elif isinstance(value, list): params[key] = random.choice(value)  #  Escolha aleat√≥ria de lista else: params[key] = value  #  Valor fixo return params
```

**Diferen√ßas da Implementa√ß√£o Customizada**:
- **N√£o cria m√∫ltiplas c√≥pias dos dados**: Usa lazy loading e processamento em batches
- **Valida√ß√£o split interna**: 20% dos dados de treino, n√£o CV folds
- **Early stopping**: Para treinamento quando n√£o melhora (patience=5)
- **√âpocas limitadas**: `search_epochs = min(15, final_epochs)` durante busca
- **Sequencial**: Testa configura√ß√µes uma por vez (n√£o paralelo, mas usa GPU eficientemente)

**Por que n√£o precisa das mesmas otimiza√ß√µes do SVM?**:
- Lazy loading: Dados carregados sob demanda (n√£o tudo na mem√≥ria)
- Processamento em batches: Apenas um batch por vez na GPU
- Sem CV folds: Apenas split simples de valida√ß√£o
- Cada itera√ß√£o √© independente: Modelo deletado ap√≥s avalia√ß√£o

---

# Random Search no ResNet50 (Deep Learning)

**Mesma implementa√ß√£o customizada** do SimpleCNN, mas com configura√ß√µes espec√≠ficas para ResNet50.

#### **Configura√ß√µes Espec√≠ficas**

**Localiza√ß√£o**: `src/config.py`, linhas 84-95

```python
# src/config.py - LINHAS 84-95:
RESNET50_BATCH_SIZES = [8, 16, 32]  #  Batch sizes reduzidos (era [16, 32, 64])
RESNET50_DEFAULT_BATCH_SIZE = 16 #  Padr√£o reduzido (era 32)
RESNET50_SEARCH_EPOCHS = 10 #  √âpocas limitadas durante busca
RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True  #  Limpar mem√≥ria entre itera√ß√µes
```

#### **Implementa√ß√£o com Limpeza de Mem√≥ria**

**Localiza√ß√£o**: `src/pipelines/deep_learning.py`, fun√ß√£o `train_resnet_transfer()`, linhas 1093-1145

**C√≥digo Completo do Random Search para ResNet50** (com limpeza de mem√≥ria):
```python
# src/pipelines/deep_learning.py - LINHAS 1093-1145:
if use_random_search: print(f"\nExecutando Random Search ({n_iter} itera√ß√µes)...") print(f"  Batch sizes testados: {RESNET50_BATCH_SIZES}") print(f"  √âpocas por itera√ß√£o: {RESNET50_SEARCH_EPOCHS}") print(f"  Limpeza de mem√≥ria entre itera√ß√µes: {'Ativada' if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS else 'Desativada'}") search_start_time = time.time() param_space = { 'learning_rate': (0.00001, 0.001), #  Learning rate menor (transfer learning) 'batch_size': RESNET50_BATCH_SIZES,  #  Batch sizes configur√°veis 'unfreeze_layers': [0, 1, 2] #  Quantas camadas descongelar } best_val_acc = 0.0 search_epochs = min(RESNET50_SEARCH_EPOCHS, final_epochs)  #  √âpocas limitadas for i in range(n_iter): iter_start = time.time() params = sample_hyperparameters(param_space) print(f"\n  Itera√ß√£o {i+1}/{n_iter}: lr={params['learning_rate']:.6f}, " f"batch={params['batch_size']}, unfreeze={params['unfreeze_layers']}") #  LIMPAR MEM√ìRIA ANTES de cada itera√ß√£o if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS: clear_memory(clear_gpu=True) train_loader, val_loader, _ = self.create_dataloaders( params['batch_size'], val_split=0.2 ) # Criar modelo (j√° verifica mem√≥ria internamente) model = self.create_resnet_model(unfreeze_layers=params['unfreeze_layers']) try: val_acc, trained_model, iter_time = self.train_single_config( model, train_loader, val_loader, search_epochs, params['learning_rate'], patience=5 ) # ... processar resultados ... except RuntimeError as e: if 'out of memory' in str(e).lower(): #  TRATAMENTO DE ERRO: Recupera√ß√£o autom√°tica print(f" [ERRO] Estouro de mem√≥ria na itera√ß√£o {i+1}!") clear_memory(clear_gpu=True) # Tentar com batch size menor if params['batch_size'] > min(RESNET50_BATCH_SIZES): reduced_batch = max(min(RESNET50_BATCH_SIZES), params['batch_size'] // 2) print(f" Tentando com batch size reduzido: {reduced_batch}") params['batch_size'] = reduced_batch continue else: print(f" [AVISO] N√£o foi poss√≠vel reduzir mais o batch size. Pulando itera√ß√£o.") continue else: raise finally: #  CR√çTICO: LIMPAR MEM√ìRIA AP√ìS cada itera√ß√£o if RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS: # Mover modelo para CPU antes de deletar if 'trained_model' in locals(): trained_model = trained_model.cpu() if 'model' in locals(): model = model.cpu() del model, trained_model  #  Deletar explicitamente clear_memory(clear_gpu=True)  #  Limpar cache CUDA # Mostrar status de mem√≥ria if torch.cuda.is_available() and self.device.type == 'cuda': gpu_mem_used = torch.cuda.memory_allocated() / (1024**3) print(f" Mem√≥ria GPU ap√≥s limpeza: {gpu_mem_used:.2f} GB")
```

**Caracter√≠sticas Especiais do Random Search do ResNet50**:
- **Limpeza autom√°tica**: Antes e depois de cada itera√ß√£o
- **Tratamento de erros**: Recupera automaticamente de estouro de mem√≥ria
- **Batch size adaptativo**: Reduz automaticamente se necess√°rio
- **Verifica√ß√£o de mem√≥ria**: Antes de carregar modelo grande
- **Batch sizes menores**: [8, 16, 32] ao inv√©s de [16, 32, 64]

---

# Compara√ß√£o: Random Search em Todos os Modelos

| Modelo | Tipo | Implementa√ß√£o | CV Folds | n_jobs | Limpeza Mem√≥ria | Otimizado? |
|--------|------|---------------|----------|--------|-----------------|------------|
| **SVM** | Cl√°ssico | RandomizedSearchCV | `CLASSIC_CV_FOLDS=2` | `CLASSIC_SVM_N_JOBS=1` | N/A (CPU) |  **Sim** |
| **Random Forest** | Cl√°ssico | RandomizedSearchCV | `CLASSIC_CV_FOLDS=2` | `CLASSIC_RF_N_JOBS=-1` | N/A (CPU) |  **Sim** |
| **Simple CNN** | Deep Learning | Customizado | Split interno (20%) | N/A (GPU) | Autom√°tica |  **N√£o precisa** |
| **ResNet50** | Deep Learning | Customizado | Split interno (20%) | N/A (GPU) | **Entre itera√ß√µes** |  **Sim** |

**Explica√ß√£o**:
- Modelos cl√°ssicos usam `RandomizedSearchCV` do scikit-learn ‚Üí precisam de otimiza√ß√µes de mem√≥ria
- Modelos deep learning usam implementa√ß√£o customizada ‚Üí j√° s√£o eficientes (lazy loading + batches)
- ResNet50 precisa de limpeza adicional porque modelo √© muito grande

---

## Pipeline Cl√°ssico - Detalhes Completos

### Modelos Implementados

#### **1. Support Vector Machine (SVM)**

**Localiza√ß√£o**: `src/pipelines/classic.py`, fun√ß√£o `train_svm()`, linhas 202-393

**Caracter√≠sticas**:
- Suporta `SVC` (kernels: RBF, linear, poly) ou `LinearSVC` (apenas linear)
- Otimiza√ß√£o: Random Search (50 itera√ß√µes padr√£o)
- Par√¢metros otimizados: C, gamma, kernel, degree, class_weight (SVC) ou C, loss, dual, class_weight (LinearSVC)
- Valida√ß√£o cruzada: 2 folds (configur√°vel)
- Paraleliza√ß√£o: 1 job (configur√°vel para economizar mem√≥ria)

**Exemplo de Par√¢metros Otimizados** (linha 274-279):
```python
# src/pipelines/classic.py - LINHA 274-279 (SVC):
param_distributions = { 'C': loguniform(0.01, 100), # Par√¢metro de regulariza√ß√£o (log-uniform) 'gamma': loguniform(0.0001, 1), # Para kernels RBF e poly (log-uniform) 'kernel': ['rbf', 'linear', 'poly'],  # Tipo de kernel (escolha aleat√≥ria) 'degree': randint(2, 5), # Grau do polin√¥mio para kernel poly (2, 3 ou 4) 'class_weight': [None, 'balanced'] # Balanceamento de classes
}
```

**Exemplo de Sa√≠da Durante Treinamento**:
```
================================================================================
TREINANDO MODELO: Support Vector Machine (SVM)
================================================================================ Dispositivo: CPU (scikit-learn n√£o suporta GPU) Verifica√ß√£o de mem√≥ria: Amostras: 10,000 Features: 500 (ap√≥s PCA) Mem√≥ria estimada para treinamento: ~0.08 GB Paraleliza√ß√£o SVM: 1 job(s) (configurado para economizar mem√≥ria) Tipo: SVC (suporta kernels n√£o-lineares, mas usa mais mem√≥ria) Otimizando hiperpar√¢metros com Random Search (50 itera√ß√µes)... CV folds: 2 (reduzido para economizar mem√≥ria) Fitting 2 folds for each of 50 candidates, totalling 100 fits [Progresso: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100/100 Melhores par√¢metros: {'C': 1.23, 'gamma': 0.045, 'kernel': 'rbf', 'degree': 3, 'class_weight': 'balanced'} Melhor score (CV): 0.8542 Tempo de Random Search: 0:15:32 (932.45 segundos) Predi√ß√µes - Tempo: 2.34 segundos Acur√°cia - Treinamento: 0.8734 Acur√°cia - Teste: 0.8542 Precis√£o - Teste: 0.8520 Recall - Teste: 0.8542 F1-Score - Teste: 0.8531 Tempo total de execu√ß√£o: 0:15:40 (940.23 segundos)
```

#### **2. Random Forest**

**Localiza√ß√£o**: `src/pipelines/classic.py`, fun√ß√£o `train_random_forest()`, linhas 396-527

**Caracter√≠sticas**:
- Ensemble de √°rvores de decis√£o
- Otimiza√ß√£o: Random Search (50 itera√ß√µes padr√£o)
- Par√¢metros otimizados: n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, bootstrap, class_weight
- Valida√ß√£o cruzada: 2 folds (configur√°vel)
- Paraleliza√ß√£o: -1 (todos os cores) - Random Forest usa mem√≥ria eficientemente

**Exemplo de Par√¢metros Otimizados** (linha 430-437):
```python
# src/pipelines/classic.py - LINHA 430-437 (Random Forest):
param_distributions = { 'n_estimators': randint(50, 300), # N√∫mero de √°rvores (50 a 299) 'max_depth': [None, 10, 20, 30, 50], # Profundidade m√°xima (None = sem limite) 'min_samples_split': randint(2, 20), # Amostras m√≠nimas para dividir (2 a 19) 'min_samples_leaf': randint(1, 10), # Amostras m√≠nimas por folha (1 a 9) 'max_features': ['sqrt', 'log2', None], # Features por split 'bootstrap': [True, False], # Bootstrap sampling 'class_weight': [None, 'balanced', 'balanced_subsample']  # Balanceamento de classes
}
```

---

# Transforma√ß√µes Aplicadas no Pipeline Cl√°ssico

#### **1. Carregamento de Imagens com Padroniza√ß√£o Completa**

**Localiza√ß√£o**: `src/utils.py`, fun√ß√£o `load_images_from_directory()`, linhas 128-316

**Caracter√≠sticas Implementadas**:

**1.1. Tratamento de M√∫ltiplos Formatos** (linha 175-190):
```python
# src/utils.py - LINHA 175-190:
# Suporta m√∫ltiplos formatos automaticamente
image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']
images_found = list(directory.glob('*.[jJ][pP][gG]')) + \ list(directory.glob('*.[jJ][pP][eE][gG]')) + \ list(directory.glob('*.[pP][nN][gG]'))
```

**1.2. Convers√£o para RGB** (linha 200-215):
```python
# src/utils.py - LINHA 200-215:
# Converter para RGB (3 canais) - CR√çTICO para consist√™ncia
if len(image.shape) == 2:  # Grayscale image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
elif len(image.shape) == 4:  # RGBA # Converter RGBA para RGB com fundo branco image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
elif image.shape[2] == 4:  # Alpha channel # Remover alpha channel image = image[:, :, :3]

# Garantir exatamente 3 canais
assert image.shape[2] == 3, f"Imagem deve ter 3 canais, encontrado: {image.shape[2]}"
```

**1.3. Corre√ß√£o de Orienta√ß√£o EXIF** (linha 195-198):
```python
# src/utils.py - LINHA 195-198:
# Corre√ß√£o de orienta√ß√£o EXIF (importante para arte)
pil_image = Image.fromarray(image)
pil_image = ImageOps.exif_transpose(pil_image)  #  Corrige rota√ß√£o baseada em EXIF
image = np.array(pil_image)
```

**1.4. Redimensionamento Inteligente** (linha 217-220):
```python
# src/utils.py - LINHA 217-220:
# Redimensionamento para tamanho padr√£o
# IMPORTANTE: Usa INTER_AREA (melhor para downscaling)
image = cv2.resize(image, img_size, interpolation=cv2.INTER_AREA)
```

**1.5. Valida√ß√£o e Tratamento de Erros** (linha 222-230):
```python
# src/utils.py - LINHA 222-230:
# Validar dimens√µes m√≠nimas
if image.shape[0] < 32 or image.shape[1] < 32: warnings.warn(f"Imagem {img_path} muito pequena: {image.shape}") continue

# Validar formato v√°lido
if image is None or image.size == 0: warnings.warn(f"Imagem {img_path} inv√°lida ou corrompida") continue
```

---

# **2. Pr√©-processamento Espec√≠fico para Modelos Cl√°ssicos**

**Localiza√ß√£o**: `src/pipelines/classic.py`, fun√ß√£o `load_data()`, linhas 135-179

**2.1. Flatten de Imagens** (linha 137):
```python
# src/pipelines/classic.py - LINHA 137:
# Fun√ß√£o preprocess_images_classic em src/utils.py
X_train_flat = preprocess_images_classic(X_train)
# Transforma (n_samples, height, width, channels) em (n_samples, height*width*channels)
# Exemplo: (1000, 64, 64, 3) ‚Üí (1000, 12288)
```

**2.2. Normaliza√ß√£o com StandardScaler** (linha 148-150):
```python
# src/pipelines/classic.py - LINHA 148-150:
# Normaliza√ß√£o: M√©dia 0, Desvio Padr√£o 1
X_train_scaled = self.scaler.fit_transform(X_train_flat)  #  Aprende m√©dia e std do treino
X_test_scaled = self.scaler.transform(X_test_flat)  #  Usa mesma m√©dia e std (importante!)
```

**2.3. Redu√ß√£o de Dimensionalidade com PCA** (linha 152-179):
```python
# src/pipelines/classic.py - LINHA 152-179:
# PCA para redu√ß√£o de dimensionalidade (opcional)
self.pca = None
if CLASSIC_USE_PCA: print(f"\n Aplicando PCA para redu√ß√£o de dimensionalidade...") if CLASSIC_PCA_COMPONENTS is None: # Auto: reduzir para 95% vari√¢ncia self.pca = PCA(n_components=0.95, random_state=42) print(f" Modo: Auto (95% vari√¢ncia explicada)") else: # N√∫mero fixo de componentes n_components = min(CLASSIC_PCA_COMPONENTS, min(n_samples - 1, n_features)) self.pca = PCA(n_components=n_components, random_state=42) print(f" Modo: Fixo ({n_components} componentes)") # CR√çTICO: fit_transform apenas no treino, transform no teste X_train_scaled = self.pca.fit_transform(X_train_scaled)  #  Aprende componentes principais X_test_scaled = self.pca.transform(X_test_scaled)  #  Usa componentes aprendidos (n√£o aprende novamente!) # Calcular e exibir estat√≠sticas n_features_after_pca = X_train_scaled.shape[1] reduction = ((n_features - n_features_after_pca) / n_features) * 100 estimated_mem_after_gb = (n_samples * n_features_after_pca * 8) / (1024**3) print(f" Features ap√≥s PCA: {n_features_after_pca:,} ({reduction:.1f}% redu√ß√£o)") print(f" Mem√≥ria estimada ap√≥s PCA: {estimated_mem_after_gb:.2f} GB") if hasattr(self.pca, 'explained_variance_ratio_'): total_variance = self.pca.explained_variance_ratio_.sum() print(f" Vari√¢ncia explicada: {total_variance:.2%}")
```

**Por Que PCA √© Importante?**:
- **Reduz dimensionalidade**: 12,288 features ‚Üí 500 componentes (96% redu√ß√£o)
- **Mant√©m informa√ß√£o**: ~98% de vari√¢ncia explicada mantida
- **Economiza mem√≥ria**: ~98% menos mem√≥ria necess√°ria
- **Acelera treinamento**: Menos features = treinamento mais r√°pido
- **Melhora performance**: Remove ru√≠do e redund√¢ncia

**Erro Comum Evitado**:
```python
# ERRADO (n√£o fazer isso):
X_test_scaled = self.pca.fit_transform(X_test_scaled)  #  Erro: re-aprende componentes no teste!

# CORRETO (implementado):
X_train_scaled = self.pca.fit_transform(X_train_scaled)  #  Aprende do treino
X_test_scaled = self.pca.transform(X_test_scaled)  #  Usa componentes do treino
```

**Salvamento do PCA**: O PCA √© salvo junto com o modelo para uso em predi√ß√µes futuras (linha 362-367):
```python
# src/pipelines/classic.py - LINHA 362-367:
# Salvar PCA se foi usado (importante para predi√ß√µes futuras)
if self.pca is not None: pca_path = MODELS_DIR / 'svm_pca.pkl' joblib.dump(self.pca, pca_path) print(f" PCA salvo em: {pca_path}")
```

---

# **3. Valores dos Par√¢metros Otimizados**

**SVM - SVC (Random Search - 50 itera√ß√µes padr√£o):**

**Localiza√ß√£o**: `src/pipelines/classic.py`, linhas 273-279

```python
# Espa√ßo de busca para SVC (CLASSIC_USE_LINEAR_SVM = False)
param_distributions = { 'C': loguniform(0.01, 100), # Regulariza√ß√£o: 0.01 a 100 (log-uniform) 'gamma': loguniform(0.0001, 1), # Kernel RBF/poly: 0.0001 a 1 (log-uniform) 'kernel': ['rbf', 'linear', 'poly'],  # Tipo de kernel (3 op√ß√µes) 'degree': randint(2, 5), # Grau polinomial: 2, 3 ou 4 (para kernel poly) 'class_weight': [None, 'balanced'] # Balanceamento: None ou balanced (2 op√ß√µes)
}
```

**Total de combina√ß√µes te√≥ricas**: Infinito (distribui√ß√µes cont√≠nuas) **Combina√ß√µes avaliadas**: Apenas `n_iter` (padr√£o: 50) aleat√≥rias **Total de fits**: `n_iter √ó cv_folds` = 50 √ó 2 = **100 fits**

--- **SVM - LinearSVC (Random Search - 50 itera√ß√µes padr√£o):**

**Localiza√ß√£o**: `src/pipelines/classic.py`, linhas 264-268

```python
# Espa√ßo de busca para LinearSVC (CLASSIC_USE_LINEAR_SVM = True)
param_distributions = { 'C': loguniform(0.01, 100), # Regulariza√ß√£o: 0.01 a 100 (log-uniform) 'loss': ['hinge', 'squared_hinge'], # Fun√ß√£o de perda (2 op√ß√µes) 'class_weight': [None, 'balanced'], # Balanceamento: None ou balanced (2 op√ß√µes) 'dual': [True, False] # Forma dual ou primal (2 op√ß√µes)
}
```

**Total de combina√ß√µes te√≥ricas**: Menor que SVC **Combina√ß√µes avaliadas**: Apenas `n_iter` (padr√£o: 50) aleat√≥rias **Total de fits**: `n_iter √ó cv_folds` = 50 √ó 2 = **100 fits** **Benef√≠cio**:  Muito mais eficiente em mem√≥ria (n√£o calcula matriz Gram)

--- **Random Forest (Random Search - 50 itera√ß√µes padr√£o):**

**Localiza√ß√£o**: `src/pipelines/classic.py`, linhas 430-437

```python
# Espa√ßo de busca para Random Forest
param_distributions = { 'n_estimators': randint(50, 300), # N√∫mero de √°rvores: 50 a 299 'max_depth': [None, 10, 20, 30, 50], # Profundidade m√°xima: 5 op√ß√µes 'min_samples_split': randint(2, 20), # Amostras m√≠nimas split: 2 a 19 'min_samples_leaf': randint(1, 10), # Amostras m√≠nimas folha: 1 a 9 'max_features': ['sqrt', 'log2', None], # Features por split: 3 op√ß√µes 'bootstrap': [True, False], # Bootstrap sampling: 2 op√ß√µes 'class_weight': [None, 'balanced', 'balanced_subsample']  # Balanceamento: 3 op√ß√µes
}
```

**Total de combina√ß√µes te√≥ricas**: Muito grande (produto de todos os espa√ßos) **Combina√ß√µes avaliadas**: Apenas `n_iter` (padr√£o: 50) aleat√≥rias **Total de fits**: `n_iter √ó cv_folds` = 50 √ó 2 = **100 fits**

### M√©tricas Utilizadas

- Acur√°cia (Accuracy)
- Precis√£o (Precision)
- Recall
- F1-Score
- Matriz de Confus√£o

---

## Pipeline Deep Learning - Detalhes Completos

### Modelos Implementados

#### **1. Simple CNN (sem Transfer Learning)**

**Localiza√ß√£o**: `src/models/cnn.py`, classe `SimpleCNN`, linhas 9-69

**Arquitetura Completa**:
```python
# src/models/cnn.py - LINHAS 26-46:
class SimpleCNN(nn.Module): def __init__(self, num_classes, dropout_rate=0.5, hidden_units=512): super(SimpleCNN, self).__init__() # Camadas convolucionais self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1) #  3 canais ‚Üí 32 filtros self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) #  32 ‚Üí 64 filtros self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) #  64 ‚Üí 128 filtros # Pooling self.pool = nn.MaxPool2d(2, 2) #  Reduz tamanho pela metade self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7)) #  Garante tamanho fixo (7x7) # Regulariza√ß√£o self.dropout = nn.Dropout(dropout_rate) #  Dropout configur√°vel # Camadas fully connected self.fc1 = nn.Linear(128 * 7 * 7, hidden_units) #  6272 ‚Üí hidden_units self.fc2 = nn.Linear(hidden_units, num_classes) #  hidden_units ‚Üí num_classes # Ativa√ß√£o self.relu = nn.ReLU() #  ReLU
```

**Forward Pass** (linha 48-69):
```python
# src/models/cnn.py - LINHA 48-69:
def forward(self, x): # Bloco 1: Conv1 ‚Üí ReLU ‚Üí MaxPool x = self.pool(self.relu(self.conv1(x)))  #  224x224 ‚Üí 112x112 # Bloco 2: Conv2 ‚Üí ReLU ‚Üí MaxPool x = self.pool(self.relu(self.conv2(x)))  #  112x112 ‚Üí 56x56 # Bloco 3: Conv3 ‚Üí ReLU ‚Üí MaxPool x = self.pool(self.relu(self.conv3(x)))  #  56x56 ‚Üí 28x28 # Adaptive pooling: Garante tamanho fixo independente da entrada x = self.adaptive_pool(x)  #  28x28 ‚Üí 7x7 # Flatten: Transforma em vetor x = x.view(-1, 128 * 7 * 7)  #  (batch, 128, 7, 7) ‚Üí (batch, 6272) # Fully connected com dropout x = self.dropout(x) #  Dropout aplicado x = self.relu(self.fc1(x)) #  6272 ‚Üí hidden_units x = self.fc2(x) #  hidden_units ‚Üí num_classes return x
```

**N√∫mero de Par√¢metros**:
- Com `hidden_units=512`: ~2.5 milh√µes de par√¢metros
- Com `hidden_units=1024`: ~5.3 milh√µes de par√¢metros
- Treinamento: Do zero (sem transfer learning)

**Otimiza√ß√£o**: Random Search customizado (10 itera√ß√µes padr√£o)

---

# **2. ResNet50 (com Transfer Learning)**

**Localiza√ß√£o**: `src/pipelines/deep_learning.py`, fun√ß√£o `create_resnet_model()`, linhas 993-1063

**Caracter√≠sticas**:
- Base pr√©-treinada: ImageNet (IMAGENET1K_V2)
- ~25 milh√µes de par√¢metros total
- Camadas convolucionais: Congeladas por padr√£o (configur√°vel)
- Camada final: Substitu√≠da e treinada
- Otimiza√ß√£o: Random Search customizado (10 itera√ß√µes padr√£o)

**C√≥digo Completo de Cria√ß√£o**:
```python
# src/pipelines/deep_learning.py - LINHAS 1031-1047:
print(f" Carregando ResNet50 pr√©-treinado...")
model = models.resnet50(weights='IMAGENET1K_V2')  #  Carrega pesos pr√©-treinados

# Congelar todas as camadas por padr√£o
for param in model.parameters(): param.requires_grad = False  #  N√£o treina camadas convolucionais

# Substituir camada final (fully connected)
num_features = model.fc.in_features  #  2048 features
model.fc = nn.Linear(num_features, self.num_classes)  #  2048 ‚Üí num_classes

# Descongelar apenas camada final
for param in model.fc.parameters(): param.requires_grad = True  #  Treina apenas camada final

# Opcional: Descongelar mais camadas para fine-tuning
if unfreeze_layers > 0: layers = [model.layer4, model.layer3, model.layer2, model.layer1]  #  Ordem: mais profundo ‚Üí mais raso for i, layer in enumerate(layers[:unfreeze_layers]): for param in layer.parameters(): param.requires_grad = True  #  Descongela camada para treinamento
```

**Configura√ß√µes de Unfreeze Layers**:
- `unfreeze_layers=0`: Apenas camada FC treinada (padr√£o) - **2,049 par√¢metros trein√°veis**
- `unfreeze_layers=1`: FC + layer4 treinadas - **~2.7 milh√µes trein√°veis**
- `unfreeze_layers=2`: FC + layer4 + layer3 treinadas - **~7.4 milh√µes trein√°veis**

**C√≥digo de Movimento para GPU** (linha 1049-1061):
```python
# src/pipelines/deep_learning.py - LINHAS 1049-1061:
# CR√çTICO: Mover modelo para dispositivo correto (GPU ou CPU)
model = model.to(self.device)

# Verificar dispositivo e mostrar informa√ß√µes
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
model_device = next(model.parameters()).device

print(f" ResNet50 carregado: {total_params:,} par√¢metros total, {trainable_params:,} trein√°veis")
print(f" Modelo movido para: {model_device}")
if model_device.type == 'cuda': print(f" ResNet50 est√° na GPU: {torch.cuda.get_device_name(model_device.index or 0)}")
else: print(f" ResNet50 est√° na CPU")

return model
```

### Configura√ß√£o de Treinamento Deep Learning

**Localiza√ß√£o**: `src/config.py`, linhas 32-36 e `src/pipelines/deep_learning.py`

**Par√¢metros Padr√£o** (`src/config.py`, linhas 32-36):
```python
# src/config.py - LINHAS 32-36:
BATCH_SIZE = 32 # Tamanho do batch padr√£o
EPOCHS = 50 # N√∫mero de √©pocas padr√£o
LEARNING_RATE = 0.001 # Taxa de aprendizado padr√£o
```

**Optimizer** (implementado em `deep_learning.py`, linha 598):
```python
# src/pipelines/deep_learning.py - LINHA 598:
optimizer = optim.Adam(model.parameters(), lr=learning_rate)  #  Adam optimizer
```

**Loss Function** (implementado em `deep_learning.py`, linha 597):
```python
# src/pipelines/deep_learning.py - LINHA 597:
criterion = nn.CrossEntropyLoss()  #  Cross-entropy loss (padr√£o para classifica√ß√£o)
```

**Learning Rate Scheduler** (implementado em `deep_learning.py`, linhas 599-601):
```python
# src/pipelines/deep_learning.py - LINHAS 599-601:
scheduler = optim.lr_scheduler.ReduceLROnPlateau( optimizer, mode='min', factor=0.5, patience=5  #  Reduz LR quando loss n√£o melhora
)
# mode='min': Reduz quando loss para de diminuir
# factor=0.5: Multiplica LR por 0.5 quando reduz
# patience=5: Espera 5 √©pocas sem melhoria antes de reduzir
```

**Corre√ß√£o Implementada** (linha 599-601):
- **Antes**: `verbose=True` ‚Üí  Erro: `TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'`
- **Depois**: Removido `verbose` ‚Üí  Funciona em todas as vers√µes do PyTorch

### Data Augmentation

Aplicado apenas durante o treinamento (n√£o no teste):

- Rota√ß√£o aleat√≥ria: 20 graus
- Transla√ß√£o horizontal/vertical: 20%
- Flip horizontal: Sim
- Zoom: 20%
- Ajuste de brilho/contraste: 20%

**Justificativa**: Aumenta a variabilidade dos dados de treinamento, reduzindo overfitting e melhorando generaliza√ß√£o.

### Normaliza√ß√£o

Valores de normaliza√ß√£o ImageNet:
- Mean: [0.485, 0.456, 0.406]
- Std: [0.229, 0.224, 0.225]

### Otimiza√ß√£o de Hiperpar√¢metros (Random Search) - Deep Learning

**CNN Simples (Random Search - 10 itera√ß√µes padr√£o):**

**Localiza√ß√£o**: `src/pipelines/deep_learning.py`, fun√ß√£o `train_simple_cnn()`, linhas 772-777

```python
# src/pipelines/deep_learning.py - LINHAS 772-777:
param_space = { 'learning_rate': (0.0001, 0.01), #  Log-uniform entre 0.0001 e 0.01 'batch_size': [16, 32, 64], #  Valores discretos 'dropout_rate': (0.3, 0.7), #  Uniform entre 0.3 e 0.7 'hidden_units': [256, 512, 1024] #  Valores discretos
}

best_val_acc = 0.0
search_epochs = min(15, final_epochs)  #  √âpocas limitadas durante busca (m√°ximo 15)
```

**Valida√ß√£o**: 20% split interno com early stopping (patience=5) **Total de itera√ß√µes**: `n_iter` (padr√£o: 10)

#### ResNet50 (Random Search - 10 itera√ß√µes padr√£o)

**Localiza√ß√£o**: `src/pipelines/deep_learning.py`, fun√ß√£o `train_resnet_transfer()`, linhas 1100-1104

```python
# src/pipelines/deep_learning.py - LINHAS 1100-1104:
param_space = { 'learning_rate': (0.00001, 0.001), #  Log-uniform (menor para transfer learning) 'batch_size': RESNET50_BATCH_SIZES,  #  [8, 16, 32] (reduzido de [16, 32, 64]) 'unfreeze_layers': [0, 1, 2] #  Quantidade de camadas a descongelar
}

best_val_acc = 0.0
search_epochs = min(RESNET50_SEARCH_EPOCHS, final_epochs)  #  M√°ximo 10 √©pocas
```

**Valida√ß√£o**: 20% split interno com early stopping (patience=5) **Limpeza de mem√≥ria**: Entre cada itera√ß√£o (configur√°vel) **Total de itera√ß√µes**: `n_iter` (padr√£o: 10)

**Configura√ß√µes de unfreeze_layers**:
- `unfreeze_layers=0`: Apenas camada FC treinada (padr√£o, mais r√°pido)
- `unfreeze_layers=1`: FC + layer4 treinadas (fine-tuning parcial)
- `unfreeze_layers=2`: FC + layer4 + layer3 treinadas (fine-tuning mais profundo)

**Vantagens do Random Search:**
1. Mais eficiente que Grid Search para espa√ßos de alta dimens√£o
2. Permite explorar distribui√ß√µes cont√≠nuas (log-uniform)
3. Early stopping reduz tempo de busca
4. Valida√ß√£o split garante sele√ß√£o n√£o enviesada de hiperpar√¢metros

### Escolha CPU/GPU

O sistema detecta automaticamente se h√° GPU dispon√≠vel. Para for√ßar CPU, altere em `config.py`:

```python
USE_GPU = False  # For√ßa uso de CPU
```

## Apresenta√ß√£o e Discuss√£o dos Resultados

### Tabela de Resultados do √öltimo Treinamento

Os resultados s√£o salvos automaticamente em:
- `outputs/results/classic_pipeline_results.csv`
- `outputs/results/deep_learning_results.csv`

#### Pipeline Cl√°ssico (√öltimo Treinamento)

**Data de Execu√ß√£o**: 10 de janeiro de 2026

| Modelo | Acur√°cia | Precis√£o | Recall | F1-Score | Otimiza√ß√£o | Dispositivo | Tempo Total | Data/Hora de Execu√ß√£o |
|--------|----------|----------|--------|----------|------------|-------------|-------------|----------------------|
| **SVM** | **0.6815** | **0.6868** | **0.6815** | **0.6823** | Random Search (50 iter) | CPU | 2.13s | 10/01/2026  |
| **Random Forest** | **0.6301** | **0.6294** | **0.6301** | **0.6173** | Random Search (50 iter) | CPU | 30.77s | 10/01/2026 |

**Observa√ß√µes do Pipeline Cl√°ssico**:
- Ambos modelos treinados no mesmo dia (10/01/2026), com intervalo de ~31 segundos entre eles
- SVM apresentou melhor performance (68.15% accuracy) comparado ao Random Forest (63.01%)
- Ambos modelos treinados com PCA (500 componentes) para redu√ß√£o de dimensionalidade
- Imagens redimensionadas para 64x64 pixels (economia de mem√≥ria)
- Random Search com 50 itera√ß√µes e 2 CV folds (otimizado para mem√≥ria)
- Tempo total muito r√°pido (< 1 minuto para ambos modelos)

#### Pipeline Deep Learning (√öltimo Treinamento)

**Data de Execu√ß√£o**: 10 de janeiro de 2026

| Modelo | Acur√°cia | Precis√£o | Recall | F1-Score | Transfer Learning | Data Augmentation | Otimiza√ß√£o | Tempo Total | Tempo Random Search | Tempo Treino Final | Data/Hora de Execu√ß√£o |
|--------|----------|----------|--------|----------|-------------------|-------------------|------------|-------------|---------------------|-------------------|----------------------|
| **CNN Simples** | **0.7089** | **0.7080** | **0.7089** | **0.7065** | N√£o | Sim | Random Search (10 iter) | 53:28 | 34:21 | 18:57 | 10/01/2026  |
| **ResNet50** | **0.5514** | **0.3040** | **0.5514** | **0.3919** | Sim | Sim | Random Search (10 iter) | 1:57:00 | 1:08:04 | 48:40 | 10/01/2026 |

**Observa√ß√µes do Pipeline Deep Learning**:
- CNN Simples treinado √†s 11:27:04 (10/01/2026)
- ResNet50 treinado √†s 13:24:05 (10/01/2026) - ~2 horas depois do CNN Simples
- Ambos modelos treinados no mesmo dia
- CNN Simples apresentou melhor performance (70.89% accuracy) comparado ao ResNet50 (55.14%)
- ResNet50 teve performance abaixo do esperado (poss√≠veis causas: poucos dados, fine-tuning limitado, ou dataset desbalanceado)
- CNN Simples foi mais r√°pido (53 minutos) comparado ao ResNet50 (1h57min)
- Ambos modelos usaram data augmentation para aumentar variabilidade dos dados
- Random Search com 10 itera√ß√µes para cada modelo
- Treinamento executado com limpeza de mem√≥ria entre itera√ß√µes (ResNet50)

#### Compara√ß√£o Geral dos Modelos

**Per√≠odo de Execu√ß√£o**: 10 de janeiro de 2026 (07:31 - 13:24)

| Modelo | Acur√°cia | Ranking | Tempo de Treinamento | Data/Hora | Observa√ß√£o |
|--------|----------|---------|----------------------|-----------|------------|
| **1¬∫ - CNN Simples** | **70.89%** |  | 53 minutos | 10/01/2026  | Melhor resultado geral, treinado do zero |
| **2¬∫ - SVM** | **68.15%** |  | 2 segundos | 10/01/2026  | Melhor dos modelos cl√°ssicos, muito r√°pido |
| **3¬∫ - Random Forest** | **63.01%** |  | 30 segundos | 10/01/2026 | Segunda melhor dos cl√°ssicos |
| **4¬∫ - ResNet50** | **55.14%** | 4¬∫ | 1h57min | 10/01/2026  | Performance abaixo do esperado, requer ajustes |

**Cronologia de Execu√ß√£o**:
1. **07:31:55** - In√≠cio do treinamento SVM (2.13s)
2. **07:32:26** - In√≠cio do treinamento Random Forest (30.77s)
3. **11:27:04** - In√≠cio do treinamento CNN Simples (53:28)
4. **13:24:05** - In√≠cio do treinamento ResNet50 (1:57:00)

**An√°lise Comparativa**:
- **CNN Simples** obteve a melhor performance (70.89%), demonstrando que um modelo simples pode superar modelos complexos quando h√° poucos dados
- **SVM** apresentou excelente rela√ß√£o performance/tempo (68.15% em apenas 2 segundos)
- **ResNet50** teve dificuldades, possivelmente devido a: - Dataset pequeno (~975 imagens) pode n√£o ser suficiente para fine-tuning eficaz - Fine-tuning parcial (unfreeze_layers=2: FC + layer4 + layer3) pode precisar de mais ajustes - Poss√≠vel necessidade de mais √©pocas, ajuste de learning rate ou batch size maior - Treinamento executado em CPU (mais lento, pode ter impacto na converg√™ncia)
- Modelos cl√°ssicos s√£o muito eficientes em tempo, adequados para testes r√°pidos
- Deep learning oferece melhor potencial com mais dados e ajustes

### Notas sobre os Resultados

**Informa√ß√µes de Execu√ß√£o**:
- **Data dos Treinamentos**: 10 de janeiro de 2026
- **Hor√°rio de Execu√ß√£o**: 07:31 - 15:21 (total de ~7h50min para todos os modelos)
- **Ambiente**: CPU (todos os modelos executados em CPU)
- **Vers√£o do Projeto**: 1.0

**Dataset Utilizado**:
- Total de imagens: ~975
- Classes: AI Art vs Human Art (desbalanceamento leve: 55% vs 45%)
- Divis√£o: 70% treino, 30% teste
- Tamanho de imagem: 224x224 (deep learning), 64x64 (cl√°ssicos)

**Configura√ß√µes Utilizadas**:
- **Pipeline Cl√°ssico**: PCA com 500 componentes, CV folds=2, n_jobs=1 (SVM), n_jobs=12 (RF)
- **Pipeline Deep Learning**: Data augmentation ativo, batch size vari√°vel (Random Search), early stopping (patience=5)

**Hiperpar√¢metros Otimizados (Melhores Encontrados)**:

**SVM**:
- C: 7.73, gamma: 0.0001, kernel: rbf, degree: 3, class_weight: balanced

**Random Forest**:
- n_estimators: 282, min_samples_split: 14, min_samples_leaf: 9, max_features: None, bootstrap: True

**CNN Simples**:
- learning_rate: 0.00013, batch_size: 16, dropout_rate: 0.35, hidden_units: 1024

**ResNet50**:
- learning_rate: 0.00012, batch_size: 8, unfreeze_layers: 2 (FC + layer4 + layer3 treinadas)

**M√©tricas Explicadas**:
- **Acur√°cia**: Porcentagem de predi√ß√µes corretas
- **Precis√£o**: Porcentagem de predi√ß√µes positivas que foram corretas
- **Recall**: Porcentagem de casos positivos corretamente identificados
- **F1-Score**: M√©dia harm√¥nica entre precis√£o e recall (melhor para datasets desbalanceados)

### Visualiza√ß√µes Geradas

1. **Matrizes de Confus√£o**: Uma para cada modelo - Salvas em `outputs/figures/` - Formato PNG, alta resolu√ß√£o

2. **M√©tricas Comparativas**: Tabelas em CSV

### An√°lise dos Resultados

**Pipeline Cl√°ssico:**
- SVM geralmente apresenta melhor performance para dados de alta dimensionalidade
- Random Forest √© robusto, interpret√°vel e lida bem com dados desbalanceados
- Ambos usam Random Search para encontrar hiperpar√¢metros √≥timos

**Pipeline Deep Learning:**
- CNN Simples aprende features automaticamente mas requer mais dados
- ResNet50 com transfer learning aproveita conhecimento pr√©-treinado
- Random Search otimiza hiperpar√¢metros de forma eficiente
- Deep learning geralmente supera m√©todos cl√°ssicos com dados suficientes

**Compara√ß√£o de Otimiza√ß√£o (Random Search):**
- Todos os 4 modelos utilizam Random Search para otimiza√ß√£o de hiperpar√¢metros
- Permite compara√ß√£o justa entre modelos cl√°ssicos e deep learning
- Pipeline cl√°ssico: 50 itera√ß√µes (mais r√°pido por modelo)
- Pipeline deep learning: 10 itera√ß√µes (mais custoso por itera√ß√£o)

## Conclus√£o

### Dificuldades Encontradas

1. **Pr√©-processamento de Dados** - **M√∫ltiplos formatos**: Necessidade de tratar JPG, PNG, JPEG uniformemente - **Canais inconsistentes**: Convers√£o de RGBA e grayscale para RGB - **Orienta√ß√£o EXIF**: Corre√ß√£o autom√°tica de rota√ß√£o baseada em metadados - **Normaliza√ß√£o adequada**: Diferentes normaliza√ß√µes para modelos cl√°ssicos e deep learning - **Balanceamento de classes**: Dataset com leve desbalanceamento (55% vs 45%) - **Tamanho adequado das imagens**: Redimensionamento mantendo qualidade - **Valida√ß√£o robusta**: Tratamento de imagens corrompidas ou inv√°lidas

2. **Otimiza√ß√£o de Hiperpar√¢metros** - Random Search mais eficiente que Grid Search para espa√ßos grandes - Trade-off entre n√∫mero de itera√ß√µes e qualidade dos resultados - Valida√ß√£o cruzada/split requer dados suficientes

3. **Deep Learning** - Requer GPU para treinamento eficiente - Overfitting com poucos dados - Ajuste fino de learning rate e batch size

4. **Compara√ß√£o de Modelos** - Diferentes m√©tricas podem dar resultados diferentes - Necessidade de m√∫ltiplas execu√ß√µes para estabilidade

### Melhorias Futuras

Se houvesse mais tempo para desenvolvimento:

1. **Pr√©-processamento** - **Implementado**: Padroniza√ß√£o completa de formatos (JPG, PNG, JPEG) - **Implementado**: Convers√£o autom√°tica para RGB (3 canais) - **Implementado**: Corre√ß√£o de orienta√ß√£o EXIF - **Implementado**: Remo√ß√£o de transpar√™ncia (alpha channel) - **Implementado**: Valida√ß√£o robusta e tratamento de erros - **Implementado**: Relat√≥rio detalhado de estat√≠sticas - Implementar balanceamento de classes (SMOTE, undersampling) - Testar diferentes tamanhos de imagem - Aplicar t√©cnicas de denoising - Histogram equalization para normalizar brilho/contraste - Detec√ß√£o autom√°tica de imagens de baixa qualidade

2. **Otimiza√ß√£o de Hiperpar√¢metros** - Implementar Optuna para busca bayesiana mais eficiente - Early stopping para evitar overfitting - Ensemble de modelos

3. **Deep Learning** - Testar diferentes arquiteturas (EfficientNet, Vision Transformer) - Fine-tuning completo do ResNet (n√£o apenas √∫ltima camada) - Implementar callbacks (checkpointing, tensorboard)

4. **Avalia√ß√£o** - Valida√ß√£o cruzada k-fold - An√°lise de erros (quais classes s√£o mais confundidas) - Visualiza√ß√£o de features aprendidas

5. **Deploy** - API REST para predi√ß√µes - Interface web para upload de imagens - Otimiza√ß√£o de modelos para produ√ß√£o

## Execu√ß√£o

### Exemplo Completo

```bash
# 1. Instalar depend√™ncias
pip install -r requirements.txt

# 2. Baixar e organizar dataset do Kaggle
python scripts/download_dataset.py

# 3. Executar pipeline
python main.py

# 4. Escolher op√ß√£o (1, 2, 3 ou 4)
# 1. Pipeline Cl√°ssico (SVM + Random Forest)
# 2. Pipeline Deep Learning (CNN + ResNet)
# 3. Ambos os pipelines
# 4. Sair

# 5. Ver resultados
# - outputs/results/classic_pipeline_results.csv
# - outputs/results/deep_learning_results.csv
# - outputs/figures/*.png
# - outputs/models/*.pkl ou *.pth
```

### Execu√ß√£o R√°pida (Autom√°tica)

Se voc√™ j√° tem as credenciais do Kaggle configuradas:

```bash
python main.py
```

O script detectar√° automaticamente se os dados n√£o existem e oferecer√° a op√ß√£o de baixar.

---

## Configura√ß√µes Detalhadas

Esta se√ß√£o explica **TODAS** as configura√ß√µes dispon√≠veis em `src/config.py`, organizadas por categoria.

### üìç Localiza√ß√£o das Configura√ß√µes

**Arquivo**: `src/config.py` **Total de configura√ß√µes**: 37 vari√°veis **Organiza√ß√£o**: Por categoria (dataset, treinamento, mem√≥ria, modelos espec√≠ficos)

---

## Configura√ß√µes de Dispositivo e Hardware

#### **`USE_GPU`** (linha 13)
```python
USE_GPU = True  # Altere para False para usar CPU
```

**Descri√ß√£o**: Controla se o sistema deve tentar usar GPU para modelos deep learning. **Valores**: `True` (tenta usar GPU se dispon√≠vel) ou `False` (for√ßa CPU) **Quando alterar**: 
- `False` se n√£o tiver GPU ou se quiser usar apenas CPU
- `False` se estiver tendo problemas com CUDA
- `True` para acelerar treinamento de modelos deep learning (CNN, ResNet50)

**Exemplo de uso**:
```python
# For√ßar CPU
USE_GPU = False

# Tentar usar GPU (padr√£o)
USE_GPU = True
```

---

## Configura√ß√µes do Dataset

#### **`KAGGLE_DATASET`** (linha 22)
```python
KAGGLE_DATASET = "hassnainzaidi/ai-art-vs-human-art"
```

**Descri√ß√£o**: Nome do dataset do Kaggle no formato `usuario/dataset`. **Valores**: String com nome do dataset **Quando alterar**: Se quiser usar um dataset diferente do Kaggle **Exemplo**: `"outro_usuario/outro-dataset"`

---

# **`USE_KAGGLE_DATASET`** (linha 23)
```python
USE_KAGGLE_DATASET = True  # Se True, usa dataset do Kaggle
```

**Descri√ß√£o**: Se `True`, o script tenta baixar o dataset do Kaggle automaticamente. **Valores**: `True` ou `False` **Quando alterar**: Se j√° tiver os dados organizados manualmente, pode manter `True` (o script n√£o baixa novamente se j√° existir)

---

# **`TRAIN_SPLIT` e `TEST_SPLIT`** (linhas 24-25)
```python
TRAIN_SPLIT = 0.7  # Propor√ß√£o de dados para treinamento
TEST_SPLIT = 0.3 # Propor√ß√£o de dados para teste
```

**Descri√ß√£o**: Propor√ß√µes para dividir o dataset em treino e teste. **Valores**: Float entre 0 e 1, devem somar 1.0 **Padr√£o**: 70% treino, 30% teste **Quando alterar**: 
- Se quiser mais dados de treino: `TRAIN_SPLIT = 0.8, TEST_SPLIT = 0.2`
- Se quiser mais dados de teste: `TRAIN_SPLIT = 0.6, TEST_SPLIT = 0.4`

**Importante**: Os valores devem somar 1.0!

---

# Configura√ß√µes de Imagens

#### **`IMG_SIZE`** (linha 28)
```python
IMG_SIZE = (224, 224)  # Tamanho padr√£o para modelos de deep learning
```

**Descri√ß√£o**: Tamanho das imagens para modelos deep learning (CNN, ResNet50). **Valores**: Tupla `(altura, largura)` em pixels **Padr√£o**: `(224, 224)` - padr√£o ImageNet **Quando alterar**: 
- Maior tamanho (`(256, 256)`, `(512, 512)`): Mais qualidade, mas mais mem√≥ria e tempo
- Menor tamanho (`(128, 128)`): Menos mem√≥ria, mas pode perder detalhes

**Uso**: Aplicado apenas em `src/pipelines/deep_learning.py`

---

# **`IMG_SIZE_CLASSIC`** (linha 29)
```python
IMG_SIZE_CLASSIC = (64, 64)  # Tamanho menor para modelos cl√°ssicos (economiza mem√≥ria)
```

**Descri√ß√£o**: Tamanho das imagens para modelos cl√°ssicos (SVM, Random Forest). **Valores**: Tupla `(altura, largura)` em pixels **Padr√£o**: `(64, 64)` - **OTIMIZADO para economizar mem√≥ria** **Quando alterar**: 
- Se tiver muito RAM: Pode aumentar para `(128, 128)` ou `(96, 96)`
- Se estiver com pouco RAM: Manter `(64, 64)` ou reduzir para `(32, 32)`

**Impacto na mem√≥ria**: 
- `(224, 224)`: 150,528 features por imagem
- `(64, 64)`: 12,288 features por imagem (**92% redu√ß√£o!**)

**Uso**: Aplicado apenas em `src/pipelines/classic.py`

---

# **`IMG_CHANNELS`** (linha 30)
```python
IMG_CHANNELS = 3  # RGB
```

**Descri√ß√£o**: N√∫mero de canais de cor. **Valores**: `3` (RGB) ou `1` (grayscale) **N√£o recomendado alterar**: O c√≥digo est√° otimizado para RGB (3 canais)

---

# Configura√ß√µes de Treinamento (Deep Learning)

#### **`BATCH_SIZE`** (linha 33)
```python
BATCH_SIZE = 32
```

**Descri√ß√£o**: Tamanho do batch para modelos deep learning (CNN, ResNet50). **Valores**: Inteiro positivo (8, 16, 32, 64, etc.) **Padr√£o**: `32` **Quando alterar**: 
- **Mais mem√≥ria dispon√≠vel**: Aumentar para `64` ou `128` (treina mais r√°pido)
- **Pouca mem√≥ria GPU**: Reduzir para `16` ou `8` (evita estouro de mem√≥ria)
- **ResNet50**: Use `RESNET50_DEFAULT_BATCH_SIZE` (linha 89) ao inv√©s desta

**Impacto**:
- Batch maior = treina mais r√°pido, mas usa mais mem√≥ria
- Batch menor = mais lento, mas usa menos mem√≥ria

---

# **`EPOCHS`** (linha 34)
```python
EPOCHS = 50
```

**Descri√ß√£o**: N√∫mero m√°ximo de √©pocas para treinamento deep learning. **Valores**: Inteiro positivo **Padr√£o**: `50` **Quando alterar**: 
- **Mais tempo dispon√≠vel**: Aumentar para `100` ou `200`
- **Testes r√°pidos**: Reduzir para `10` ou `20`
- **Random Search**: Usa `min(15, EPOCHS)` durante busca (linha 1586 em `deep_learning.py`)

**Nota**: Early stopping pode parar antes se n√£o houver melhoria (patience=5)

---

# **`LEARNING_RATE`** (linha 35)
```python
LEARNING_RATE = 0.001
```

**Descri√ß√£o**: Taxa de aprendizado inicial para otimizador Adam. **Valores**: Float positivo (geralmente entre 0.00001 e 0.1) **Padr√£o**: `0.001` (1e-3) **Quando alterar**: 
- **Modelo n√£o converge**: Reduzir para `0.0001` ou `0.0005`
- **Modelo converge muito devagar**: Aumentar para `0.002` ou `0.005`
- **Transfer learning (ResNet50)**: Usar learning rate menor (`0.0001` ou `0.00001`)

**Nota**: Random Search otimiza automaticamente este par√¢metro (espa√ßo: 0.0001 a 0.01 para CNN, 0.00001 a 0.001 para ResNet50)

---

## Configura√ß√µes de Data Augmentation

#### **`USE_AUGMENTATION`** (linha 38)
```python
USE_AUGMENTATION = True
```

**Descri√ß√£o**: Ativa/desativa data augmentation durante treinamento deep learning. **Valores**: `True` ou `False` **Quando alterar**: 
- **Poucos dados**: Manter `True` (aumenta variabilidade)
- **Muitos dados**: Pode desativar `False` (acelera treinamento)
- **Overfitting**: Manter `True` (reduz overfitting)

**Aplicado apenas em**: Treinamento (n√£o em teste/valida√ß√£o)

---

# **`AUGMENTATION_PARAMS`** (linhas 39-46)
```python
AUGMENTATION_PARAMS = { 'rotation_range': 20, # Rota√ß√£o: ¬±20 graus 'width_shift_range': 0.2, # Transla√ß√£o horizontal: ¬±20% 'height_shift_range': 0.2, # Transla√ß√£o vertical: ¬±20% 'horizontal_flip': True, # Flip horizontal 'zoom_range': 0.2, # Zoom: ¬±20% 'fill_mode': 'nearest' # Preenchimento de bordas
}
```

**Descri√ß√£o**: Par√¢metros espec√≠ficos de data augmentation. **Quando alterar**: 
- **Arte com orienta√ß√£o importante**: Reduzir `rotation_range` para `10`
- **Arte que n√£o deve ser espelhada**: `horizontal_flip = False`
- **Mais varia√ß√£o**: Aumentar `zoom_range` para `0.3` ou `0.4`

---

## Configura√ß√µes de Gerenciamento de Mem√≥ria

#### **`USE_LAZY_LOADING`** (linha 58)
```python
USE_LAZY_LOADING = True
```

**Descri√ß√£o**: Carrega imagens sob demanda (lazy loading) ao inv√©s de carregar tudo na mem√≥ria. **Valores**: `True` ou `False` **Recomendado**: Sempre `True` (economiza muita mem√≥ria) **Quando alterar**: Apenas se quiser carregar tudo na mem√≥ria de uma vez (`False` - n√£o recomendado)

---

# **`IMAGE_CACHE_SIZE`** (linha 61)
```python
IMAGE_CACHE_SIZE = 100
```

**Descri√ß√£o**: Tamanho do cache LRU de imagens (quantas imagens manter em cache). **Valores**: Inteiro positivo (0 = sem cache) **Padr√£o**: `100` **Quando alterar**: 
- **Mais RAM dispon√≠vel**: Aumentar para `200` ou `500` (acelera carregamento)
- **Pouca RAM**: Reduzir para `50` ou `0` (desativa cache)

**Funcionamento**: LRU (Least Recently Used) - imagens menos usadas s√£o removidas do cache

---

# **`MIN_BATCH_SIZE`** (linha 64)
```python
MIN_BATCH_SIZE = 4
```

**Descri√ß√£o**: Batch size m√≠nimo para adaptive batch size (em caso de estouro de mem√≥ria). **Valores**: Inteiro positivo (geralmente 1, 2, 4, 8) **Quando alterar**: Apenas se implementar adaptive batch size (atualmente n√£o implementado completamente)

---

# **`MEMORY_WARNING_THRESHOLD` e `MEMORY_CRITICAL_THRESHOLD`** (linhas 67-68)
```python
MEMORY_WARNING_THRESHOLD = 0.8 # 80% de uso
MEMORY_CRITICAL_THRESHOLD = 0.9  # 90% de uso
```

**Descri√ß√£o**: Limites de mem√≥ria para alertas. **Valores**: Float entre 0 e 1 (0.8 = 80%, 0.9 = 90%) **Quando alterar**: Apenas para ajustar sensibilidade dos alertas

---

# **`CLEAR_MEMORY_EVERY_N_BATCHES`** (linha 74)
```python
CLEAR_MEMORY_EVERY_N_BATCHES = 50
```

**Descri√ß√£o**: Limpar mem√≥ria GPU a cada N batches durante treinamento. **Valores**: Inteiro positivo **Quando alterar**: 
- **Estouro de mem√≥ria durante treinamento**: Reduzir para `20` ou `10`
- **Treinamento est√°vel**: Manter `50` ou aumentar para `100`

**Funcionamento**: Chama `clear_memory(clear_gpu=True)` automaticamente

---

## Configura√ß√µes Espec√≠ficas para ResNet50

#### **`RESNET50_BATCH_SIZES`** (linha 86)
```python
RESNET50_BATCH_SIZES = [8, 16, 32]  # Reduzido de [16, 32, 64]
```

**Descri√ß√£o**: Batch sizes testados durante Random Search do ResNet50. **Valores**: Lista de inteiros positivos **Padr√£o**: `[8, 16, 32]` (otimizado para evitar estouro de mem√≥ria) **Quando alterar**: 
- **GPU com muita mem√≥ria (16GB+)**: Pode aumentar para `[16, 32, 64]`
- **GPU com pouca mem√≥ria (4-6GB)**: Reduzir para `[4, 8, 16]`

**Impacto**: Batch sizes menores = menos mem√≥ria, mas Random Search mais lento

---

# **`RESNET50_DEFAULT_BATCH_SIZE`** (linha 89)
```python
RESNET50_DEFAULT_BATCH_SIZE = 16  # Reduzido de 32
```

**Descri√ß√£o**: Batch size padr√£o para treinamento final do ResNet50 (quando n√£o usar Random Search). **Valores**: Inteiro positivo **Padr√£o**: `16` (otimizado) **Quando alterar**: Baseado na mem√≥ria dispon√≠vel (mesmas recomenda√ß√µes de `BATCH_SIZE`)

---

# **`RESNET50_SEARCH_EPOCHS`** (linha 92)
```python
RESNET50_SEARCH_EPOCHS = 10  # N√∫mero m√°ximo de √©pocas durante Random Search
```

**Descri√ß√£o**: N√∫mero m√°ximo de √©pocas por itera√ß√£o durante Random Search do ResNet50. **Valores**: Inteiro positivo **Padr√£o**: `10` (otimizado para velocidade) **Quando alterar**: 
- **Random Search muito r√°pido**: Aumentar para `15` ou `20` (mais tempo, melhor busca)
- **Random Search muito lento**: Reduzir para `5` (mais r√°pido, mas menos preciso)

**Nota**: Treinamento final usa `EPOCHS` completo (50 por padr√£o)

---

# **`RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS`** (linha 95)
```python
RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True  # IMPORTANTE: Limpar entre itera√ß√µes
```

**Descri√ß√£o**: Limpa mem√≥ria GPU entre cada itera√ß√£o do Random Search do ResNet50. **Valores**: `True` ou `False` **Recomendado**: **Sempre `True`** (cr√≠tico para evitar estouro de mem√≥ria) **Quando alterar**: Apenas se tiver GPU com muita mem√≥ria e quiser testar sem limpeza (`False` - n√£o recomendado)

**Funcionamento**: Chama `clear_memory(clear_gpu=True)` antes e depois de cada itera√ß√£o

---

## Configura√ß√µes Espec√≠ficas para Modelos Cl√°ssicos

#### **`CLASSIC_USE_PCA`** (linha 102)
```python
CLASSIC_USE_PCA = True  # Usar PCA para redu√ß√£o de dimensionalidade
```

**Descri√ß√£o**: Ativa/desativa PCA para reduzir dimensionalidade antes de modelos cl√°ssicos. **Valores**: `True` ou `False` **Recomendado**: **Sempre `True`** (economiza 95%+ de mem√≥ria) **Quando alterar**: 
- **Muito RAM dispon√≠vel**: Pode desativar `False` (mais features, mais tempo)
- **Pouca RAM**: Manter `True` (essencial para economizar mem√≥ria)

**Impacto**: 
- `True`: 12,288 features ‚Üí 500 componentes (**96% redu√ß√£o!**)
- `False`: Usa todas as 12,288 features (mais mem√≥ria)

---

# **`CLASSIC_PCA_COMPONENTS`** (linha 103)
```python
CLASSIC_PCA_COMPONENTS = 500  # N√∫mero de componentes PCA
```

**Descri√ß√£o**: N√∫mero de componentes principais do PCA. **Valores**: Inteiro positivo ou `None` (auto = 95% vari√¢ncia) **Padr√£o**: `500` (otimizado para balancear mem√≥ria e qualidade) **Quando alterar**: 
- **Mais mem√≥ria dispon√≠vel**: Aumentar para `1000` ou `1500` (mais features, mais tempo)
- **Muito pouca RAM**: Reduzir para `250` ou `300` (menos features, menos qualidade)
- **Auto (95% vari√¢ncia)**: `None` (PCA decide n√∫mero automaticamente)

**Impacto na vari√¢ncia explicada**: Geralmente mant√©m ~95-98% da vari√¢ncia original

---

# **`CLASSIC_USE_LINEAR_SVM`** (linha 104)
```python
CLASSIC_USE_LINEAR_SVM = False  # False = SVC (kernels), True = LinearSVC (s√≥ linear)
```

**Descri√ß√£o**: Se `True`, usa `LinearSVC` (apenas kernel linear, mais eficiente em mem√≥ria). **Valores**: `True` ou `False` **Padr√£o**: `False` (usa `SVC` com kernels RBF, linear, poly) **Quando alterar**: 
- **Estouro de mem√≥ria com SVC**: Ativar `True` (economiza 70-90% de mem√≥ria adicional)
- **Quer kernels n√£o-lineares (RBF, poly)**: Manter `False`

**Trade-off**:
- `True`: Muito mais eficiente em mem√≥ria, mas apenas kernel linear (pode perder performance)
- `False`: Suporta kernels n√£o-lineares, mas usa mais mem√≥ria

---

# **`CLASSIC_MAX_SAMPLES`** (linha 105)
```python
CLASSIC_MAX_SAMPLES = None  # None = usar todas as amostras
```

**Descri√ß√£o**: Limita n√∫mero de amostras de treinamento para modelos cl√°ssicos. **Valores**: Inteiro positivo ou `None` (usa todas) **Padr√£o**: `None` (usa todas as amostras) **Quando alterar**: 
- **Estouro de mem√≥ria mesmo com PCA**: Definir para `10000` ou `5000` (usa amostras aleat√≥rias)
- **Testes r√°pidos**: Definir para `1000` ou `500`

**Nota**: Amostras s√£o selecionadas aleatoriamente mantendo propor√ß√£o de classes

---

# **`CLASSIC_SVM_N_JOBS`** (linha 106)
```python
CLASSIC_SVM_N_JOBS = 1  # 1 = sem paraleliza√ß√£o (economiza mem√≥ria)
```

**Descri√ß√£o**: N√∫mero de jobs paralelos para SVM e RandomizedSearchCV do SVM. **Valores**: Inteiro positivo (1 = sem paraleliza√ß√£o) ou `-1` (todos os cores) **Padr√£o**: `1` (otimizado para economizar mem√≥ria) **Quando alterar**: 
- **Muito RAM dispon√≠vel**: Aumentar para `2`, `4` ou `-1` (acelera treinamento)
- **Pouca RAM**: Manter `1` (evita duplica√ß√£o de dados em m√∫ltiplos processos)

**Trade-off**:
- `1`: Usa menos mem√≥ria, mas mais lento
- `-1`: Mais r√°pido, mas usa muito mais mem√≥ria (cada processo duplica dados)

---

# **`CLASSIC_RF_N_JOBS`** (linha 107)
```python
CLASSIC_RF_N_JOBS = -1  # -1 = todos os cores (Random Forest usa mem√≥ria eficientemente)
```

**Descri√ß√£o**: N√∫mero de jobs paralelos para Random Forest e RandomizedSearchCV do RF. **Valores**: Inteiro positivo ou `-1` (todos os cores) **Padr√£o**: `-1` (todos os cores) **Quando alterar**: 
- **Quer economizar CPU**: Reduzir para `2` ou `4`
- **Normal**: Manter `-1` (Random Forest paraleliza muito bem)

**Por que diferente do SVM?**: Random Forest usa mem√≥ria de forma mais eficiente (√°rvores independentes), ent√£o pode usar paraleliza√ß√£o sem problemas

---

# **`CLASSIC_CV_FOLDS`** (linha 108)
```python
CLASSIC_CV_FOLDS = 2  # 2 ao inv√©s de 3 para economizar mem√≥ria
```

**Descri√ß√£o**: N√∫mero de folds para valida√ß√£o cruzada em modelos cl√°ssicos (SVM e Random Forest). **Valores**: Inteiro positivo (geralmente 2, 3, 5, 10) **Padr√£o**: `2` (otimizado para economizar mem√≥ria) **Quando alterar**: 
- **Mais RAM dispon√≠vel**: Aumentar para `3` ou `5` (mais robusto, mas mais mem√≥ria)
- **Pouca RAM**: Manter `2` (essencial para economizar mem√≥ria)

**Impacto na mem√≥ria**: 
- `2`: 2 c√≥pias dos dados durante CV
- `3`: 3 c√≥pias dos dados durante CV (**50% mais mem√≥ria!**)

**Aplica-se a**: SVM e Random Forest (ambos usam esta configura√ß√£o)

---

## Configura√ß√µes de Diret√≥rios

#### **`ROOT_DIR`** (linha 10)
```python
ROOT_DIR = Path(__file__).parent.parent.absolute()
```

**Descri√ß√£o**: Diret√≥rio raiz do projeto (calculado automaticamente). **N√£o alterar**: √â calculado automaticamente baseado na localiza√ß√£o de `config.py`

---

# **`DATA_DIR`, `TRAIN_DIR`, `TEST_DIR`** (linhas 16-18)
```python
DATA_DIR = ROOT_DIR / 'data'
TRAIN_DIR = DATA_DIR / 'train'
TEST_DIR = DATA_DIR / 'test'
```

**Descri√ß√£o**: Caminhos dos diret√≥rios de dados. **Quando alterar**: Se quiser usar uma estrutura de diret√≥rios diferente **Exemplo**: `DATA_DIR = Path('/caminho/para/dados')`

---

# **`OUTPUT_DIR`, `MODELS_DIR`, `RESULTS_DIR`, `FIGURES_DIR`** (linhas 111-114)
```python
OUTPUT_DIR = ROOT_DIR / 'outputs'
MODELS_DIR = OUTPUT_DIR / 'models'
RESULTS_DIR = OUTPUT_DIR / 'results'
FIGURES_DIR = OUTPUT_DIR / 'figures'
```

**Descri√ß√£o**: Caminhos dos diret√≥rios de sa√≠da (modelos, resultados, figuras). **Quando alterar**: Se quiser salvar em outro local **Nota**: Diret√≥rios s√£o criados automaticamente se n√£o existirem (linha 117-118)

---

## Resumo de Configura√ß√µes Cr√≠ticas

**Para economizar mem√≥ria (problemas de estouro)**:
1.  `CLASSIC_USE_PCA = True` (essencial!)
2.  `CLASSIC_PCA_COMPONENTS = 500` (ou menor)
3.  `CLASSIC_SVM_N_JOBS = 1` (sem paraleliza√ß√£o)
4.  `CLASSIC_CV_FOLDS = 2` (menos folds)
5.  `RESNET50_BATCH_SIZES = [8, 16, 32]` (ou menor)
6.  `RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True` (essencial!)
7.  `IMG_SIZE_CLASSIC = (64, 64)` (n√£o aumentar!)

**Para acelerar treinamento (mais recursos dispon√≠veis)**:
1.  `USE_GPU = True` (essencial para deep learning)
2.  `BATCH_SIZE = 64` ou maior (se tiver mem√≥ria GPU)
3.  `CLASSIC_RF_N_JOBS = -1` (todos os cores)
4.  `CLASSIC_SVM_N_JOBS = -1` ou `4` (se tiver RAM)
5.  `IMAGE_CACHE_SIZE = 500` (cache maior)

**Para melhor qualidade (mais tempo dispon√≠vel)**:
1.  `EPOCHS = 100` ou maior
2.  `CLASSIC_PCA_COMPONENTS = 1000` (mais features)
3.  `CLASSIC_CV_FOLDS = 5` (mais robusto)
4.  `IMG_SIZE = (256, 256)` (imagens maiores)
5.  `RESNET50_SEARCH_EPOCHS = 20` (mais √©pocas por itera√ß√£o)

---

## Guias de Uso Completo

### Guia 1: Execu√ß√£o Completa do Zero

#### **Passo 1: Preparar Ambiente**

```bash
# 1.1. Clonar ou baixar o projeto
cd Atividade_Visao_Computacional_Residencia_IA

# 1.2. Criar ambiente virtual (recomendado)
python -m venv venv

# 1.3. Ativar ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 1.4. Instalar depend√™ncias
pip install -r requirements.txt

# 1.5. Verificar instala√ß√£o
python verificar_pytorch.py  # Verifica PyTorch e CUDA
python check_gpu.py # Verifica GPU
```

---

# **Passo 2: Configurar Dataset**

**Op√ß√£o A: Usar Dataset do Kaggle (Recomendado)**

```bash
# 2.1. Configurar credenciais do Kaggle (se necess√°rio)
# Linux/Mac:
mkdir -p ~/.kaggle
cp kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json

# Windows:
# Copie kaggle.json para: C:\Users\<username>\.kaggle\kaggle.json

# 2.2. Baixar e organizar dataset
python scripts/download_dataset.py
```

**Op√ß√£o B: Organizar Dados Manualmente**

```bash
# 2.1. Criar estrutura de diret√≥rios
mkdir -p data/train/classe1
mkdir -p data/train/classe2
mkdir -p data/test/classe1
mkdir -p data/test/classe2

# 2.2. Copiar imagens para diret√≥rios correspondentes
# (organize manualmente suas imagens)
```

---

# **Passo 3: Verificar Estrutura de Dados**

```bash
# 3.1. Diagn√≥stico da estrutura de dados
python diagnose_data.py

# 3.2. Verificar se h√° pelo menos 2 classes
# Sa√≠da esperada:
# "Classes encontradas: ['aiartdata', 'realart']"
# "Total de amostras: X"
```

**Se encontrar apenas 1 classe**:
- Execute `python scripts/download_dataset.py` novamente
- Ou use `python scripts/create_subset.py` para criar subset com classes artificiais

---

# **Passo 4: Configurar Par√¢metros (Opcional)**

Edite `src/config.py` conforme suas necessidades:

```python
# Exemplo: Configura√ß√£o para economia de mem√≥ria
USE_GPU = True
CLASSIC_USE_PCA = True
CLASSIC_PCA_COMPONENTS = 500
CLASSIC_CV_FOLDS = 2
RESNET50_BATCH_SIZES = [8, 16, 32]
```

---

# **Passo 5: Executar Pipeline**

```bash
# 5.1. Executar script principal
python main.py

# 5.2. Escolher op√ß√£o no menu:
# 1. Pipeline Cl√°ssico (SVM + Random Forest)
# 2. Pipeline Deep Learning (CNN + ResNet50)
# 3. Ambos os pipelines
# 4. Sair
```

**Tempo estimado**:
- Pipeline Cl√°ssico: 15-30 minutos (CPU)
- Pipeline Deep Learning: 30-120 minutos (GPU) ou 2-4 horas (CPU)
- Ambos: Soma dos dois

---

# **Passo 6: Analisar Resultados**

```bash
# 6.1. Resultados em CSV
cat outputs/results/classic_pipeline_results.csv
cat outputs/results/deep_learning_results.csv

# 6.2. Figuras (matrizes de confus√£o)
# Visualize: outputs/figures/*.png

# 6.3. Modelos salvos
ls outputs/models/
# Arquivos: *.pkl (modelos cl√°ssicos), *.pth (modelos deep learning), *.json (metadados)
```

---

## Guia 2: Teste R√°pido com Subset

Para testar rapidamente sem usar o dataset completo:

```bash
# 1. Criar subset pequeno (10 imagens por classe)
python scripts/create_subset.py

# 2. Executar vers√£o r√°pida do pipeline
python main_subset.py

# 3. Ajustar configura√ß√µes para testes r√°pidos em src/config.py:
# EPOCHS = 5
# n_iter = 10  # No c√≥digo main_subset.py
```

**Tempo estimado**: 2-5 minutos

---

## Guia 3: Treinar um Modelo Espec√≠fico

#### **Treinar apenas SVM**

Edite `main.py` temporariamente ou crie script customizado:

```python
# Exemplo: treinar_svm.py
from src.pipelines.classic import ClassicPipeline
from src.config import *

pipeline = ClassicPipeline(TRAIN_DIR, TEST_DIR)
pipeline.load_data()
pipeline.train_svm(use_random_search=True, n_iter=50)
pipeline.evaluate_svm()
```

```bash
python treinar_svm.py
```

---

# **Treinar apenas ResNet50**

```python
# Exemplo: treinar_resnet.py
from src.pipelines.deep_learning import DeepLearningPipeline
from src.config import *

pipeline = DeepLearningPipeline(TRAIN_DIR, TEST_DIR)
pipeline.load_data()
pipeline.train_resnet_transfer(use_random_search=True, n_iter=10, final_epochs=50)
pipeline.evaluate_resnet_transfer()
```

```bash
python treinar_resnet.py
```

---

## Guia 4: Carregar Modelo Salvo e Fazer Predi√ß√µes

Use o script de exemplo:

```python
# scripts/load_model_example.py (j√° existe no projeto)
from src.model_saver import load_model_with_metadata
from src.utils import load_image, preprocess_image
import torch

# Carregar modelo SVM
svm_model, svm_metadata = load_model_with_metadata( model_path='outputs/models/svm_model.pkl', model_type='sklearn'
)

# Carregar modelo SimpleCNN
from src.models.cnn import SimpleCNN
cnn_model, cnn_metadata = load_model_with_metadata( model_path='outputs/models/simple_cnn.pth', model_type='pytorch', model_class=SimpleCNN
)

# Fazer predi√ß√£o em nova imagem
image = load_image('caminho/para/imagem.jpg')
# ... preprocessar imagem ...
prediction = model.predict(image)
```

```bash
python scripts/load_model_example.py
```

---

### Guia 5: Otimiza√ß√£o de Hiperpar√¢metros Customizada

#### **Aumentar N√∫mero de Itera√ß√µes do Random Search**

No c√≥digo `main.py` ou nos pipelines, altere:

```python
# Pipeline Cl√°ssico
pipeline.train_svm(use_random_search=True, n_iter=100)  # Era 50

# Pipeline Deep Learning
pipeline.train_simple_cnn(use_random_search=True, n_iter=20)  # Era 10
```

**Trade-off**: Mais itera√ß√µes = melhor resultado, mas mais tempo

---

# **Personalizar Espa√ßo de Busca**

Edite os pipelines diretamente:

```python
# src/pipelines/deep_learning.py - Fun√ß√£o train_simple_cnn()
param_space = { 'learning_rate': (0.00001, 0.001),  # Espa√ßo maior 'batch_size': [8, 16, 32, 64], # Mais op√ß√µes 'dropout_rate': (0.2, 0.8), # Espa√ßo maior 'hidden_units': [128, 256, 512, 1024, 2048]  # Mais op√ß√µes
}
```

---

## Guia 6: Diagn√≥stico e Verifica√ß√£o

#### **Verificar GPU**

```bash
# Verifica√ß√£o completa
python verificar_pytorch.py

# Verifica√ß√£o de GPU
python check_gpu.py

# Diagn√≥stico de uso de GPU
python diagnose_gpu_usage.py

# Teste direto de GPU
python testar_gpu_direto.py
```

---

#### Diagnosticar Estrutura de Dados

```bash
# Diagn√≥stico completo
python diagnose_data.py

# Criar subset se necess√°rio
python scripts/create_subset.py
```

---

# **Monitorar Mem√≥ria Durante Treinamento**

Adicione logs no c√≥digo ou use ferramentas externas:

```python
# Em src/pipelines/deep_learning.py ou classic.py
from src.memory import get_memory_usage

# Durante treinamento
ram_used, ram_total, ram_percent = get_memory_usage()
print(f"RAM: {ram_used:.2f} GB / {ram_total:.2f} GB ({ram_percent*100:.1f}%)")
```

---

## Troubleshooting - Problemas Comuns e Solu√ß√µes

Esta se√ß√£o lista **TODOS** os problemas encontrados durante o desenvolvimento e suas solu√ß√µes.

---

### Problema 1: "ModuleNotFoundError: No module named 'cv2'"

**Erro completo**:
```
ModuleNotFoundError: No module named 'cv2'
```

**Causa**: `opencv-python` n√£o est√° instalado.

**Solu√ß√£o**:
```bash
pip install opencv-python
# ou
pip install -r requirements.txt
```

**Preven√ß√£o**: Sempre instale todas as depend√™ncias do `requirements.txt` antes de executar.

---

### Problema 2: "ValueError: Apenas 1 classe(s) foi(ram) carregada(s)"

**Erro completo**:
```
ValueError: ERRO: Apenas 1 classe(s) foi(ram) carregada(s), mas s√£o necess√°rias pelo menos 2 classes para classifica√ß√£o.
```

**Causa**: Dataset tem apenas 1 classe ou estrutura de diret√≥rios incorreta.

**Solu√ß√µes**:

**Solu√ß√£o 2.1: Baixar dataset do Kaggle**
```bash
python scripts/download_dataset.py
```

**Solu√ß√£o 2.2: Criar subset com classes artificiais**
```bash
python scripts/create_subset.py
```

**Solu√ß√£o 2.3: Verificar estrutura manualmente**
```bash
python diagnose_data.py
# Verifique se h√° pelo menos 2 diret√≥rios em data/train/
```

**Preven√ß√£o**: Sempre execute `diagnose_data.py` antes de treinar.

---

### Problema 3: "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"

**Erro completo**:
```
TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'
```

**Causa**: Vers√£o do PyTorch n√£o suporta par√¢metro `verbose` em `ReduceLROnPlateau`.

**Status**:  **CORRIGIDO** - Par√¢metro `verbose` foi removido em `src/pipelines/deep_learning.py` (linhas 599-601 e 548-550).

**Se ainda ocorrer**: Atualize o PyTorch:
```bash
pip install --upgrade torch torchvision
```

### Problema 4: "RuntimeError: CUDA out of memory"

**Erro completo**:
```
RuntimeError: CUDA out of memory. Tried to allocate X.XX GiB. GPU allocated memory: X.XX GiB
```

**Causa**: Modelo ou batch size muito grande para a mem√≥ria GPU dispon√≠vel.

**Solu√ß√µes**:

**Solu√ß√£o 4.1: Reduzir batch size (ResNet50)**
```python
# Em src/config.py
RESNET50_BATCH_SIZES = [4, 8, 16]  # Era [8, 16, 32]
RESNET50_DEFAULT_BATCH_SIZE = 8 # Era 16
```

**Solu√ß√£o 4.2: Reduzir batch size (CNN simples)**
```python
# Em src/config.py
BATCH_SIZE = 16  # Era 32
```

**Solu√ß√£o 4.3: Garantir limpeza de mem√≥ria (ResNet50)**
```python
# Em src/config.py
RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True  # DEVE estar True
```

**Solu√ß√£o 4.4: Limpar mem√≥ria GPU manualmente**
```python
import torch
torch.cuda.empty_cache()
torch.cuda.synchronize()
```

**Solu√ß√£o 4.5: Usar CPU ao inv√©s de GPU**
```python
# Em src/config.py
USE_GPU = False
```

**Preven√ß√£o**: 
- Sempre monitore uso de GPU: `nvidia-smi` (Linux/Windows) ou `watch -n 1 nvidia-smi`
- Use `RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True` sempre
- Comece com batch sizes pequenos e aumente gradualmente

---

### Problema 5: "MemoryError" ou Sistema Travando (SVM)

**Erro completo**:
```
MemoryError
# ou sistema simplesmente trava/freeze
```

**Causa**: SVM tentando usar muita mem√≥ria RAM (imagens muito grandes ou muitas amostras).

**Solu√ß√µes**:

**Solu√ß√£o 5.1: Ativar PCA (ESSENCIAL)**
```python
# Em src/config.py
CLASSIC_USE_PCA = True  # DEVE estar True
CLASSIC_PCA_COMPONENTS = 500  # Ou menor (250, 300)
```

**Solu√ß√£o 5.2: Reduzir tamanho de imagem**
```python
# Em src/config.py
IMG_SIZE_CLASSIC = (32, 32)  # Era (64, 64), ainda menor
```

**Solu√ß√£o 5.3: Limitar n√∫mero de amostras**
```python
# Em src/config.py
CLASSIC_MAX_SAMPLES = 5000  # Limita a 5000 amostras
```

**Solu√ß√£o 5.4: Usar LinearSVC (mais eficiente)**
```python
# Em src/config.py
CLASSIC_USE_LINEAR_SVM = True  # Mais eficiente em mem√≥ria
```

**Solu√ß√£o 5.5: Reduzir paraleliza√ß√£o**
```python
# Em src/config.py
CLASSIC_SVM_N_JOBS = 1  # Sem paraleliza√ß√£o (j√° √© padr√£o)
CLASSIC_CV_FOLDS = 2 # Menos folds (j√° √© padr√£o)
```

**Preven√ß√£o**: 
- **SEMPRE** use `CLASSIC_USE_PCA = True` para SVM
- N√£o aumente `IMG_SIZE_CLASSIC` acima de `(64, 64)`
- Monitore mem√≥ria antes de treinar (o c√≥digo j√° faz isso automaticamente)

---

### Problema 6: "AttributeError: 'str' object has no attribute 'type'"

**Erro completo**:
```
AttributeError: 'str' object has no attribute 'type'
```

**Causa**: `setup_device()` retornava string `'cpu'` ao inv√©s de `torch.device('cpu')`.

**Status**:  **CORRIGIDO** - `setup_device()` sempre retorna `torch.device` em `src/utils.py` (linhas 62, 122).

**Se ainda ocorrer**: Verifique se est√° usando a vers√£o mais recente do c√≥digo.

---

### Problema 7: Modelos Deep Learning N√£o Est√£o Usando GPU

**Sintoma**: Treinamento muito lento, ou logs mostram "CPU" ao inv√©s de "GPU".

**Causas poss√≠veis**:
1. GPU n√£o detectada
2. Modelo n√£o movido para GPU
3. Dados n√£o movidos para GPU

**Solu√ß√µes**:

**Solu√ß√£o 7.1: Verificar GPU**
```bash
python verificar_pytorch.py
python check_gpu.py
```

**Solu√ß√£o 7.2: Verificar configura√ß√£o**
```python
# Em src/config.py
USE_GPU = True  # DEVE estar True
```

**Solu√ß√£o 7.3: For√ßar GPU (se dispon√≠vel)**
```python
# O c√≥digo j√° faz isso automaticamente, mas voc√™ pode verificar:
import torch
print(f"CUDA dispon√≠vel: {torch.cuda.is_available()}")
print(f"CUDA device: {torch.cuda.get_device_name(0)}")
```

**Status**:  **CORRIGIDO** - Modelos s√£o movidos explicitamente para GPU em:
- `src/pipelines/deep_learning.py` linha 309 (SimpleCNN - Random Search)
- `src/pipelines/deep_learning.py` linha 325 (SimpleCNN - treinamento final)
- `src/pipelines/deep_learning.py` linha 1049 (ResNet50 - cria√ß√£o)
- `src/pipelines/deep_learning.py` linha 505 (train_single_config - verifica√ß√£o)

**Preven√ß√£o**: Sempre verifique os logs durante inicializa√ß√£o do pipeline:
```
 Dispositivo configurado: cuda:0
 GPU dispon√≠vel: NVIDIA GeForce RTX 3060
 SimpleCNN est√° na GPU: NVIDIA GeForce RTX 3060
```

---

### Problema 8: "EOFError" ao Executar Scripts N√£o-Interativamente

**Erro completo**:
```
EOFError
```

**Causa**: Script usa `input()` para confirma√ß√£o do usu√°rio em ambiente n√£o-interativo (CI/CD, scripts automatizados).

**Status**:  **CORRIGIDO** - `scripts/create_subset.py` n√£o usa mais `input()` interativo.

**Se ainda ocorrer**: Verifique se est√° usando a vers√£o mais recente do c√≥digo.

---

### Problema 9: "UnicodeEncodeError" ao Executar verificar_pytorch.py no Windows

**Erro completo**:
```
UnicodeEncodeError: 'charmap' codec can't encode character '\u2705'
```

**Causa**: Console do Windows n√£o configurado para UTF-8.

**Status**:  **CORRIGIDO** - `verificar_pytorch.py` agora usa `sys.stdout.reconfigure(encoding='utf-8')`.

**Se ainda ocorrer**: Execute no PowerShell com encoding UTF-8:
```powershell
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8
python verificar_pytorch.py
```

---

### Problema 10: Resultados Muito Diferentes Entre Execu√ß√µes

**Sintoma**: M√©tricas (accuracy, F1-score) variam muito entre execu√ß√µes.

**Causas poss√≠veis**:
1. Sementes aleat√≥rias n√£o fixadas
2. Divis√£o treino/teste n√£o fixada
3. Data augmentation muito agressiva

**Solu√ß√µes**:

**Solu√ß√£o 10.1: Verificar seeds fixadas**
```python
# O c√≥digo j√° usa random_state=42 em v√°rios lugares, mas verifique:
import random
import numpy as np
import torch

random.seed(42)
np.random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available(): torch.cuda.manual_seed_all(42)
```

**Solu√ß√£o 10.2: Desativar data augmentation temporariamente**
```python
# Em src/config.py
USE_AUGMENTATION = False  # Teste sem augmentation
```

**Solu√ß√£o 10.3: Usar mais √©pocas**
```python
# Em src/config.py
EPOCHS = 100  # Mais √©pocas para estabilizar
```

---

### Problema 11: "FileNotFoundError: Modelo n√£o encontrado"

**Erro completo**:
```
FileNotFoundError: Modelo n√£o encontrado: outputs/models/svm_model.pkl
```

**Causa**: Tentando carregar modelo que n√£o foi treinado ainda.

**Solu√ß√£o**:
```bash
# Treine o modelo primeiro
python main.py
# Escolha op√ß√£o 1 (Pipeline Cl√°ssico) ou 2 (Deep Learning)
```

---

### Problema 12: Treinamento Muito Lento

**Sintoma**: Treinamento demora horas mesmo para datasets pequenos.

**Causas poss√≠veis**:
1. Usando CPU ao inv√©s de GPU
2. Batch size muito pequeno
3. N√∫mero de √©pocas muito alto
4. Random Search com muitas itera√ß√µes

**Solu√ß√µes**:

**Solu√ß√£o 12.1: Verificar se est√° usando GPU**
```bash
python check_gpu.py
# Se GPU dispon√≠vel, verifique se USE_GPU = True em config.py
```

**Solu√ß√£o 12.2: Aumentar batch size (se tiver mem√≥ria)**
```python
# Em src/config.py
BATCH_SIZE = 64  # Era 32
```

**Solu√ß√£o 12.3: Reduzir √©pocas durante Random Search**
```python
# O c√≥digo j√° limita: search_epochs = min(15, final_epochs)
# Mas voc√™ pode reduzir ainda mais editando o c√≥digo
```

**Solu√ß√£o 12.4: Reduzir n√∫mero de itera√ß√µes do Random Search**
```python
# No main.py ou ao chamar pipeline:
pipeline.train_svm(use_random_search=True, n_iter=10)  # Era 50
```

---

### Problema 13: Overfitting (Alta Accuracy no Treino, Baixa no Teste)

**Sintoma**: 
- Accuracy treino: 0.95+
- Accuracy teste: 0.70-0.80

**Solu√ß√µes**:

**Solu√ß√£o 13.1: Aumentar data augmentation**
```python
# Em src/config.py
USE_AUGMENTATION = True  # J√° est√° ativo
AUGMENTATION_PARAMS = { 'rotation_range': 30, # Aumentar de 20 para 30 'zoom_range': 0.3, # Aumentar de 0.2 para 0.3 # ... outros par√¢metros
}
```

**Solu√ß√£o 13.2: Aumentar dropout**
```python
# Para SimpleCNN, durante Random Search, o dropout varia de 0.3 a 0.7
# Modelo final usar√° o melhor encontrado, mas voc√™ pode for√ßar:
# (edite o c√≥digo para usar dropout_rate fixo maior)
```

**Solu√ß√£o 13.3: Reduzir complexidade do modelo**
```python
# Para SimpleCNN: reduzir hidden_units
# Para Random Forest: reduzir max_depth, n_estimators
```

**Solu√ß√£o 13.4: Usar mais dados de treinamento**
- Baixar dataset maior
- N√£o limitar `CLASSIC_MAX_SAMPLES`

---

### Checklist de Verifica√ß√£o Antes de Treinar

Antes de executar o pipeline, verifique:

- [ ]  Todas as depend√™ncias instaladas: `pip install -r requirements.txt`
- [ ]  Dataset organizado corretamente: `python diagnose_data.py`
- [ ]  Pelo menos 2 classes detectadas
- [ ]  GPU verificada (se usando deep learning): `python check_gpu.py`
- [ ]  Configura√ß√µes de mem√≥ria ajustadas (se tiver pouco RAM)
- [ ]  `CLASSIC_USE_PCA = True` (se usando SVM)
- [ ]  `RESNET50_CLEAR_MEMORY_BETWEEN_ITERATIONS = True` (se usando ResNet50)
- [ ]  Espa√ßo em disco suficiente para salvar modelos

---

### Como Obter Mais Ajuda

Se nenhuma das solu√ß√µes acima resolveu seu problema:

1. **Verifique os logs**: O c√≥digo imprime informa√ß√µes detalhadas durante execu√ß√£o
2. **Execute scripts de diagn√≥stico**: `verificar_pytorch.py`, `check_gpu.py`, `diagnose_data.py`
3. **Consulte a documenta√ß√£o**: Este README cont√©m todas as informa√ß√µes
4. **Verifique vers√µes**: `pip list | grep torch` (verifique vers√µes compat√≠veis)

---

# Requisitos do Sistema

- Python 3.7+
- CUDA (opcional, para GPU)
- RAM: M√≠nimo 8GB (recomendado 16GB)
- Espa√ßo em disco: Depende do tamanho da base de dados

## Autores

Projeto desenvolvido para disciplina de Vis√£o Computacional.

## Licen√ßa

Este projeto √© para fins educacionais.

# Atividade_Visao_Computacional_Residencia_IA
