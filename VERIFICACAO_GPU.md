# Guia de Verifica√ß√£o de GPU/CPU

## üìã Resumo

**GPU Detectada**: ‚úÖ NVIDIA GeForce RTX 3050 (8GB)  
**PyTorch com CUDA**: ‚úÖ Vers√£o 2.7.1+cu118  
**CUDA**: ‚úÖ Vers√£o 11.8  
**Status**: ‚úÖ **GPU EST√Å SENDO USADA**

---

## üîç Como Verificar se GPU/CPU Est√° Sendo Usado

### M√©todo 1: Script de Verifica√ß√£o (Recomendado)

Execute o script de verifica√ß√£o:

```bash
python check_gpu.py
```

Este script verifica:
- ‚úÖ Instala√ß√£o do PyTorch
- ‚úÖ Disponibilidade de CUDA
- ‚úÖ Detalhes da GPU (nome, mem√≥ria, vers√£o)
- ‚úÖ Configura√ß√£o do projeto (USE_GPU)
- ‚úÖ Teste pr√°tico de cria√ß√£o de tensores
- ‚úÖ Status final (GPU ou CPU)

**Sa√≠da esperada se GPU estiver dispon√≠vel:**
```
[OK] STATUS: GPU ESTA SENDO USADA
   GPU: NVIDIA GeForce RTX 3050
   Config USE_GPU: True
   Memoria Total: 8.00 GB
```

---

### M√©todo 2: Durante o Treinamento

Ao executar o pipeline de Deep Learning, o sistema mostra automaticamente:

1. **Na inicializa√ß√£o do pipeline:**
```
============================================================
CONFIGURA√á√ÉO DE DISPOSITIVO
============================================================
‚úÖ Usando GPU: NVIDIA GeForce RTX 3050
   N√∫mero de GPUs dispon√≠veis: 1
   Mem√≥ria GPU:
     Total: 8.00 GB
     Livre: 7.98 GB
     Usada: 0.02 GB
============================================================
```

2. **No primeiro batch do treinamento:**
```
============================================================
   VERIFICACAO DE DISPOSITIVO (Batch 1, Epoca 1)
============================================================
   Modelo esta em: cuda:0
   Imagens estao em: cuda:0
   Labels estao em: cuda:0
   [OK] CONFIRMADO: Dados estao na GPU!
   GPU: NVIDIA GeForce RTX 3050
   Memoria GPU em uso: 150.25 MB
============================================================
```

---

### M√©todo 3: Verifica√ß√£o Manual no C√≥digo

Voc√™ pode verificar programaticamente:

```python
import torch
from src.utils import setup_device
from src.config import USE_GPU

# Verificar disponibilidade
print(f"CUDA disponivel: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"Memoria Total: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB")

# Verificar dispositivo configurado
device = setup_device(use_gpu=USE_GPU)
print(f"Dispositivo usado: {device}")

# Teste pr√°tico
tensor = torch.randn(100, 100).to(device)
print(f"Tensor criado em: {tensor.device}")
```

---

## ‚öôÔ∏è Configura√ß√£o

### Alterar entre GPU e CPU

Edite `src/config.py`:

```python
# Para usar GPU (padr√£o)
USE_GPU = True

# Para for√ßar CPU
USE_GPU = False
```

### Verificar Configura√ß√£o Atual

```bash
# Op√ß√£o 1: Verificar arquivo diretamente
cat src/config.py | grep USE_GPU

# Op√ß√£o 2: Usar script de verifica√ß√£o
python check_gpu.py
```

---

## üîß Troubleshooting

### Problema: GPU n√£o est√° sendo detectada

**Sintomas:**
- `CUDA dispon√≠vel: False`
- Mensagem "GPU n√£o dispon√≠vel, usando CPU"

**Solu√ß√µes:**

1. **Verificar instala√ß√£o do PyTorch com CUDA:**
   ```bash
   python -c "import torch; print(torch.cuda.is_available())"
   ```

2. **Verificar drivers NVIDIA:**
   ```bash
   nvidia-smi
   ```

3. **Reinstalar PyTorch com CUDA:**
   ```bash
   pip uninstall torch torchvision
   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
   ```

4. **Verificar vers√£o de CUDA:**
   - Sistema deve ter CUDA instalado
   - PyTorch deve ser compat√≠vel com vers√£o CUDA do sistema

### Problema: USE_GPU=True mas usando CPU

**Causas poss√≠veis:**
- PyTorch instalado sem suporte CUDA
- GPU n√£o compat√≠vel
- Drivers NVIDIA n√£o instalados

**Solu√ß√£o:** O c√≥digo automaticamente usa CPU quando GPU n√£o est√° dispon√≠vel, mesmo com `USE_GPU=True`.

### Problema: Mem√≥ria GPU insuficiente

**Sintomas:**
- Erro "out of memory"
- Treinamento muito lento

**Solu√ß√µes:**

1. **Reduzir batch size** em `src/config.py`:
   ```python
   BATCH_SIZE = 16  # Reduzir de 32 para 16
   ```

2. **Ativar lazy loading** (j√° ativado por padr√£o):
   ```python
   USE_LAZY_LOADING = True
   ```

3. **Reduzir cache de imagens:**
   ```python
   IMAGE_CACHE_SIZE = 50  # Reduzir de 100 para 50
   ```

4. **Limpar mem√≥ria GPU periodicamente:**
   - J√° est√° implementado automaticamente
   - Limpa a cada 50 batches

---

## üìä Informa√ß√µes da GPU Detectada

**GPU Atual:**
- **Nome**: NVIDIA GeForce RTX 3050
- **Mem√≥ria Total**: 8.00 GB
- **Capacidade CUDA**: (8, 6)
- **Vers√£o CUDA**: 11.8
- **Vers√£o cuDNN**: 90100

**Status de Uso:**
- ‚úÖ GPU est√° dispon√≠vel e configurada
- ‚úÖ PyTorch detecta a GPU corretamente
- ‚úÖ Configura√ß√£o `USE_GPU=True` est√° correta
- ‚úÖ Testes pr√°ticos confirmam uso da GPU

---

## ‚úÖ Verifica√ß√µes Implementadas

O c√≥digo agora verifica automaticamente:

1. ‚úÖ **Na inicializa√ß√£o do pipeline** - Mostra dispositivo configurado
2. ‚úÖ **No primeiro batch do treinamento** - Confirma localiza√ß√£o dos dados
3. ‚úÖ **Durante Random Search** - Verifica dispositivo em cada itera√ß√£o
4. ‚úÖ **No script de verifica√ß√£o** - Teste completo de GPU/CPU

---

## üéØ Pr√≥ximos Passos

1. **Execute o script de verifica√ß√£o:**
   ```bash
   python check_gpu.py
   ```

2. **Execute o pipeline de Deep Learning** para ver as verifica√ß√µes em tempo real:
   ```bash
   python main.py
   # Escolha op√ß√£o 2 (Pipeline Deep Learning)
   ```

3. **Monitore uso de mem√≥ria GPU** durante o treinamento:
   - O c√≥digo mostra automaticamente
   - Ou use `nvidia-smi` em outro terminal

---

## üìù Notas Importantes

- ‚ö†Ô∏è **Pipeline Cl√°ssico (SVM/RF)** sempre usa CPU (n√£o usa GPU)
- ‚úÖ **Pipeline Deep Learning** usa GPU se dispon√≠vel
- ‚úÖ O c√≥digo **automaticamente** detecta e usa GPU quando dispon√≠vel
- ‚úÖ Se GPU n√£o estiver dispon√≠vel, **automaticamente** usa CPU
- ‚úÖ Verifica√ß√µes s√£o feitas **automaticamente** durante o treinamento

---

**√öltima verifica√ß√£o**: Script `check_gpu.py` executado com sucesso  
**Status**: ‚úÖ GPU configurada e pronta para uso
